2019-05-30 15:40:34,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-30 15:40:34,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-30 15:40:34,965 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-30 15:40:35,505 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data
2019-05-30 15:40:35,610 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-30 15:40:35,733 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-30 15:40:35,733 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-30 15:40:35,739 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:40:35,744 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-30 15:40:35,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-30 15:40:35,751 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:40:35,751 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-30 15:40:35,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-30 15:40:35,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-30 15:40:35,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-30 15:40:35,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-30 15:40:35,914 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-30 15:40:35,928 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-30 15:40:35,952 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-30 15:40:35,966 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-30 15:40:35,972 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-30 15:40:35,972 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-30 15:40:35,972 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-30 15:40:35,999 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 59584
2019-05-30 15:40:36,000 INFO org.mortbay.log: jetty-6.1.26
2019-05-30 15:40:36,338 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:59584
2019-05-30 15:40:36,463 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-30 15:40:36,471 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-30 15:40:36,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-30 15:40:36,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-30 15:40:36,897 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-30 15:40:36,921 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-30 15:40:37,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-30 15:40:37,239 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-30 15:40:37,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-30 15:40:37,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-30 15:40:37,271 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-30 15:40:37,271 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-30 15:40:38,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:39,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:40,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:41,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:42,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:43,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:44,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:45,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:46,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:47,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:47,434 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:40:53,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:54,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:55,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:56,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:57,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:58,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:40:59,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:00,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:01,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:02,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:02,443 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:41:08,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:09,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:10,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:11,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:12,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:13,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:14,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:15,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:16,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:17,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:17,453 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:41:23,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:24,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:25,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:26,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:27,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:28,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:29,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:30,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:31,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:32,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:32,461 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:41:38,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:39,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:40,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:41,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:42,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:43,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:44,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:45,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:46,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:47,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:47,470 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:41:53,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:54,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:55,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:56,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:57,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:58,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:41:59,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:00,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:01,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:02,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:02,479 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:42:08,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:09,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:10,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:11,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:12,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:13,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:14,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:15,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:16,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:17,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:17,487 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:42:23,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:24,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:25,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:26,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:27,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:28,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:29,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:30,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:31,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:32,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:32,495 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:42:38,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:39,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:40,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:41,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:42,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:43,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:44,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:45,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:46,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:47,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:47,505 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:42:53,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:54,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:55,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:56,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:57,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:58,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:42:59,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:00,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:01,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:02,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:02,512 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:43:08,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:09,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:10,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:11,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:12,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:13,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:14,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:15,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:16,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:17,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:17,520 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:43:23,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:24,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:25,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:26,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:27,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:28,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:29,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:30,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:31,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:32,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:32,528 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:43:38,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:39,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:40,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:41,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:42,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:43,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:44,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:45,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:46,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:47,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:47,538 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:43:53,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:54,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:55,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:56,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:57,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:58,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:43:59,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:00,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:01,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:02,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:02,547 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:44:08,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:09,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:10,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:11,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:12,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:13,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:14,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:15,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:16,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:17,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:44:17,559 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-05-30 15:44:17,787 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-05-30 15:44:17,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-05-30 15:46:05,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-30 15:46:05,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-30 15:46:05,987 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-30 15:46:06,547 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data/
2019-05-30 15:46:06,633 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-30 15:46:06,755 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-30 15:46:06,755 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-30 15:46:06,760 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:46:06,762 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-30 15:46:06,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-30 15:46:06,764 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:46:06,765 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-30 15:46:06,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-30 15:46:06,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-30 15:46:06,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-30 15:46:06,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-30 15:46:06,931 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-30 15:46:06,946 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-30 15:46:06,972 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-30 15:46:06,986 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-30 15:46:06,997 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-30 15:46:06,997 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-30 15:46:06,997 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-30 15:46:07,026 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 53013
2019-05-30 15:46:07,026 INFO org.mortbay.log: jetty-6.1.26
2019-05-30 15:46:07,380 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:53013
2019-05-30 15:46:07,470 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-30 15:46:07,477 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-30 15:46:07,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-30 15:46:07,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-30 15:46:07,909 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-30 15:46:07,929 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-30 15:46:08,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-30 15:46:08,026 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-30 15:46:08,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-30 15:46:08,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-30 15:46:08,068 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-30 15:46:08,069 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-30 15:46:08,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-05-30 15:46:08,460 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-05-30 15:46:08,501 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 22762@master
2019-05-30 15:46:08,502 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-root/dfs/data is not formatted for namespace 1704698767. Formatting...
2019-05-30 15:46:08,502 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-c8676de4-32a9-4004-9dce-11a5343a5ee5 for directory /tmp/hadoop-root/dfs/data
2019-05-30 15:46:08,587 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:46:08,587 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:46:08,587 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798 is not formatted for BP-1428274316-192.168.56.180-1559198748798. Formatting ...
2019-05-30 15:46:08,587 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1428274316-192.168.56.180-1559198748798 directory /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798/current
2019-05-30 15:46:08,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1704698767;bpid=BP-1428274316-192.168.56.180-1559198748798;lv=-57;nsInfo=lv=-63;cid=CID-063d246f-8474-4e20-97fb-6058682c532e;nsid=1704698767;c=1559198748798;bpid=BP-1428274316-192.168.56.180-1559198748798;dnuuid=null
2019-05-30 15:46:08,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 329be567-c950-48a1-a34a-6a3e06a46de2
2019-05-30 15:46:08,701 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c8676de4-32a9-4004-9dce-11a5343a5ee5
2019-05-30 15:46:08,701 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-root/dfs/data/current, StorageType: DISK
2019-05-30 15:46:08,708 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-05-30 15:46:08,724 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /tmp/hadoop-root/dfs/data/current
2019-05-30 15:46:08,735 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /tmp/hadoop-root/dfs/data/current
2019-05-30 15:46:08,737 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:46:08,740 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data/current...
2019-05-30 15:46:08,863 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1428274316-192.168.56.180-1559198748798 on /tmp/hadoop-root/dfs/data/current: 122ms
2019-05-30 15:46:08,864 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1428274316-192.168.56.180-1559198748798: 128ms
2019-05-30 15:46:08,875 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data/current...
2019-05-30 15:46:08,876 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798/current/replicas doesn't exist 
2019-05-30 15:46:08,876 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data/current: 0ms
2019-05-30 15:46:08,876 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 10ms
2019-05-30 15:46:08,877 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data
2019-05-30 15:46:08,878 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-c8676de4-32a9-4004-9dce-11a5343a5ee5): finished scanning block pool BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:46:08,922 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 5. 30 오후 5:42 with interval of 21600000ms
2019-05-30 15:46:08,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1428274316-192.168.56.180-1559198748798 (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-05-30 15:46:09,015 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-c8676de4-32a9-4004-9dce-11a5343a5ee5): no suitable block pools found to scan.  Waiting 1814399862 ms.
2019-05-30 15:46:09,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1428274316-192.168.56.180-1559198748798 (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-05-30 15:46:09,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-05-30 15:46:09,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x945dddf03fbf4c1b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 155 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-30 15:46:09,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:47:18,124 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-05-30 15:47:22,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:47:23,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:47:24,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:47:25,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:47:25,219 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-05-30 15:47:25,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-05-30 15:48:56,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-30 15:48:56,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-30 15:48:57,287 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-30 15:48:57,835 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data/
2019-05-30 15:48:57,932 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-30 15:48:58,051 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-30 15:48:58,051 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-30 15:48:58,061 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:48:58,065 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-30 15:48:58,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-30 15:48:58,068 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:48:58,068 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-30 15:48:58,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-30 15:48:58,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-30 15:48:58,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-30 15:48:58,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-30 15:48:58,230 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-30 15:48:58,248 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-30 15:48:58,276 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-30 15:48:58,283 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-30 15:48:58,293 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-30 15:48:58,294 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-30 15:48:58,294 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-30 15:48:58,307 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50833
2019-05-30 15:48:58,307 INFO org.mortbay.log: jetty-6.1.26
2019-05-30 15:48:58,663 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:50833
2019-05-30 15:48:58,747 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-30 15:48:58,755 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-30 15:48:59,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-30 15:48:59,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-30 15:48:59,161 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-30 15:48:59,190 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-30 15:48:59,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-30 15:48:59,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-30 15:48:59,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-30 15:48:59,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-30 15:48:59,337 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-30 15:48:59,338 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-30 15:48:59,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-05-30 15:48:59,762 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-05-30 15:48:59,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 23707@master
2019-05-30 15:48:59,848 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:48:59,848 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:48:59,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1704698767;bpid=BP-1428274316-192.168.56.180-1559198748798;lv=-57;nsInfo=lv=-63;cid=CID-063d246f-8474-4e20-97fb-6058682c532e;nsid=1704698767;c=1559198748798;bpid=BP-1428274316-192.168.56.180-1559198748798;dnuuid=329be567-c950-48a1-a34a-6a3e06a46de2
2019-05-30 15:48:59,925 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c8676de4-32a9-4004-9dce-11a5343a5ee5
2019-05-30 15:48:59,925 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-root/dfs/data/current, StorageType: DISK
2019-05-30 15:48:59,936 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-05-30 15:48:59,944 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /tmp/hadoop-root/dfs/data/current
2019-05-30 15:48:59,950 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /tmp/hadoop-root/dfs/data/current
2019-05-30 15:48:59,954 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:48:59,957 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data/current...
2019-05-30 15:48:59,971 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798/current: 24576
2019-05-30 15:48:59,999 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1428274316-192.168.56.180-1559198748798 on /tmp/hadoop-root/dfs/data/current: 43ms
2019-05-30 15:48:59,999 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1428274316-192.168.56.180-1559198748798: 43ms
2019-05-30 15:49:00,002 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data/current...
2019-05-30 15:49:00,002 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798/current/replicas doesn't exist 
2019-05-30 15:49:00,002 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data/current: 1ms
2019-05-30 15:49:00,002 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2019-05-30 15:49:00,085 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-c8676de4-32a9-4004-9dce-11a5343a5ee5): no suitable block pools found to scan.  Waiting 1814228792 ms.
2019-05-30 15:49:00,097 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 5. 30 오후 4:27 with interval of 21600000ms
2019-05-30 15:49:00,101 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1428274316-192.168.56.180-1559198748798 (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-05-30 15:49:00,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1428274316-192.168.56.180-1559198748798 (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-05-30 15:49:00,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-05-30 15:49:00,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x99e750f211bd329f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 129 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-30 15:49:00,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:51:15,266 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-05-30 15:51:18,761 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-05-30 15:51:18,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-05-30 15:54:02,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-30 15:54:02,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-30 15:54:02,650 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-30 15:54:03,102 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data/
2019-05-30 15:54:03,184 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-30 15:54:03,303 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-30 15:54:03,303 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-30 15:54:03,312 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:54:03,314 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-30 15:54:03,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-30 15:54:03,319 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:54:03,319 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-30 15:54:03,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-30 15:54:03,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-30 15:54:03,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-30 15:54:03,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-30 15:54:03,465 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-30 15:54:03,480 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-30 15:54:03,504 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-30 15:54:03,512 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-30 15:54:03,519 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-30 15:54:03,519 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-30 15:54:03,520 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-30 15:54:03,532 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40707
2019-05-30 15:54:03,532 INFO org.mortbay.log: jetty-6.1.26
2019-05-30 15:54:03,857 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40707
2019-05-30 15:54:03,932 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-30 15:54:03,940 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-30 15:54:04,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-30 15:54:04,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-30 15:54:04,350 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-30 15:54:04,379 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-30 15:54:04,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-30 15:54:04,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-30 15:54:04,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-30 15:54:04,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-30 15:54:04,528 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-30 15:54:04,532 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-30 15:54:04,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-05-30 15:54:04,922 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-05-30 15:54:05,000 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 24646@master
2019-05-30 15:54:05,066 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:54:05,066 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:54:05,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1704698767;bpid=BP-1428274316-192.168.56.180-1559198748798;lv=-57;nsInfo=lv=-63;cid=CID-063d246f-8474-4e20-97fb-6058682c532e;nsid=1704698767;c=1559198748798;bpid=BP-1428274316-192.168.56.180-1559198748798;dnuuid=329be567-c950-48a1-a34a-6a3e06a46de2
2019-05-30 15:54:05,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c8676de4-32a9-4004-9dce-11a5343a5ee5
2019-05-30 15:54:05,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-root/dfs/data/current, StorageType: DISK
2019-05-30 15:54:05,143 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-05-30 15:54:05,150 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /tmp/hadoop-root/dfs/data/current
2019-05-30 15:54:05,156 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /tmp/hadoop-root/dfs/data/current
2019-05-30 15:54:05,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:54:05,158 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data/current...
2019-05-30 15:54:05,171 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798/current: 24576
2019-05-30 15:54:05,202 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1428274316-192.168.56.180-1559198748798 on /tmp/hadoop-root/dfs/data/current: 44ms
2019-05-30 15:54:05,202 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1428274316-192.168.56.180-1559198748798: 45ms
2019-05-30 15:54:05,204 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data/current...
2019-05-30 15:54:05,204 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /tmp/hadoop-root/dfs/data/current/BP-1428274316-192.168.56.180-1559198748798/current/replicas doesn't exist 
2019-05-30 15:54:05,204 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1428274316-192.168.56.180-1559198748798 on volume /tmp/hadoop-root/dfs/data/current: 1ms
2019-05-30 15:54:05,204 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2019-05-30 15:54:05,288 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-c8676de4-32a9-4004-9dce-11a5343a5ee5): no suitable block pools found to scan.  Waiting 1813923589 ms.
2019-05-30 15:54:05,302 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 5. 30 오후 4:04 with interval of 21600000ms
2019-05-30 15:54:05,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1428274316-192.168.56.180-1559198748798 (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-05-30 15:54:05,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1428274316-192.168.56.180-1559198748798 (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-05-30 15:54:05,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-05-30 15:54:05,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd604928894d40622,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 16 msec to generate and 123 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-30 15:54:05,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1428274316-192.168.56.180-1559198748798
2019-05-30 15:55:05,530 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: Failed on local exception: java.io.IOException: 연결이 상대편에 의해 끊어짐; Host Details : local host is: "master/192.168.56.180"; destination host is: "localhost":9000; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:805)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:558)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-05-30 15:55:09,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:55:10,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-30 15:55:10,552 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-05-30 15:55:10,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-05-30 15:56:01,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-30 15:56:01,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-30 15:56:01,834 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-30 15:56:02,236 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data/
2019-05-30 15:56:02,325 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-30 15:56:02,440 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-30 15:56:02,440 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-30 15:56:02,446 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:56:02,447 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-30 15:56:02,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-30 15:56:02,450 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:56:02,450 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-30 15:56:02,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-30 15:56:02,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-30 15:56:02,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-30 15:56:02,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-30 15:56:02,591 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-30 15:56:02,607 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-30 15:56:02,630 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-30 15:56:02,640 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-30 15:56:02,648 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-30 15:56:02,648 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-30 15:56:02,648 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-30 15:56:02,663 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 49903
2019-05-30 15:56:02,663 INFO org.mortbay.log: jetty-6.1.26
2019-05-30 15:56:03,030 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:49903
2019-05-30 15:56:03,140 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-30 15:56:03,150 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-30 15:56:03,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-30 15:56:03,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-30 15:56:03,576 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-30 15:56:03,608 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-30 15:56:03,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-30 15:56:03,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-30 15:56:03,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-30 15:56:03,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-30 15:56:03,780 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-30 15:56:03,781 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-30 15:56:04,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-05-30 15:56:04,171 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-05-30 15:56:04,227 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 25537@master
2019-05-30 15:56:04,229 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/tmp/hadoop-root/dfs/data/
java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-0c3f4de0-d895-4956-8cd7-a5892f91e4dc; datanode clusterID = CID-063d246f-8474-4e20-97fb-6058682c532e
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-05-30 15:56:04,234 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-05-30 15:56:04,235 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000
2019-05-30 15:56:04,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2)
2019-05-30 15:56:06,239 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-05-30 15:56:06,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-05-30 15:57:30,743 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-30 15:57:30,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-30 15:57:31,159 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-30 15:57:31,591 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data/
2019-05-30 15:57:31,673 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-30 15:57:31,794 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-30 15:57:31,794 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-30 15:57:31,800 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:57:31,802 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-30 15:57:31,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-30 15:57:31,804 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 15:57:31,804 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-30 15:57:31,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-30 15:57:31,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-30 15:57:31,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-30 15:57:31,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-30 15:57:31,956 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-30 15:57:31,977 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-30 15:57:32,002 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-30 15:57:32,008 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-30 15:57:32,014 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-30 15:57:32,014 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-30 15:57:32,014 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-30 15:57:32,029 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 59732
2019-05-30 15:57:32,029 INFO org.mortbay.log: jetty-6.1.26
2019-05-30 15:57:32,400 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:59732
2019-05-30 15:57:32,542 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-30 15:57:32,552 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-30 15:57:32,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-30 15:57:32,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-30 15:57:33,022 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-30 15:57:33,048 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-30 15:57:33,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-30 15:57:33,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-30 15:57:33,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-30 15:57:33,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-30 15:57:33,178 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-30 15:57:33,182 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-30 15:57:33,627 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-05-30 15:57:33,636 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-05-30 15:57:33,678 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 26412@master
2019-05-30 15:57:33,679 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/tmp/hadoop-root/dfs/data/
java.io.IOException: Incompatible clusterIDs in /tmp/hadoop-root/dfs/data: namenode clusterID = CID-0c3f4de0-d895-4956-8cd7-a5892f91e4dc; datanode clusterID = CID-063d246f-8474-4e20-97fb-6058682c532e
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-05-30 15:57:33,681 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-05-30 15:57:33,686 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2) service to localhost/127.0.0.1:9000
2019-05-30 15:57:33,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 329be567-c950-48a1-a34a-6a3e06a46de2)
2019-05-30 15:57:35,692 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-05-30 15:57:35,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-05-30 17:14:49,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-30 17:14:50,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-30 17:14:50,525 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-30 17:14:51,138 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-05-30 17:14:51,329 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-30 17:14:51,475 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-30 17:14:51,475 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-30 17:14:51,487 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 17:14:51,489 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-30 17:14:51,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-30 17:14:51,497 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 17:14:51,497 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-30 17:14:51,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-30 17:14:51,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-30 17:14:51,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-30 17:14:51,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-30 17:14:52,015 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-30 17:14:52,043 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-30 17:14:52,086 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-30 17:14:52,096 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-30 17:14:52,098 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-30 17:14:52,099 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-30 17:14:52,099 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-30 17:14:52,151 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42527
2019-05-30 17:14:52,151 INFO org.mortbay.log: jetty-6.1.26
2019-05-30 17:14:52,953 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:42527
2019-05-30 17:14:53,464 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-30 17:14:53,485 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-30 17:14:54,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-30 17:14:54,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-30 17:14:54,628 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-30 17:14:54,703 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-30 17:14:54,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-30 17:14:55,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-30 17:14:55,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-30 17:14:55,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-30 17:14:55,157 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-30 17:14:55,160 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-30 17:14:56,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-05-30 17:14:56,147 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-05-30 17:14:56,190 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 2063@master
2019-05-30 17:14:56,191 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /home/FP/hadoop/datanode is not formatted for namespace 825864606. Formatting...
2019-05-30 17:14:56,194 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a for directory /home/FP/hadoop/datanode
2019-05-30 17:14:56,324 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1050389560-192.168.56.180-1559204067205
2019-05-30 17:14:56,324 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205
2019-05-30 17:14:56,325 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205 is not formatted for BP-1050389560-192.168.56.180-1559204067205. Formatting ...
2019-05-30 17:14:56,325 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1050389560-192.168.56.180-1559204067205 directory /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current
2019-05-30 17:14:56,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=825864606;bpid=BP-1050389560-192.168.56.180-1559204067205;lv=-57;nsInfo=lv=-63;cid=CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5;nsid=825864606;c=1559204067205;bpid=BP-1050389560-192.168.56.180-1559204067205;dnuuid=null
2019-05-30 17:14:56,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 32039258-15d2-4d4a-ad40-f606c2429562
2019-05-30 17:14:56,557 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a
2019-05-30 17:14:56,557 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-05-30 17:14:56,585 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-05-30 17:14:56,615 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-05-30 17:14:56,664 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-05-30 17:14:56,665 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-30 17:14:56,667 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-05-30 17:14:56,796 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1050389560-192.168.56.180-1559204067205 on /home/FP/hadoop/datanode/current: 129ms
2019-05-30 17:14:56,798 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1050389560-192.168.56.180-1559204067205: 133ms
2019-05-30 17:14:56,808 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-05-30 17:14:56,808 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/replicas doesn't exist 
2019-05-30 17:14:56,808 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current: 0ms
2019-05-30 17:14:56,808 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 9ms
2019-05-30 17:14:56,810 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode
2019-05-30 17:14:56,811 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a): finished scanning block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-30 17:14:56,859 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 5. 30 오후 10:19 with interval of 21600000ms
2019-05-30 17:14:56,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-05-30 17:14:56,958 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a): no suitable block pools found to scan.  Waiting 1814399852 ms.
2019-05-30 17:14:57,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-05-30 17:14:57,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-05-30 17:14:57,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x95a644008e30836d,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 22 msec to generate and 263 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-30 17:14:57,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-30 17:21:18,252 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-05-30 17:21:20,970 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-05-30 17:21:20,977 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-05-30 17:25:39,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-30 17:25:39,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-30 17:25:40,557 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-30 17:25:41,330 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-05-30 17:25:41,465 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-30 17:25:41,621 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-30 17:25:41,621 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-30 17:25:41,645 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 17:25:41,651 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-30 17:25:41,658 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-30 17:25:41,658 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-30 17:25:41,658 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-30 17:25:41,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-30 17:25:41,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-30 17:25:41,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-30 17:25:41,727 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-30 17:25:41,898 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-30 17:25:41,923 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-30 17:25:41,955 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-30 17:25:41,961 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-30 17:25:41,967 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-30 17:25:41,968 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-30 17:25:41,968 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-30 17:25:41,988 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41156
2019-05-30 17:25:41,988 INFO org.mortbay.log: jetty-6.1.26
2019-05-30 17:25:42,617 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41156
2019-05-30 17:25:42,912 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-30 17:25:42,939 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-30 17:25:44,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-30 17:25:44,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-30 17:25:44,254 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-30 17:25:44,337 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-30 17:25:44,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-30 17:25:44,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-30 17:25:44,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-30 17:25:44,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-30 17:25:45,004 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-30 17:25:45,010 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-30 17:25:46,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-05-30 17:25:46,765 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-05-30 17:25:46,821 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 3025@master
2019-05-30 17:25:46,994 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1050389560-192.168.56.180-1559204067205
2019-05-30 17:25:46,995 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205
2019-05-30 17:25:46,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=825864606;bpid=BP-1050389560-192.168.56.180-1559204067205;lv=-57;nsInfo=lv=-63;cid=CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5;nsid=825864606;c=1559204067205;bpid=BP-1050389560-192.168.56.180-1559204067205;dnuuid=32039258-15d2-4d4a-ad40-f606c2429562
2019-05-30 17:25:47,310 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a
2019-05-30 17:25:47,310 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-05-30 17:25:47,333 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-05-30 17:25:47,372 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-05-30 17:25:47,426 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-05-30 17:25:47,435 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-30 17:25:47,443 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-05-30 17:25:47,520 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current: 24576
2019-05-30 17:25:47,614 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1050389560-192.168.56.180-1559204067205 on /home/FP/hadoop/datanode/current: 171ms
2019-05-30 17:25:47,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1050389560-192.168.56.180-1559204067205: 177ms
2019-05-30 17:25:47,621 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-05-30 17:25:47,621 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/replicas doesn't exist 
2019-05-30 17:25:47,622 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current: 1ms
2019-05-30 17:25:47,622 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 4ms
2019-05-30 17:25:47,847 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a): no suitable block pools found to scan.  Waiting 1813748963 ms.
2019-05-30 17:25:47,885 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 5. 30 오후 8:13 with interval of 21600000ms
2019-05-30 17:25:47,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-05-30 17:25:48,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-05-30 17:25:48,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-05-30 17:25:48,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xed103c79b36df872,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 114 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-30 17:25:48,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-30 19:00:49,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xed103c79b36df873,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-30 19:00:49,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-30 20:13:19,891 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1050389560-192.168.56.180-1559204067205 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-05-31 01:00:51,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xed103c79b36df874,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-31 01:00:51,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-31 02:13:19,886 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1050389560-192.168.56.180-1559204067205 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-05-31 07:00:51,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xed103c79b36df875,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-31 07:00:51,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-31 08:13:19,886 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1050389560-192.168.56.180-1559204067205 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-05-31 11:49:11,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-31 11:49:11,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-31 11:49:12,337 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-31 11:49:12,969 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-05-31 11:49:13,133 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-31 11:49:13,346 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-31 11:49:13,346 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-31 11:49:13,364 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-31 11:49:13,366 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-31 11:49:13,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-31 11:49:13,370 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-31 11:49:13,371 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-31 11:49:13,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-31 11:49:13,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-31 11:49:13,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-31 11:49:13,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-31 11:49:13,721 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-31 11:49:13,738 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-31 11:49:13,802 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-31 11:49:13,811 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-31 11:49:13,815 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-31 11:49:13,815 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-31 11:49:13,817 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-31 11:49:13,858 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40082
2019-05-31 11:49:13,858 INFO org.mortbay.log: jetty-6.1.26
2019-05-31 11:49:14,975 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40082
2019-05-31 11:49:15,274 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-31 11:49:15,305 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-31 11:49:16,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-31 11:49:16,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-31 11:49:16,772 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-31 11:49:16,842 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-31 11:49:17,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-31 11:49:17,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-31 11:49:17,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-31 11:49:17,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-31 11:49:17,174 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-31 11:49:17,174 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-31 11:49:18,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-05-31 11:49:18,045 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-05-31 11:49:18,068 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 2687@master
2019-05-31 11:49:18,228 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1050389560-192.168.56.180-1559204067205
2019-05-31 11:49:18,228 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205
2019-05-31 11:49:18,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=825864606;bpid=BP-1050389560-192.168.56.180-1559204067205;lv=-57;nsInfo=lv=-63;cid=CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5;nsid=825864606;c=1559204067205;bpid=BP-1050389560-192.168.56.180-1559204067205;dnuuid=32039258-15d2-4d4a-ad40-f606c2429562
2019-05-31 11:49:18,411 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a
2019-05-31 11:49:18,411 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-05-31 11:49:18,423 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-05-31 11:49:18,448 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-05-31 11:49:18,471 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-05-31 11:49:18,472 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-31 11:49:18,479 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-05-31 11:49:18,561 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1050389560-192.168.56.180-1559204067205 on /home/FP/hadoop/datanode/current: 83ms
2019-05-31 11:49:18,561 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1050389560-192.168.56.180-1559204067205: 87ms
2019-05-31 11:49:18,563 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-05-31 11:49:18,563 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/replicas doesn't exist 
2019-05-31 11:49:18,563 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current: 0ms
2019-05-31 11:49:18,566 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 4ms
2019-05-31 11:49:18,791 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a): no suitable block pools found to scan.  Waiting 1747538019 ms.
2019-05-31 11:49:18,822 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 5/31/19 1:59 PM with interval of 21600000ms
2019-05-31 11:49:18,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-05-31 11:49:19,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-05-31 11:49:19,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-05-31 11:49:19,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xf7632cb863d25c8e,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 22 msec to generate and 265 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-31 11:49:19,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-31 11:51:55,077 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-05-31 11:51:59,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-05-31 11:51:59,617 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-05-31 11:51:59,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-05-31 11:58:21,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-05-31 11:58:21,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-05-31 11:58:21,997 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-05-31 11:58:22,861 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-05-31 11:58:22,986 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-05-31 11:58:23,161 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-05-31 11:58:23,161 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-05-31 11:58:23,171 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-31 11:58:23,173 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-05-31 11:58:23,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-05-31 11:58:23,176 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-05-31 11:58:23,176 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-05-31 11:58:23,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-05-31 11:58:23,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-05-31 11:58:23,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-05-31 11:58:23,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-05-31 11:58:23,460 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-05-31 11:58:23,487 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-05-31 11:58:23,544 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-05-31 11:58:23,571 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-05-31 11:58:23,576 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-05-31 11:58:23,577 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-05-31 11:58:23,577 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-05-31 11:58:23,646 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46558
2019-05-31 11:58:23,646 INFO org.mortbay.log: jetty-6.1.26
2019-05-31 11:58:24,559 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46558
2019-05-31 11:58:24,885 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-05-31 11:58:24,903 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-05-31 11:58:26,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-05-31 11:58:26,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-05-31 11:58:26,502 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-05-31 11:58:26,582 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-05-31 11:58:26,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-05-31 11:58:26,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-05-31 11:58:26,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-05-31 11:58:26,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-05-31 11:58:27,013 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-05-31 11:58:27,020 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-05-31 11:58:27,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-05-31 11:58:27,958 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-05-31 11:58:27,974 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 3624@master
2019-05-31 11:58:28,261 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1050389560-192.168.56.180-1559204067205
2019-05-31 11:58:28,261 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205
2019-05-31 11:58:28,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=825864606;bpid=BP-1050389560-192.168.56.180-1559204067205;lv=-57;nsInfo=lv=-63;cid=CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5;nsid=825864606;c=1559204067205;bpid=BP-1050389560-192.168.56.180-1559204067205;dnuuid=32039258-15d2-4d4a-ad40-f606c2429562
2019-05-31 11:58:28,419 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a
2019-05-31 11:58:28,419 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-05-31 11:58:28,434 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-05-31 11:58:28,456 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-05-31 11:58:28,487 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-05-31 11:58:28,488 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-31 11:58:28,499 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-05-31 11:58:28,538 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current: 32768
2019-05-31 11:58:28,604 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1050389560-192.168.56.180-1559204067205 on /home/FP/hadoop/datanode/current: 105ms
2019-05-31 11:58:28,604 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1050389560-192.168.56.180-1559204067205: 111ms
2019-05-31 11:58:28,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-05-31 11:58:28,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/replicas doesn't exist 
2019-05-31 11:58:28,617 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current: 0ms
2019-05-31 11:58:28,617 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 11ms
2019-05-31 11:58:28,833 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a): no suitable block pools found to scan.  Waiting 1746987977 ms.
2019-05-31 11:58:28,863 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 5/31/19 2:13 PM with interval of 21600000ms
2019-05-31 11:58:28,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-05-31 11:58:29,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-05-31 11:58:29,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-05-31 11:58:29,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x92a6f6e9399c0f85,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 13 msec to generate and 163 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-31 11:58:29,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-31 13:57:21,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x92a6f6e9399c0f86,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-05-31 13:57:21,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-05-31 14:13:19,868 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1050389560-192.168.56.180-1559204067205 Total blocks: 0, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-05-31 14:41:59,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741825_1001 src: /127.0.0.1:35004 dest: /127.0.0.1:50010
2019-05-31 14:42:00,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:35004, dest: /127.0.0.1:50010, bytes: 2310165, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1497048615_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741825_1001, duration(ns): 87771458
2019-05-31 14:42:00,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2019-06-03 09:35:53,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-03 09:35:53,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-03 09:35:53,987 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-03 09:35:54,953 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-03 09:35:55,127 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-03 09:35:55,435 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-03 09:35:55,435 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-03 09:35:55,479 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-03 09:35:55,493 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-03 09:35:55,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-03 09:35:55,503 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-03 09:35:55,503 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-03 09:35:55,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-03 09:35:55,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-03 09:35:55,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-03 09:35:55,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-03 09:35:55,991 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-03 09:35:56,034 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-03 09:35:56,127 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-03 09:35:56,165 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-03 09:35:56,180 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-03 09:35:56,181 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-03 09:35:56,184 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-03 09:35:56,240 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45042
2019-06-03 09:35:56,241 INFO org.mortbay.log: jetty-6.1.26
2019-06-03 09:35:57,405 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45042
2019-06-03 09:35:57,737 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-03 09:35:57,759 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-03 09:35:58,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-03 09:35:58,711 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-03 09:35:58,843 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-03 09:35:58,909 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-03 09:35:59,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-03 09:35:59,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-03 09:35:59,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-03 09:35:59,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-03 09:35:59,261 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-03 09:35:59,264 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-03 09:35:59,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-03 09:35:59,970 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-03 09:35:59,982 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 2362@master
2019-06-03 09:36:00,105 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1050389560-192.168.56.180-1559204067205
2019-06-03 09:36:00,105 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205
2019-06-03 09:36:00,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=825864606;bpid=BP-1050389560-192.168.56.180-1559204067205;lv=-57;nsInfo=lv=-63;cid=CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5;nsid=825864606;c=1559204067205;bpid=BP-1050389560-192.168.56.180-1559204067205;dnuuid=32039258-15d2-4d4a-ad40-f606c2429562
2019-06-03 09:36:00,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a
2019-06-03 09:36:00,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-03 09:36:00,322 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-03 09:36:00,341 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-03 09:36:00,378 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-03 09:36:00,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1050389560-192.168.56.180-1559204067205
2019-06-03 09:36:00,388 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-06-03 09:36:00,484 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1050389560-192.168.56.180-1559204067205 on /home/FP/hadoop/datanode/current: 95ms
2019-06-03 09:36:00,484 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1050389560-192.168.56.180-1559204067205: 101ms
2019-06-03 09:36:00,489 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current...
2019-06-03 09:36:00,489 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/replicas doesn't exist 
2019-06-03 09:36:00,504 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1050389560-192.168.56.180-1559204067205 on volume /home/FP/hadoop/datanode/current: 14ms
2019-06-03 09:36:00,504 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 18ms
2019-06-03 09:36:00,733 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-4557fb9b-b7c7-4542-b5fb-edd6747feb3a): no suitable block pools found to scan.  Waiting 1496336077 ms.
2019-06-03 09:36:00,768 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 3 오전 11:37 with interval of 21600000ms
2019-06-03 09:36:00,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-06-03 09:36:00,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1050389560-192.168.56.180-1559204067205 (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-06-03 09:36:00,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-03 09:36:01,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x92cc126b814f1c7b,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 19 msec to generate and 150 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-03 09:36:01,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-06-03 09:49:28,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x92cc126b814f1c7c,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-03 09:49:28,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-06-03 11:37:38,780 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1050389560-192.168.56.180-1559204067205 Total blocks: 1, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-03 15:49:29,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x92cc126b814f1c7d,  containing 1 storage report(s), of which we sent 1. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-03 15:49:29,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-06-03 16:24:31,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741826_1002 src: /127.0.0.1:49118 dest: /127.0.0.1:50010
2019-06-03 16:24:31,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49118, dest: /127.0.0.1:50010, bytes: 2310165, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2099087072_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741826_1002, duration(ns): 90152939
2019-06-03 16:24:31,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2019-06-03 17:08:50,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741827_1003 src: /127.0.0.1:49370 dest: /127.0.0.1:50010
2019-06-03 17:08:50,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49370, dest: /127.0.0.1:50010, bytes: 7169, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2099087072_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741827_1003, duration(ns): 1089923
2019-06-03 17:08:50,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2019-06-03 17:08:50,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741828_1004 src: /127.0.0.1:49374 dest: /127.0.0.1:50010
2019-06-03 17:08:51,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49374, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2099087072_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741828_1004, duration(ns): 639733946
2019-06-03 17:08:51,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2019-06-03 17:08:52,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741829_1005 src: /127.0.0.1:49376 dest: /127.0.0.1:50010
2019-06-03 17:08:52,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49376, dest: /127.0.0.1:50010, bytes: 236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2099087072_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741829_1005, duration(ns): 1065844
2019-06-03 17:08:52,178 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2019-06-03 17:08:52,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741830_1006 src: /127.0.0.1:49378 dest: /127.0.0.1:50010
2019-06-03 17:08:52,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49378, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2099087072_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741830_1006, duration(ns): 1099728
2019-06-03 17:08:52,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2019-06-03 17:08:52,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741831_1007 src: /127.0.0.1:49380 dest: /127.0.0.1:50010
2019-06-03 17:08:52,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49380, dest: /127.0.0.1:50010, bytes: 347920, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2099087072_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741831_1007, duration(ns): 64340457
2019-06-03 17:08:52,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2019-06-03 17:09:09,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741832_1008 src: /127.0.0.1:49396 dest: /127.0.0.1:50010
2019-06-03 17:09:09,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49396, dest: /127.0.0.1:50010, bytes: 393924, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-842881563_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741832_1008, duration(ns): 58899986
2019-06-03 17:09:09,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2019-06-03 17:09:19,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741833_1009 src: /127.0.0.1:49408 dest: /127.0.0.1:50010
2019-06-03 17:09:20,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49408, dest: /127.0.0.1:50010, bytes: 1404248, op: HDFS_WRITE, cliID: DFSClient_attempt_1559522198326_0001_m_000000_0_-79415601_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741833_1009, duration(ns): 667888658
2019-06-03 17:09:20,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2019-06-03 17:09:20,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741834_1010 src: /127.0.0.1:49410 dest: /127.0.0.1:50010
2019-06-03 17:09:20,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49410, dest: /127.0.0.1:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_1559522198326_0001_m_000000_0_-79415601_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741834_1010, duration(ns): 3145323
2019-06-03 17:09:20,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2019-06-03 17:09:20,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741835_1011 src: /127.0.0.1:49412 dest: /127.0.0.1:50010
2019-06-03 17:09:20,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49412, dest: /127.0.0.1:50010, bytes: 22925, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-842881563_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741835_1011, duration(ns): 67492534
2019-06-03 17:09:20,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2019-06-03 17:09:20,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741836_1012 src: /127.0.0.1:49414 dest: /127.0.0.1:50010
2019-06-03 17:09:20,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49414, dest: /127.0.0.1:50010, bytes: 375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-842881563_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741836_1012, duration(ns): 5882564
2019-06-03 17:09:20,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2019-06-03 17:09:20,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741837_1013 src: /127.0.0.1:49418 dest: /127.0.0.1:50010
2019-06-03 17:09:20,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49418, dest: /127.0.0.1:50010, bytes: 22925, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-842881563_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741837_1013, duration(ns): 1270976
2019-06-03 17:09:20,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2019-06-03 17:09:20,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741838_1014 src: /127.0.0.1:49420 dest: /127.0.0.1:50010
2019-06-03 17:09:20,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49420, dest: /127.0.0.1:50010, bytes: 393924, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-842881563_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741838_1014, duration(ns): 23330852
2019-06-03 17:09:20,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2019-06-03 17:09:24,842 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2019-06-03 17:09:24,848 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2019-06-03 17:09:24,848 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
2019-06-03 17:09:24,848 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2019-06-03 17:09:24,848 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2019-06-03 17:09:24,848 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741831 for deletion
2019-06-03 17:09:24,848 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
2019-06-03 17:09:24,849 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741835_1011 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2019-06-03 17:09:24,849 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741826_1002 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741826
2019-06-03 17:09:24,850 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741827_1003 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741827
2019-06-03 17:09:24,859 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741828_1004 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741828
2019-06-03 17:09:24,859 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741829_1005 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741829
2019-06-03 17:09:24,859 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741830_1006 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741830
2019-06-03 17:09:24,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741831_1007 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741831
2019-06-03 17:09:24,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741832_1008 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741832
2019-06-03 17:09:24,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741835_1011 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741835
2019-06-03 17:09:27,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741834_1010 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741834 for deletion
2019-06-03 17:09:27,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741834_1010 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741834
2019-06-03 17:37:38,774 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1050389560-192.168.56.180-1559204067205 Total blocks: 5, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-03 17:39:16,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741839_1015 src: /127.0.0.1:49814 dest: /127.0.0.1:50010
2019-06-03 17:39:16,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49814, dest: /127.0.0.1:50010, bytes: 2310165, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1897714218_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741839_1015, duration(ns): 66943149
2019-06-03 17:39:16,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2019-06-03 17:39:19,143 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2019-06-03 17:39:19,144 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741833_1009 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741833
2019-06-03 17:41:44,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741840_1016 src: /127.0.0.1:49830 dest: /127.0.0.1:50010
2019-06-03 17:41:44,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49830, dest: /127.0.0.1:50010, bytes: 7184, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1897714218_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741840_1016, duration(ns): 1620117
2019-06-03 17:41:44,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2019-06-03 17:41:46,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741841_1017 src: /127.0.0.1:49834 dest: /127.0.0.1:50010
2019-06-03 17:41:46,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49834, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1897714218_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741841_1017, duration(ns): 463357100
2019-06-03 17:41:46,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2019-06-03 17:41:46,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741842_1018 src: /127.0.0.1:49836 dest: /127.0.0.1:50010
2019-06-03 17:41:47,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49836, dest: /127.0.0.1:50010, bytes: 236, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1897714218_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741842_1018, duration(ns): 1418092
2019-06-03 17:41:47,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2019-06-03 17:41:47,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741843_1019 src: /127.0.0.1:49838 dest: /127.0.0.1:50010
2019-06-03 17:41:47,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49838, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1897714218_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741843_1019, duration(ns): 3605587
2019-06-03 17:41:47,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2019-06-03 17:41:47,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741844_1020 src: /127.0.0.1:49840 dest: /127.0.0.1:50010
2019-06-03 17:41:47,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49840, dest: /127.0.0.1:50010, bytes: 347878, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1897714218_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741844_1020, duration(ns): 49469322
2019-06-03 17:41:47,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2019-06-03 17:41:59,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741845_1021 src: /127.0.0.1:49858 dest: /127.0.0.1:50010
2019-06-03 17:41:59,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49858, dest: /127.0.0.1:50010, bytes: 393858, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-247796569_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741845_1021, duration(ns): 133007679
2019-06-03 17:41:59,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2019-06-03 17:42:09,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741846_1022 src: /127.0.0.1:49868 dest: /127.0.0.1:50010
2019-06-03 17:42:10,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49868, dest: /127.0.0.1:50010, bytes: 1404248, op: HDFS_WRITE, cliID: DFSClient_attempt_1559522198326_0002_m_000000_0_846631312_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741846_1022, duration(ns): 606785290
2019-06-03 17:42:10,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2019-06-03 17:42:10,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741847_1023 src: /127.0.0.1:49870 dest: /127.0.0.1:50010
2019-06-03 17:42:10,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49870, dest: /127.0.0.1:50010, bytes: 76, op: HDFS_WRITE, cliID: DFSClient_attempt_1559522198326_0002_m_000000_0_846631312_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741847_1023, duration(ns): 7552800
2019-06-03 17:42:10,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2019-06-03 17:42:10,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741848_1024 src: /127.0.0.1:49874 dest: /127.0.0.1:50010
2019-06-03 17:42:10,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49874, dest: /127.0.0.1:50010, bytes: 22925, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-247796569_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741848_1024, duration(ns): 86876105
2019-06-03 17:42:10,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2019-06-03 17:42:10,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741849_1025 src: /127.0.0.1:49876 dest: /127.0.0.1:50010
2019-06-03 17:42:10,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49876, dest: /127.0.0.1:50010, bytes: 375, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-247796569_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741849_1025, duration(ns): 14388417
2019-06-03 17:42:10,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2019-06-03 17:42:11,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741850_1026 src: /127.0.0.1:49880 dest: /127.0.0.1:50010
2019-06-03 17:42:11,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49880, dest: /127.0.0.1:50010, bytes: 22925, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-247796569_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741850_1026, duration(ns): 1427236
2019-06-03 17:42:11,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2019-06-03 17:42:11,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741851_1027 src: /127.0.0.1:49882 dest: /127.0.0.1:50010
2019-06-03 17:42:11,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49882, dest: /127.0.0.1:50010, bytes: 393858, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-247796569_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741851_1027, duration(ns): 18031347
2019-06-03 17:42:11,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2019-06-03 17:42:16,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741840_1016 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2019-06-03 17:42:16,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741841_1017 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2019-06-03 17:42:16,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2019-06-03 17:42:16,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2019-06-03 17:42:16,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741844_1020 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2019-06-03 17:42:16,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741845_1021 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741845 for deletion
2019-06-03 17:42:16,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741847_1023 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2019-06-03 17:42:16,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741848_1024 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741848 for deletion
2019-06-03 17:42:16,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741839_1015 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2019-06-03 17:42:16,176 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741840_1016 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741840
2019-06-03 17:42:16,182 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741841_1017 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741841
2019-06-03 17:42:16,182 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741842_1018 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741842
2019-06-03 17:42:16,182 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741843_1019 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741843
2019-06-03 17:42:16,182 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741844_1020 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741844
2019-06-03 17:42:16,183 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741845_1021 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741845
2019-06-03 17:42:16,183 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741847_1023 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741847
2019-06-03 17:42:16,183 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741848_1024 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741848
2019-06-03 17:42:16,183 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1050389560-192.168.56.180-1559204067205 blk_1073741839_1015 file /home/FP/hadoop/datanode/current/BP-1050389560-192.168.56.180-1559204067205/current/finalized/subdir0/subdir0/blk_1073741839
2019-06-03 21:49:27,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x92cc126b814f1c7e,  containing 1 storage report(s), of which we sent 1. The reports had 8 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-03 21:49:27,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-06-03 23:37:38,773 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1050389560-192.168.56.180-1559204067205 Total blocks: 8, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-04 03:49:28,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x92cc126b814f1c7f,  containing 1 storage report(s), of which we sent 1. The reports had 8 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-04 03:49:28,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-06-04 05:37:38,775 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1050389560-192.168.56.180-1559204067205 Total blocks: 8, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-04 09:49:28,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x92cc126b814f1c80,  containing 1 storage report(s), of which we sent 1. The reports had 8 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-04 09:49:28,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1050389560-192.168.56.180-1559204067205
2019-06-04 11:27:16,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741852_1028 src: /127.0.0.1:52938 dest: /127.0.0.1:50010
2019-06-04 11:27:16,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52938, dest: /127.0.0.1:50010, bytes: 1558456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2033385502_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741852_1028, duration(ns): 48479017
2019-06-04 11:27:16,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2019-06-04 11:27:29,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741853_1029 src: /127.0.0.1:52942 dest: /127.0.0.1:50010
2019-06-04 11:27:29,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52942, dest: /127.0.0.1:50010, bytes: 1558456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2033385502_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741853_1029, duration(ns): 23979260
2019-06-04 11:27:29,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2019-06-04 11:27:37,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741854_1030 src: /127.0.0.1:52944 dest: /127.0.0.1:50010
2019-06-04 11:27:37,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52944, dest: /127.0.0.1:50010, bytes: 1558456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2033385502_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741854_1030, duration(ns): 8640803
2019-06-04 11:27:37,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2019-06-04 11:27:43,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741855_1031 src: /127.0.0.1:52946 dest: /127.0.0.1:50010
2019-06-04 11:27:43,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52946, dest: /127.0.0.1:50010, bytes: 1558456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2033385502_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741855_1031, duration(ns): 10622669
2019-06-04 11:27:43,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2019-06-04 11:27:47,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741856_1032 src: /127.0.0.1:52948 dest: /127.0.0.1:50010
2019-06-04 11:27:47,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52948, dest: /127.0.0.1:50010, bytes: 1558456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2033385502_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741856_1032, duration(ns): 7104239
2019-06-04 11:27:47,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2019-06-04 11:28:00,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741857_1033 src: /127.0.0.1:52954 dest: /127.0.0.1:50010
2019-06-04 11:28:00,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52954, dest: /127.0.0.1:50010, bytes: 1558456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2033385502_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741857_1033, duration(ns): 16550439
2019-06-04 11:28:00,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2019-06-04 11:28:08,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741858_1034 src: /127.0.0.1:52956 dest: /127.0.0.1:50010
2019-06-04 11:28:08,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52956, dest: /127.0.0.1:50010, bytes: 1558456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2033385502_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741858_1034, duration(ns): 2106668
2019-06-04 11:28:08,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2019-06-04 11:28:14,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1050389560-192.168.56.180-1559204067205:blk_1073741859_1035 src: /127.0.0.1:52958 dest: /127.0.0.1:50010
2019-06-04 11:28:14,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52958, dest: /127.0.0.1:50010, bytes: 1558456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2033385502_1, offset: 0, srvID: 32039258-15d2-4d4a-ad40-f606c2429562, blockid: BP-1050389560-192.168.56.180-1559204067205:blk_1073741859_1035, duration(ns): 13135997
2019-06-04 11:28:14,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1050389560-192.168.56.180-1559204067205:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2019-06-04 11:37:38,779 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1050389560-192.168.56.180-1559204067205 Total blocks: 16, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-04 11:50:33,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-06-04 11:50:37,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-04 11:50:37,656 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-04 11:50:37,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 11:51:30,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 11:51:30,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 11:51:31,073 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 11:51:31,785 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 11:51:31,893 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 11:51:32,084 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 11:51:32,084 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 11:51:32,099 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 11:51:32,102 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 11:51:32,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 11:51:32,107 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 11:51:32,107 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 11:51:32,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 11:51:32,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 11:51:32,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 11:51:32,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 11:51:32,329 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 11:51:32,349 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 11:51:32,386 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 11:51:32,403 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 11:51:32,405 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 11:51:32,406 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 11:51:32,406 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 11:51:32,429 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46470
2019-06-04 11:51:32,429 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 11:51:33,360 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46470
2019-06-04 11:51:33,648 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 11:51:33,666 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 11:51:34,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 11:51:34,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 11:51:35,140 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 11:51:35,210 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 11:51:35,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 11:51:35,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 11:51:35,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 11:51:35,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 11:51:35,658 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 11:51:35,661 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 11:51:36,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 11:51:36,753 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 11:51:36,783 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 12043@master
2019-06-04 11:51:36,785 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/FP/hadoop/datanode/
java.io.IOException: Incompatible clusterIDs in /home/FP/hadoop-2.9.2/datanode: namenode clusterID = CID-398b8926-f56b-4c4c-872a-7f4e7867a62d; datanode clusterID = CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 11:51:36,794 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 11:51:36,804 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000
2019-06-04 11:51:36,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562)
2019-06-04 11:51:38,810 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-06-04 11:51:38,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 12:24:55,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 12:24:55,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 12:24:56,100 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 12:24:56,872 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 12:24:57,035 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 12:24:57,215 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 12:24:57,215 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 12:24:57,222 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 12:24:57,224 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 12:24:57,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 12:24:57,229 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 12:24:57,229 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 12:24:57,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 12:24:57,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 12:24:57,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 12:24:57,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 12:24:57,470 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 12:24:57,493 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 12:24:57,526 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 12:24:57,544 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 12:24:57,553 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 12:24:57,553 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 12:24:57,554 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 12:24:57,594 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39156
2019-06-04 12:24:57,594 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 12:24:58,348 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39156
2019-06-04 12:24:58,662 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 12:24:58,683 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 12:24:59,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 12:24:59,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 12:25:00,125 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 12:25:00,178 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 12:25:00,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 12:25:00,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 12:25:00,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 12:25:00,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 12:25:00,604 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 12:25:00,607 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 12:25:01,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 12:25:01,647 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 12:25:01,675 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 2738@master
2019-06-04 12:25:01,683 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/FP/hadoop/datanode/
java.io.IOException: Incompatible clusterIDs in /home/FP/hadoop-2.9.2/datanode: namenode clusterID = CID-81b9adf5-7615-45f5-ba00-9f37b31ccf34; datanode clusterID = CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 12:25:01,694 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 12:25:01,695 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000
2019-06-04 12:25:01,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562)
2019-06-04 12:25:03,707 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-06-04 12:25:03,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 13:40:59,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 13:40:59,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 13:41:00,582 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 13:41:01,322 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 13:41:01,468 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 13:41:01,715 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 13:41:01,715 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 13:41:01,726 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 13:41:01,737 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 13:41:01,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 13:41:01,746 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 13:41:01,746 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 13:41:01,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 13:41:01,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 13:41:01,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 13:41:01,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 13:41:02,096 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 13:41:02,120 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 13:41:02,165 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 13:41:02,182 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 13:41:02,185 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 13:41:02,189 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 13:41:02,189 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 13:41:02,218 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45296
2019-06-04 13:41:02,218 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 13:41:03,137 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45296
2019-06-04 13:41:03,503 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 13:41:03,524 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 13:41:04,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 13:41:04,732 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 13:41:04,909 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 13:41:04,978 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 13:41:05,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 13:41:05,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 13:41:05,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 13:41:05,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 13:41:05,455 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 13:41:05,459 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 13:41:06,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 13:41:06,175 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 13:41:06,189 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 2595@master
2019-06-04 13:41:06,193 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/FP/hadoop/datanode/
java.io.IOException: Incompatible clusterIDs in /home/FP/hadoop-2.9.2/datanode: namenode clusterID = CID-81b9adf5-7615-45f5-ba00-9f37b31ccf34; datanode clusterID = CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 13:41:06,201 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 13:41:06,202 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000
2019-06-04 13:41:06,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562)
2019-06-04 13:41:08,210 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-06-04 13:41:08,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 14:47:44,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 14:47:44,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 14:47:45,738 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 14:47:46,369 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 14:47:46,563 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 14:47:46,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 14:47:46,844 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 14:47:46,878 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 14:47:46,881 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 14:47:46,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 14:47:46,890 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 14:47:46,890 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 14:47:46,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 14:47:46,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 14:47:46,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 14:47:46,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 14:47:47,228 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 14:47:47,264 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 14:47:47,334 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 14:47:47,359 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 14:47:47,363 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 14:47:47,365 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 14:47:47,366 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 14:47:47,410 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40703
2019-06-04 14:47:47,410 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 14:47:48,542 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:40703
2019-06-04 14:47:48,889 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 14:47:48,909 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 14:47:50,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 14:47:50,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 14:47:50,418 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 14:47:50,506 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 14:47:50,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 14:47:50,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 14:47:50,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 14:47:50,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 14:47:50,876 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 14:47:50,877 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 14:47:51,634 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 14:47:51,644 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 14:47:51,662 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 2510@master
2019-06-04 14:47:51,669 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/FP/hadoop/datanode/
java.io.IOException: Incompatible clusterIDs in /home/FP/hadoop-2.9.2/datanode: namenode clusterID = CID-81b9adf5-7615-45f5-ba00-9f37b31ccf34; datanode clusterID = CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 14:47:51,680 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 14:47:51,683 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000
2019-06-04 14:47:51,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562)
2019-06-04 14:47:53,694 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-06-04 14:47:53,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 14:51:45,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 14:51:45,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 14:51:46,442 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 14:51:47,695 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 14:51:47,966 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 14:51:48,371 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 14:51:48,371 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 14:51:48,421 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 14:51:48,430 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 14:51:48,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 14:51:48,442 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 14:51:48,452 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 14:51:48,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 14:51:48,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 14:51:48,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 14:51:48,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 14:51:49,039 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 14:51:49,093 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 14:51:49,209 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 14:51:49,257 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 14:51:49,265 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 14:51:49,265 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 14:51:49,265 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 14:51:49,362 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44355
2019-06-04 14:51:49,362 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 14:51:50,838 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44355
2019-06-04 14:51:51,164 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 14:51:51,184 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 14:51:52,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 14:51:52,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 14:51:52,449 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 14:51:52,518 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 14:51:52,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 14:51:52,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 14:51:52,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 14:51:52,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 14:51:52,861 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 14:51:52,862 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 14:51:53,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 14:51:53,219 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 14:51:53,233 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 4103@master
2019-06-04 14:51:53,239 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/FP/hadoop/datanode/
java.io.IOException: Incompatible clusterIDs in /home/FP/hadoop-2.9.2/datanode: namenode clusterID = CID-81b9adf5-7615-45f5-ba00-9f37b31ccf34; datanode clusterID = CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 14:51:53,247 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 14:51:53,252 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000
2019-06-04 14:51:53,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562)
2019-06-04 14:51:55,260 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-06-04 14:51:55,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 14:57:54,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 14:57:54,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 14:57:55,158 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 14:57:56,572 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 14:57:56,834 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 14:57:57,208 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 14:57:57,208 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 14:57:57,233 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 14:57:57,235 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 14:57:57,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 14:57:57,250 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 14:57:57,250 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 14:57:57,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 14:57:57,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 14:57:57,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 14:57:57,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 14:57:57,715 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 14:57:57,747 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 14:57:57,829 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 14:57:57,857 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 14:57:57,873 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 14:57:57,875 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 14:57:57,875 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 14:57:57,952 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38756
2019-06-04 14:57:57,952 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 14:57:59,146 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38756
2019-06-04 14:57:59,396 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 14:57:59,409 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 14:58:00,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 14:58:00,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 14:58:00,567 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 14:58:00,624 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 14:58:00,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 14:58:00,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 14:58:00,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 14:58:00,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 14:58:00,975 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 14:58:00,979 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 14:58:01,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 14:58:01,851 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 14:58:01,886 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 6184@master
2019-06-04 14:58:01,888 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/FP/hadoop/datanode/
java.io.IOException: Incompatible clusterIDs in /home/FP/hadoop-2.9.2/datanode: namenode clusterID = CID-81b9adf5-7615-45f5-ba00-9f37b31ccf34; datanode clusterID = CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 14:58:01,902 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 14:58:01,908 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000
2019-06-04 14:58:01,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562)
2019-06-04 14:58:03,914 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-06-04 14:58:03,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 15:02:40,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 15:02:40,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 15:02:40,728 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 15:02:41,466 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 15:02:41,595 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 15:02:41,776 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 15:02:41,776 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 15:02:41,787 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:02:41,793 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 15:02:41,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 15:02:41,801 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:02:41,801 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 15:02:41,806 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 15:02:41,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 15:02:41,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 15:02:41,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 15:02:42,020 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 15:02:42,037 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 15:02:42,075 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 15:02:42,089 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 15:02:42,093 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 15:02:42,096 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 15:02:42,097 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 15:02:42,135 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43465
2019-06-04 15:02:42,135 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 15:02:42,596 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43465
2019-06-04 15:02:42,884 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 15:02:42,900 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 15:02:43,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 15:02:43,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 15:02:44,238 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 15:02:44,303 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 15:02:44,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 15:02:44,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 15:02:44,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 15:02:44,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 15:02:44,777 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 15:02:44,779 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 15:02:45,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 15:02:45,893 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 15:02:45,924 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 8049@master
2019-06-04 15:02:45,926 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/FP/hadoop/datanode/
java.io.IOException: Incompatible clusterIDs in /home/FP/hadoop-2.9.2/datanode: namenode clusterID = CID-a517c20a-73ed-4f82-9a63-2f60ccca046d; datanode clusterID = CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 15:02:45,941 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 15:02:45,943 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000
2019-06-04 15:02:45,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562)
2019-06-04 15:02:47,955 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-06-04 15:02:47,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 15:05:27,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 15:05:27,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 15:05:28,041 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 15:05:28,608 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 15:05:28,718 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 15:05:28,893 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 15:05:28,893 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 15:05:28,900 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:05:28,903 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 15:05:28,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 15:05:28,907 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:05:28,907 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 15:05:28,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 15:05:28,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 15:05:28,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 15:05:28,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 15:05:29,143 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 15:05:29,164 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 15:05:29,201 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 15:05:29,218 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 15:05:29,222 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 15:05:29,222 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 15:05:29,222 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 15:05:29,256 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41326
2019-06-04 15:05:29,256 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 15:05:29,771 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41326
2019-06-04 15:05:29,888 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 15:05:29,905 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 15:05:30,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 15:05:30,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 15:05:30,837 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 15:05:30,894 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 15:05:31,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 15:05:31,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 15:05:31,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 15:05:31,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 15:05:31,386 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 15:05:31,390 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 15:05:31,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 15:05:31,860 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 15:05:31,895 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 9680@master
2019-06-04 15:05:31,897 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/FP/hadoop/datanode/
java.io.IOException: Incompatible clusterIDs in /home/FP/hadoop-2.9.2/datanode: namenode clusterID = CID-a517c20a-73ed-4f82-9a63-2f60ccca046d; datanode clusterID = CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 15:05:31,909 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 15:05:31,910 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000
2019-06-04 15:05:31,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562)
2019-06-04 15:05:33,920 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-06-04 15:05:33,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 15:06:13,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 15:06:13,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 15:06:14,362 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 15:06:14,948 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 15:06:15,031 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 15:06:15,185 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 15:06:15,185 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 15:06:15,193 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:06:15,196 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 15:06:15,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 15:06:15,199 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:06:15,199 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 15:06:15,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 15:06:15,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 15:06:15,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 15:06:15,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 15:06:15,387 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 15:06:15,408 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 15:06:15,440 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 15:06:15,452 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 15:06:15,457 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 15:06:15,457 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 15:06:15,458 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 15:06:15,496 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44310
2019-06-04 15:06:15,496 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 15:06:16,023 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44310
2019-06-04 15:06:16,136 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 15:06:16,149 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 15:06:16,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 15:06:16,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 15:06:16,823 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 15:06:16,867 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 15:06:17,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 15:06:17,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 15:06:17,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 15:06:17,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 15:06:17,212 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 15:06:17,215 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 15:06:17,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 15:06:17,586 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 15:06:17,604 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 10673@master
2019-06-04 15:06:17,609 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/home/FP/hadoop/datanode/
java.io.IOException: Incompatible clusterIDs in /home/FP/hadoop-2.9.2/datanode: namenode clusterID = CID-a517c20a-73ed-4f82-9a63-2f60ccca046d; datanode clusterID = CID-60c7bcad-6853-468f-bdaf-fee7107eb8e5
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.doTransition(DataStorage.java:760)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:293)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 15:06:17,623 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-06-04 15:06:17,631 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562) service to localhost/127.0.0.1:9000
2019-06-04 15:06:17,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid 32039258-15d2-4d4a-ad40-f606c2429562)
2019-06-04 15:06:19,637 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-06-04 15:06:19,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 15:09:10,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 15:09:10,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 15:09:11,457 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 15:09:12,204 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 15:09:12,342 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 15:09:12,500 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 15:09:12,500 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 15:09:12,510 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:09:12,516 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 15:09:12,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 15:09:12,522 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:09:12,523 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 15:09:12,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 15:09:12,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 15:09:12,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 15:09:12,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 15:09:12,739 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 15:09:12,762 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 15:09:12,798 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 15:09:12,811 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 15:09:12,815 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 15:09:12,815 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 15:09:12,816 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 15:09:12,834 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43534
2019-06-04 15:09:12,834 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 15:09:13,338 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43534
2019-06-04 15:09:13,450 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 15:09:13,461 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 15:09:14,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 15:09:14,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 15:09:14,425 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 15:09:14,513 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 15:09:14,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 15:09:14,844 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 15:09:14,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 15:09:14,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 15:09:14,988 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 15:09:14,993 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 15:09:15,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 15:09:15,521 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 15:09:15,551 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 11665@master
2019-06-04 15:09:15,552 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /home/FP/hadoop/datanode is not formatted for namespace 534211926. Formatting...
2019-06-04 15:09:15,552 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-68688a0c-d7d9-4ad9-b231-896fc82bab6e for directory /home/FP/hadoop/datanode
2019-06-04 15:09:15,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1809874864-192.168.56.180-1559627915474
2019-06-04 15:09:15,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-1809874864-192.168.56.180-1559627915474
2019-06-04 15:09:15,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /home/FP/hadoop/datanode/current/BP-1809874864-192.168.56.180-1559627915474 is not formatted for BP-1809874864-192.168.56.180-1559627915474. Formatting ...
2019-06-04 15:09:15,728 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1809874864-192.168.56.180-1559627915474 directory /home/FP/hadoop/datanode/current/BP-1809874864-192.168.56.180-1559627915474/current
2019-06-04 15:09:15,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=534211926;bpid=BP-1809874864-192.168.56.180-1559627915474;lv=-57;nsInfo=lv=-63;cid=CID-a517c20a-73ed-4f82-9a63-2f60ccca046d;nsid=534211926;c=1559627915474;bpid=BP-1809874864-192.168.56.180-1559627915474;dnuuid=null
2019-06-04 15:09:15,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 2fd3b880-28f8-4c64-85ec-2d6dd518329a
2019-06-04 15:09:15,980 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-68688a0c-d7d9-4ad9-b231-896fc82bab6e
2019-06-04 15:09:15,980 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-04 15:09:16,000 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-04 15:09:16,035 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-04 15:09:16,076 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-04 15:09:16,078 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1809874864-192.168.56.180-1559627915474
2019-06-04 15:09:16,081 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1809874864-192.168.56.180-1559627915474 on volume /home/FP/hadoop/datanode/current...
2019-06-04 15:09:16,186 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1809874864-192.168.56.180-1559627915474 on /home/FP/hadoop/datanode/current: 105ms
2019-06-04 15:09:16,188 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1809874864-192.168.56.180-1559627915474: 111ms
2019-06-04 15:09:16,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1809874864-192.168.56.180-1559627915474 on volume /home/FP/hadoop/datanode/current...
2019-06-04 15:09:16,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-1809874864-192.168.56.180-1559627915474/current/replicas doesn't exist 
2019-06-04 15:09:16,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1809874864-192.168.56.180-1559627915474 on volume /home/FP/hadoop/datanode/current: 1ms
2019-06-04 15:09:16,199 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 10ms
2019-06-04 15:09:16,201 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1809874864-192.168.56.180-1559627915474 on volume /home/FP/hadoop/datanode
2019-06-04 15:09:16,202 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-68688a0c-d7d9-4ad9-b231-896fc82bab6e): finished scanning block pool BP-1809874864-192.168.56.180-1559627915474
2019-06-04 15:09:16,262 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 4 오후 8:04 with interval of 21600000ms
2019-06-04 15:09:16,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1809874864-192.168.56.180-1559627915474 (Datanode Uuid 2fd3b880-28f8-4c64-85ec-2d6dd518329a) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-06-04 15:09:16,390 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-68688a0c-d7d9-4ad9-b231-896fc82bab6e): no suitable block pools found to scan.  Waiting 1814399811 ms.
2019-06-04 15:09:16,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1809874864-192.168.56.180-1559627915474 (Datanode Uuid 2fd3b880-28f8-4c64-85ec-2d6dd518329a) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-06-04 15:09:16,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-04 15:09:17,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xc40886affa2af0bf,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 20 msec to generate and 179 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-04 15:09:17,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1809874864-192.168.56.180-1559627915474
2019-06-04 15:13:42,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 15:13:42,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 15:13:42,886 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 15:13:43,611 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 15:13:43,732 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 15:13:43,918 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 15:13:43,918 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 15:13:43,931 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:13:43,933 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 15:13:43,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 15:13:43,937 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:13:43,937 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 15:13:43,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 15:13:43,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 15:13:44,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 15:13:44,001 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 15:13:44,151 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 15:13:44,175 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 15:13:44,215 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 15:13:44,234 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 15:13:44,237 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 15:13:44,238 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 15:13:44,238 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 15:13:44,262 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36901
2019-06-04 15:13:44,262 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 15:13:45,039 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:36901
2019-06-04 15:13:45,337 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 15:13:45,358 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 15:13:46,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 15:13:46,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 15:13:46,824 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 15:13:46,893 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 15:13:47,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 15:13:47,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 15:13:47,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 15:13:47,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 15:13:47,399 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 15:13:47,403 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 15:13:48,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 15:13:48,552 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 15:13:48,576 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 2150@master
2019-06-04 15:13:48,576 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /home/FP/hadoop/datanode is not formatted for namespace 1394054448. Formatting...
2019-06-04 15:13:48,577 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9 for directory /home/FP/hadoop/datanode
2019-06-04 15:13:48,772 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-04 15:13:48,772 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-04 15:13:48,773 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602 is not formatted for BP-176234095-192.168.56.180-1559628803602. Formatting ...
2019-06-04 15:13:48,773 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-176234095-192.168.56.180-1559628803602 directory /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current
2019-06-04 15:13:48,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=null
2019-06-04 15:13:48,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-04 15:13:49,029 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-04 15:13:49,029 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-04 15:13:49,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-04 15:13:49,052 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-04 15:13:49,072 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-04 15:13:49,074 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-04 15:13:49,079 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-04 15:13:49,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 60ms
2019-06-04 15:13:49,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 66ms
2019-06-04 15:13:49,145 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-04 15:13:49,145 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-04 15:13:49,145 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 0ms
2019-06-04 15:13:49,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 8ms
2019-06-04 15:13:49,150 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode
2019-06-04 15:13:49,151 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): finished scanning block pool BP-176234095-192.168.56.180-1559628803602
2019-06-04 15:13:49,184 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 4 오후 6:18 with interval of 21600000ms
2019-06-04 15:13:49,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-06-04 15:13:49,302 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 1814399848 ms.
2019-06-04 15:13:49,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-06-04 15:13:49,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-04 15:13:49,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xa3437ca9c745d49c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 12 msec to generate and 140 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-04 15:13:49,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-04 15:14:10,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-06-04 15:14:12,756 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-04 15:14:12,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-04 15:14:46,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-04 15:14:46,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-04 15:14:47,112 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-04 15:14:47,796 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-04 15:14:47,911 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-04 15:14:48,081 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-04 15:14:48,081 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-04 15:14:48,088 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:14:48,091 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-04 15:14:48,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-04 15:14:48,094 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-04 15:14:48,094 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-04 15:14:48,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-04 15:14:48,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-04 15:14:48,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-04 15:14:48,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-04 15:14:48,317 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-04 15:14:48,352 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-04 15:14:48,392 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-04 15:14:48,407 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-04 15:14:48,410 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-04 15:14:48,410 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-04 15:14:48,411 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-04 15:14:48,443 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34533
2019-06-04 15:14:48,443 INFO org.mortbay.log: jetty-6.1.26
2019-06-04 15:14:49,138 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34533
2019-06-04 15:14:49,414 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-04 15:14:49,428 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-04 15:14:50,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-04 15:14:50,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-04 15:14:50,709 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-04 15:14:50,785 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-04 15:14:51,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-04 15:14:51,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-04 15:14:51,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-04 15:14:51,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-04 15:14:51,285 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-04 15:14:51,292 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-04 15:14:52,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-04 15:14:52,455 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-04 15:14:52,489 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 3048@master
2019-06-04 15:14:52,689 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-04 15:14:52,689 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-04 15:14:52,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-04 15:14:52,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-04 15:14:52,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-04 15:14:52,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-04 15:14:52,903 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-04 15:14:52,942 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-04 15:14:52,951 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-04 15:14:52,959 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-04 15:14:53,003 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current: 24576
2019-06-04 15:14:53,075 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 116ms
2019-06-04 15:14:53,077 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 125ms
2019-06-04 15:14:53,080 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-04 15:14:53,080 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-04 15:14:53,080 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 0ms
2019-06-04 15:14:53,080 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 2ms
2019-06-04 15:14:53,245 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 1814335905 ms.
2019-06-04 15:14:53,275 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 4 오후 6:35 with interval of 21600000ms
2019-06-04 15:14:53,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-06-04 15:14:53,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-06-04 15:14:53,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-04 15:14:53,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a04,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 134 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-04 15:14:53,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-04 15:16:24,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741825_1001 src: /127.0.0.1:55038 dest: /127.0.0.1:50010
2019-06-04 15:16:38,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741826_1002 src: /127.0.0.1:55058 dest: /127.0.0.1:50010
2019-06-04 15:16:38,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55058, dest: /127.0.0.1:50010, bytes: 428996, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1027778952_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741826_1002, duration(ns): 74302381
2019-06-04 15:16:38,946 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2019-06-04 15:16:48,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741827_1003 src: /127.0.0.1:55062 dest: /127.0.0.1:50010
2019-06-04 15:16:48,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55062, dest: /127.0.0.1:50010, bytes: 428996, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1027778952_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741827_1003, duration(ns): 13192423
2019-06-04 15:16:48,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2019-06-04 15:17:03,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741828_1004 src: /127.0.0.1:55074 dest: /127.0.0.1:50010
2019-06-04 15:17:03,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55074, dest: /127.0.0.1:50010, bytes: 428996, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1027778952_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741828_1004, duration(ns): 19157486
2019-06-04 15:17:03,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2019-06-04 15:17:08,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741829_1005 src: /127.0.0.1:55078 dest: /127.0.0.1:50010
2019-06-04 15:17:08,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55078, dest: /127.0.0.1:50010, bytes: 428996, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1027778952_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741829_1005, duration(ns): 4359179
2019-06-04 15:17:08,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2019-06-04 15:17:19,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741830_1006 src: /127.0.0.1:55082 dest: /127.0.0.1:50010
2019-06-04 15:17:19,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55082, dest: /127.0.0.1:50010, bytes: 428996, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1027778952_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741830_1006, duration(ns): 7145759
2019-06-04 15:17:19,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2019-06-04 15:19:10,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55038, dest: /127.0.0.1:50010, bytes: 9, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_578613633_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741825_1001, duration(ns): 166069748904
2019-06-04 15:19:10,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2019-06-04 15:19:13,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741831_1007 src: /127.0.0.1:55114 dest: /127.0.0.1:50010
2019-06-04 15:22:23,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55114, dest: /127.0.0.1:50010, bytes: 9, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_578613633_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741831_1007, duration(ns): 190036448636
2019-06-04 15:22:23,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2019-06-04 15:22:26,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741832_1008 src: /127.0.0.1:55160 dest: /127.0.0.1:50010
2019-06-04 15:27:04,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741833_1009 src: /127.0.0.1:55232 dest: /127.0.0.1:50010
2019-06-04 15:27:04,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55232, dest: /127.0.0.1:50010, bytes: 428996, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1445602606_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741833_1009, duration(ns): 30743975
2019-06-04 15:27:04,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2019-06-04 15:29:38,648 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2019-06-04 15:29:38,649 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741833_1009 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741833
2019-06-04 15:30:36,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741834_1010 src: /127.0.0.1:55316 dest: /127.0.0.1:50010
2019-06-04 15:30:36,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55316, dest: /127.0.0.1:50010, bytes: 428996, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741834_1010, duration(ns): 31567683
2019-06-04 15:30:36,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2019-06-04 15:32:23,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55160, dest: /127.0.0.1:50010, bytes: 9, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_578613633_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741832_1008, duration(ns): 596987995648
2019-06-04 15:32:23,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:17,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741835_1011 src: /127.0.0.1:55364 dest: /127.0.0.1:50010
2019-06-04 15:37:17,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55364, dest: /127.0.0.1:50010, bytes: 4774, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741835_1011, duration(ns): 1167210
2019-06-04 15:37:17,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:17,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741836_1012 src: /127.0.0.1:55366 dest: /127.0.0.1:50010
2019-06-04 15:37:17,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55366, dest: /127.0.0.1:50010, bytes: 5098, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741836_1012, duration(ns): 1217950
2019-06-04 15:37:17,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:18,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741837_1013 src: /127.0.0.1:55370 dest: /127.0.0.1:50010
2019-06-04 15:37:19,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55370, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741837_1013, duration(ns): 579432687
2019-06-04 15:37:19,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:19,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741838_1014 src: /127.0.0.1:55372 dest: /127.0.0.1:50010
2019-06-04 15:37:19,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55372, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741838_1014, duration(ns): 933360
2019-06-04 15:37:19,671 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:19,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741839_1015 src: /127.0.0.1:55374 dest: /127.0.0.1:50010
2019-06-04 15:37:19,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55374, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741839_1015, duration(ns): 2751928
2019-06-04 15:37:19,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:19,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741840_1016 src: /127.0.0.1:55376 dest: /127.0.0.1:50010
2019-06-04 15:37:19,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55376, dest: /127.0.0.1:50010, bytes: 344831, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741840_1016, duration(ns): 28839800
2019-06-04 15:37:19,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:34,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741841_1017 src: /127.0.0.1:55400 dest: /127.0.0.1:50010
2019-06-04 15:37:34,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55400, dest: /127.0.0.1:50010, bytes: 390403, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_655617345_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741841_1017, duration(ns): 109554066
2019-06-04 15:37:34,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:45,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741842_1018 src: /127.0.0.1:55410 dest: /127.0.0.1:50010
2019-06-04 15:37:55,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741843_1019 src: /127.0.0.1:55422 dest: /127.0.0.1:50010
2019-06-04 15:37:55,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55422, dest: /127.0.0.1:50010, bytes: 200, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0001_r_000000_0_-825941027_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741843_1019, duration(ns): 21022678
2019-06-04 15:37:55,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:55,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55410, dest: /127.0.0.1:50010, bytes: 35391, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_655617345_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741842_1018, duration(ns): 10019429655
2019-06-04 15:37:55,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:55,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741844_1020 src: /127.0.0.1:55424 dest: /127.0.0.1:50010
2019-06-04 15:37:55,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55424, dest: /127.0.0.1:50010, bytes: 391, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_655617345_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741844_1020, duration(ns): 3493377
2019-06-04 15:37:55,657 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:55,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741845_1021 src: /127.0.0.1:55428 dest: /127.0.0.1:50010
2019-06-04 15:37:55,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55428, dest: /127.0.0.1:50010, bytes: 35391, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_655617345_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741845_1021, duration(ns): 3251016
2019-06-04 15:37:55,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:55,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741846_1022 src: /127.0.0.1:55430 dest: /127.0.0.1:50010
2019-06-04 15:37:55,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55430, dest: /127.0.0.1:50010, bytes: 390403, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_655617345_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741846_1022, duration(ns): 35197257
2019-06-04 15:37:55,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2019-06-04 15:37:59,713 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741840_1016 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2019-06-04 15:37:59,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741841_1017 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2019-06-04 15:37:59,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2019-06-04 15:37:59,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2019-06-04 15:37:59,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741835_1011 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2019-06-04 15:37:59,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741836_1012 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2019-06-04 15:37:59,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2019-06-04 15:37:59,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741838_1014 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2019-06-04 15:37:59,714 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741839_1015 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2019-06-04 15:37:59,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741840_1016 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741840
2019-06-04 15:37:59,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741841_1017 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741841
2019-06-04 15:37:59,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741842_1018 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741842
2019-06-04 15:37:59,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741843_1019 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741843
2019-06-04 15:37:59,715 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741835_1011 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741835
2019-06-04 15:37:59,716 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741836_1012 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741836
2019-06-04 15:37:59,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741837_1013 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741837
2019-06-04 15:37:59,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741838_1014 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741838
2019-06-04 15:37:59,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741839_1015 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741839
2019-06-04 15:38:22,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741847_1023 src: /127.0.0.1:55444 dest: /127.0.0.1:50010
2019-06-04 15:38:22,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55444, dest: /127.0.0.1:50010, bytes: 4390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741847_1023, duration(ns): 1107338
2019-06-04 15:38:22,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:22,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741848_1024 src: /127.0.0.1:55446 dest: /127.0.0.1:50010
2019-06-04 15:38:22,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55446, dest: /127.0.0.1:50010, bytes: 4536, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741848_1024, duration(ns): 1086200
2019-06-04 15:38:22,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:22,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741849_1025 src: /127.0.0.1:55450 dest: /127.0.0.1:50010
2019-06-04 15:38:22,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55450, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741849_1025, duration(ns): 376872971
2019-06-04 15:38:22,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:23,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741850_1026 src: /127.0.0.1:55452 dest: /127.0.0.1:50010
2019-06-04 15:38:23,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55452, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741850_1026, duration(ns): 1191392
2019-06-04 15:38:23,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:23,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741851_1027 src: /127.0.0.1:55454 dest: /127.0.0.1:50010
2019-06-04 15:38:23,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55454, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741851_1027, duration(ns): 3462648
2019-06-04 15:38:23,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:23,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741852_1028 src: /127.0.0.1:55456 dest: /127.0.0.1:50010
2019-06-04 15:38:23,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55456, dest: /127.0.0.1:50010, bytes: 344809, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741852_1028, duration(ns): 19721382
2019-06-04 15:38:23,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:34,520 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741853_1029 src: /127.0.0.1:55476 dest: /127.0.0.1:50010
2019-06-04 15:38:34,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55476, dest: /127.0.0.1:50010, bytes: 390381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_311511624_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741853_1029, duration(ns): 37617036
2019-06-04 15:38:34,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:44,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741854_1030 src: /127.0.0.1:55488 dest: /127.0.0.1:50010
2019-06-04 15:38:52,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741855_1031 src: /127.0.0.1:55500 dest: /127.0.0.1:50010
2019-06-04 15:38:52,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55500, dest: /127.0.0.1:50010, bytes: 135, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0002_r_000000_0_-1777806837_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741855_1031, duration(ns): 6655286
2019-06-04 15:38:52,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:53,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55488, dest: /127.0.0.1:50010, bytes: 35363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_311511624_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741854_1030, duration(ns): 8953365515
2019-06-04 15:38:53,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:53,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741856_1032 src: /127.0.0.1:55502 dest: /127.0.0.1:50010
2019-06-04 15:38:53,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55502, dest: /127.0.0.1:50010, bytes: 391, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_311511624_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741856_1032, duration(ns): 1186691
2019-06-04 15:38:53,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:53,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741857_1033 src: /127.0.0.1:55506 dest: /127.0.0.1:50010
2019-06-04 15:38:53,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55506, dest: /127.0.0.1:50010, bytes: 35363, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_311511624_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741857_1033, duration(ns): 6921899
2019-06-04 15:38:53,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:53,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741858_1034 src: /127.0.0.1:55508 dest: /127.0.0.1:50010
2019-06-04 15:38:53,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55508, dest: /127.0.0.1:50010, bytes: 390381, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_311511624_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741858_1034, duration(ns): 22323021
2019-06-04 15:38:53,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2019-06-04 15:38:56,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741849_1025 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741849 for deletion
2019-06-04 15:38:56,721 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741850_1026 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2019-06-04 15:38:56,721 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741851_1027 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2019-06-04 15:38:56,721 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741852_1028 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2019-06-04 15:38:56,721 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741853_1029 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741853 for deletion
2019-06-04 15:38:56,721 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741854_1030 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741854 for deletion
2019-06-04 15:38:56,726 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741849_1025 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741849
2019-06-04 15:38:56,726 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741850_1026 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741850
2019-06-04 15:38:56,726 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741851_1027 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741851
2019-06-04 15:38:56,726 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741852_1028 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741852
2019-06-04 15:38:56,726 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741853_1029 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741853
2019-06-04 15:38:56,726 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741854_1030 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741854
2019-06-04 15:38:59,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741847_1023 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2019-06-04 15:38:59,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741848_1024 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741848 for deletion
2019-06-04 15:38:59,720 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741855_1031 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2019-06-04 15:38:59,722 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741847_1023 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741847
2019-06-04 15:38:59,722 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741848_1024 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741848
2019-06-04 15:38:59,722 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741855_1031 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741855
2019-06-04 15:39:52,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741859_1035 src: /127.0.0.1:55520 dest: /127.0.0.1:50010
2019-06-04 15:39:52,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55520, dest: /127.0.0.1:50010, bytes: 4646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741859_1035, duration(ns): 962479
2019-06-04 15:39:52,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2019-06-04 15:39:52,098 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741860_1036 src: /127.0.0.1:55522 dest: /127.0.0.1:50010
2019-06-04 15:39:52,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55522, dest: /127.0.0.1:50010, bytes: 5078, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741860_1036, duration(ns): 1370296
2019-06-04 15:39:52,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2019-06-04 15:39:52,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741861_1037 src: /127.0.0.1:55526 dest: /127.0.0.1:50010
2019-06-04 15:39:52,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55526, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741861_1037, duration(ns): 320901691
2019-06-04 15:39:52,517 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2019-06-04 15:39:52,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741862_1038 src: /127.0.0.1:55528 dest: /127.0.0.1:50010
2019-06-04 15:39:52,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55528, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741862_1038, duration(ns): 1128652
2019-06-04 15:39:52,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2019-06-04 15:39:52,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741863_1039 src: /127.0.0.1:55530 dest: /127.0.0.1:50010
2019-06-04 15:39:52,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55530, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741863_1039, duration(ns): 933995
2019-06-04 15:39:52,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2019-06-04 15:39:53,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741864_1040 src: /127.0.0.1:55532 dest: /127.0.0.1:50010
2019-06-04 15:39:53,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55532, dest: /127.0.0.1:50010, bytes: 344827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741864_1040, duration(ns): 12613517
2019-06-04 15:39:53,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2019-06-04 15:40:04,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741865_1041 src: /127.0.0.1:55556 dest: /127.0.0.1:50010
2019-06-04 15:40:04,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55556, dest: /127.0.0.1:50010, bytes: 390399, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2057146783_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741865_1041, duration(ns): 93767504
2019-06-04 15:40:04,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2019-06-04 15:40:14,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741866_1042 src: /127.0.0.1:55570 dest: /127.0.0.1:50010
2019-06-04 15:40:23,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741867_1043 src: /127.0.0.1:55582 dest: /127.0.0.1:50010
2019-06-04 15:40:23,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55582, dest: /127.0.0.1:50010, bytes: 133, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0003_r_000000_0_706573890_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741867_1043, duration(ns): 13969369
2019-06-04 15:40:23,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2019-06-04 15:40:24,028 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55570, dest: /127.0.0.1:50010, bytes: 35369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2057146783_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741866_1042, duration(ns): 9725796668
2019-06-04 15:40:24,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2019-06-04 15:40:25,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741868_1044 src: /127.0.0.1:55584 dest: /127.0.0.1:50010
2019-06-04 15:40:25,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55584, dest: /127.0.0.1:50010, bytes: 391, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2057146783_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741868_1044, duration(ns): 1662950
2019-06-04 15:40:25,074 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2019-06-04 15:40:25,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741869_1045 src: /127.0.0.1:55588 dest: /127.0.0.1:50010
2019-06-04 15:40:25,163 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55588, dest: /127.0.0.1:50010, bytes: 35369, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2057146783_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741869_1045, duration(ns): 1157809
2019-06-04 15:40:25,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2019-06-04 15:40:25,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741870_1046 src: /127.0.0.1:55590 dest: /127.0.0.1:50010
2019-06-04 15:40:25,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55590, dest: /127.0.0.1:50010, bytes: 390399, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2057146783_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741870_1046, duration(ns): 5253654
2019-06-04 15:40:25,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2019-06-04 15:40:29,732 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2019-06-04 15:40:29,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2019-06-04 15:40:29,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2019-06-04 15:40:29,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2019-06-04 15:40:29,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741863_1039 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741863 for deletion
2019-06-04 15:40:29,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741864_1040 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741864 for deletion
2019-06-04 15:40:29,733 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741865_1041 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741865 for deletion
2019-06-04 15:40:29,734 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741866_1042 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741866 for deletion
2019-06-04 15:40:29,734 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741867_1043 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741867 for deletion
2019-06-04 15:40:29,735 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741859_1035 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741859
2019-06-04 15:40:29,736 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741860_1036 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741860
2019-06-04 15:40:29,740 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741861_1037 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741861
2019-06-04 15:40:29,740 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741862_1038 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741862
2019-06-04 15:40:29,741 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741863_1039 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741863
2019-06-04 15:40:29,741 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741864_1040 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741864
2019-06-04 15:40:29,746 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741865_1041 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741865
2019-06-04 15:40:29,746 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741866_1042 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741866
2019-06-04 15:40:29,746 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741867_1043 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741867
2019-06-04 15:48:33,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741871_1047 src: /127.0.0.1:55618 dest: /127.0.0.1:50010
2019-06-04 15:48:33,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55618, dest: /127.0.0.1:50010, bytes: 4646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741871_1047, duration(ns): 984307
2019-06-04 15:48:33,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2019-06-04 15:48:33,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741872_1048 src: /127.0.0.1:55620 dest: /127.0.0.1:50010
2019-06-04 15:48:33,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55620, dest: /127.0.0.1:50010, bytes: 4861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741872_1048, duration(ns): 2806804
2019-06-04 15:48:33,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741872_1048, type=LAST_IN_PIPELINE terminating
2019-06-04 15:48:33,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741873_1049 src: /127.0.0.1:55624 dest: /127.0.0.1:50010
2019-06-04 15:48:33,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55624, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741873_1049, duration(ns): 302407803
2019-06-04 15:48:33,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741873_1049, type=LAST_IN_PIPELINE terminating
2019-06-04 15:48:34,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741874_1050 src: /127.0.0.1:55626 dest: /127.0.0.1:50010
2019-06-04 15:48:34,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55626, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741874_1050, duration(ns): 1158925
2019-06-04 15:48:34,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741874_1050, type=LAST_IN_PIPELINE terminating
2019-06-04 15:48:34,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741875_1051 src: /127.0.0.1:55628 dest: /127.0.0.1:50010
2019-06-04 15:48:34,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55628, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741875_1051, duration(ns): 2008651
2019-06-04 15:48:34,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741875_1051, type=LAST_IN_PIPELINE terminating
2019-06-04 15:48:34,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741876_1052 src: /127.0.0.1:55630 dest: /127.0.0.1:50010
2019-06-04 15:48:34,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55630, dest: /127.0.0.1:50010, bytes: 344847, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741876_1052, duration(ns): 22397923
2019-06-04 15:48:34,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741876_1052, type=LAST_IN_PIPELINE terminating
2019-06-04 15:48:45,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741877_1053 src: /127.0.0.1:55652 dest: /127.0.0.1:50010
2019-06-04 15:48:45,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55652, dest: /127.0.0.1:50010, bytes: 390419, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175772777_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741877_1053, duration(ns): 39098309
2019-06-04 15:48:45,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741877_1053, type=LAST_IN_PIPELINE terminating
2019-06-04 15:48:54,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741878_1054 src: /127.0.0.1:55662 dest: /127.0.0.1:50010
2019-06-04 15:49:03,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741879_1055 src: /127.0.0.1:55676 dest: /127.0.0.1:50010
2019-06-04 15:49:03,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55676, dest: /127.0.0.1:50010, bytes: 143, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0004_r_000000_0_676246905_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741879_1055, duration(ns): 7035345
2019-06-04 15:49:03,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741879_1055, type=LAST_IN_PIPELINE terminating
2019-06-04 15:49:03,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55662, dest: /127.0.0.1:50010, bytes: 35373, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175772777_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741878_1054, duration(ns): 8996923245
2019-06-04 15:49:03,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741878_1054, type=LAST_IN_PIPELINE terminating
2019-06-04 15:49:03,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741880_1056 src: /127.0.0.1:55678 dest: /127.0.0.1:50010
2019-06-04 15:49:03,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55678, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175772777_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741880_1056, duration(ns): 1227890
2019-06-04 15:49:03,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741880_1056, type=LAST_IN_PIPELINE terminating
2019-06-04 15:49:03,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741881_1057 src: /127.0.0.1:55682 dest: /127.0.0.1:50010
2019-06-04 15:49:03,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55682, dest: /127.0.0.1:50010, bytes: 35373, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175772777_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741881_1057, duration(ns): 1302477
2019-06-04 15:49:03,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741881_1057, type=LAST_IN_PIPELINE terminating
2019-06-04 15:49:03,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741882_1058 src: /127.0.0.1:55684 dest: /127.0.0.1:50010
2019-06-04 15:49:03,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55684, dest: /127.0.0.1:50010, bytes: 390419, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1175772777_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741882_1058, duration(ns): 19927076
2019-06-04 15:49:03,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741882_1058, type=LAST_IN_PIPELINE terminating
2019-06-04 15:49:08,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741872_1048 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741872 for deletion
2019-06-04 15:49:08,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741873_1049 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741873 for deletion
2019-06-04 15:49:08,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741874_1050 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741874 for deletion
2019-06-04 15:49:08,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741875_1051 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741875 for deletion
2019-06-04 15:49:08,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741876_1052 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741876 for deletion
2019-06-04 15:49:08,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741877_1053 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741877 for deletion
2019-06-04 15:49:08,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741878_1054 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741878 for deletion
2019-06-04 15:49:08,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741879_1055 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741879 for deletion
2019-06-04 15:49:08,826 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741871_1047 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741871 for deletion
2019-06-04 15:49:08,827 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741872_1048 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741872
2019-06-04 15:49:08,831 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741873_1049 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741873
2019-06-04 15:49:08,831 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741874_1050 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741874
2019-06-04 15:49:08,831 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741875_1051 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741875
2019-06-04 15:49:08,831 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741876_1052 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741876
2019-06-04 15:49:08,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741877_1053 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741877
2019-06-04 15:49:08,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741878_1054 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741878
2019-06-04 15:49:08,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741879_1055 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741879
2019-06-04 15:49:08,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741871_1047 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741871
2019-06-04 16:07:46,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741883_1059 src: /127.0.0.1:55736 dest: /127.0.0.1:50010
2019-06-04 16:07:46,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55736, dest: /127.0.0.1:50010, bytes: 4646, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741883_1059, duration(ns): 980328
2019-06-04 16:07:46,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741883_1059, type=LAST_IN_PIPELINE terminating
2019-06-04 16:07:46,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741884_1060 src: /127.0.0.1:55738 dest: /127.0.0.1:50010
2019-06-04 16:07:46,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55738, dest: /127.0.0.1:50010, bytes: 4868, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741884_1060, duration(ns): 927132
2019-06-04 16:07:46,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741884_1060, type=LAST_IN_PIPELINE terminating
2019-06-04 16:07:46,628 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741885_1061 src: /127.0.0.1:55742 dest: /127.0.0.1:50010
2019-06-04 16:07:46,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55742, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741885_1061, duration(ns): 353305726
2019-06-04 16:07:46,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741885_1061, type=LAST_IN_PIPELINE terminating
2019-06-04 16:07:47,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741886_1062 src: /127.0.0.1:55744 dest: /127.0.0.1:50010
2019-06-04 16:07:47,432 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55744, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741886_1062, duration(ns): 979519
2019-06-04 16:07:47,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741886_1062, type=LAST_IN_PIPELINE terminating
2019-06-04 16:07:47,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741887_1063 src: /127.0.0.1:55746 dest: /127.0.0.1:50010
2019-06-04 16:07:47,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55746, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741887_1063, duration(ns): 976860
2019-06-04 16:07:47,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741887_1063, type=LAST_IN_PIPELINE terminating
2019-06-04 16:07:47,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741888_1064 src: /127.0.0.1:55748 dest: /127.0.0.1:50010
2019-06-04 16:07:47,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55748, dest: /127.0.0.1:50010, bytes: 344850, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741888_1064, duration(ns): 7176988
2019-06-04 16:07:47,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741888_1064, type=LAST_IN_PIPELINE terminating
2019-06-04 16:07:58,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741889_1065 src: /127.0.0.1:55772 dest: /127.0.0.1:50010
2019-06-04 16:07:58,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55772, dest: /127.0.0.1:50010, bytes: 390422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_965292263_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741889_1065, duration(ns): 82556436
2019-06-04 16:07:58,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741889_1065, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:09,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741890_1066 src: /127.0.0.1:55782 dest: /127.0.0.1:50010
2019-06-04 16:08:18,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741891_1067 src: /127.0.0.1:55794 dest: /127.0.0.1:50010
2019-06-04 16:08:18,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55794, dest: /127.0.0.1:50010, bytes: 143, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0005_r_000000_0_-13211649_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741891_1067, duration(ns): 15182421
2019-06-04 16:08:18,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741891_1067, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:19,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55782, dest: /127.0.0.1:50010, bytes: 35374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_965292263_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741890_1066, duration(ns): 10065711069
2019-06-04 16:08:19,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741890_1066, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:19,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741892_1068 src: /127.0.0.1:55796 dest: /127.0.0.1:50010
2019-06-04 16:08:19,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55796, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_965292263_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741892_1068, duration(ns): 1418055
2019-06-04 16:08:19,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741892_1068, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:19,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741893_1069 src: /127.0.0.1:55800 dest: /127.0.0.1:50010
2019-06-04 16:08:19,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55800, dest: /127.0.0.1:50010, bytes: 35374, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_965292263_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741893_1069, duration(ns): 1025227
2019-06-04 16:08:19,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741893_1069, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:19,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741894_1070 src: /127.0.0.1:55802 dest: /127.0.0.1:50010
2019-06-04 16:08:19,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55802, dest: /127.0.0.1:50010, bytes: 390422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_965292263_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741894_1070, duration(ns): 17299353
2019-06-04 16:08:19,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741894_1070, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:24,037 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741888_1064 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741888 for deletion
2019-06-04 16:08:24,037 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741889_1065 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741889 for deletion
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741890_1066 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741890 for deletion
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741891_1067 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741891 for deletion
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741883_1059 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741883 for deletion
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741884_1060 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741884 for deletion
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741885_1061 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741885 for deletion
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741886_1062 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741886 for deletion
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741887_1063 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741887 for deletion
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741888_1064 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741888
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741889_1065 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741889
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741890_1066 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741890
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741891_1067 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741891
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741883_1059 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741883
2019-06-04 16:08:24,038 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741884_1060 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741884
2019-06-04 16:08:24,043 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741885_1061 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741885
2019-06-04 16:08:24,043 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741886_1062 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741886
2019-06-04 16:08:24,043 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741887_1063 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741887
2019-06-04 16:08:57,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741895_1071 src: /127.0.0.1:55814 dest: /127.0.0.1:50010
2019-06-04 16:08:57,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55814, dest: /127.0.0.1:50010, bytes: 5110, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741895_1071, duration(ns): 972695
2019-06-04 16:08:57,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741895_1071, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:57,587 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741896_1072 src: /127.0.0.1:55816 dest: /127.0.0.1:50010
2019-06-04 16:08:57,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55816, dest: /127.0.0.1:50010, bytes: 5422, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741896_1072, duration(ns): 1431450
2019-06-04 16:08:57,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741896_1072, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:57,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741897_1073 src: /127.0.0.1:55820 dest: /127.0.0.1:50010
2019-06-04 16:08:58,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55820, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741897_1073, duration(ns): 307542478
2019-06-04 16:08:58,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741897_1073, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:58,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741898_1074 src: /127.0.0.1:55824 dest: /127.0.0.1:50010
2019-06-04 16:08:58,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55824, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741898_1074, duration(ns): 1094203
2019-06-04 16:08:58,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741898_1074, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:58,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741899_1075 src: /127.0.0.1:55826 dest: /127.0.0.1:50010
2019-06-04 16:08:58,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55826, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741899_1075, duration(ns): 1066523
2019-06-04 16:08:58,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741899_1075, type=LAST_IN_PIPELINE terminating
2019-06-04 16:08:58,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741900_1076 src: /127.0.0.1:55828 dest: /127.0.0.1:50010
2019-06-04 16:08:58,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55828, dest: /127.0.0.1:50010, bytes: 344909, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741900_1076, duration(ns): 19750964
2019-06-04 16:08:58,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741900_1076, type=LAST_IN_PIPELINE terminating
2019-06-04 16:09:10,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741901_1077 src: /127.0.0.1:55850 dest: /127.0.0.1:50010
2019-06-04 16:09:10,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55850, dest: /127.0.0.1:50010, bytes: 390481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1459226614_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741901_1077, duration(ns): 64744322
2019-06-04 16:09:10,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741901_1077, type=LAST_IN_PIPELINE terminating
2019-06-04 16:09:19,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741902_1078 src: /127.0.0.1:55860 dest: /127.0.0.1:50010
2019-06-04 16:09:28,663 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741903_1079 src: /127.0.0.1:55872 dest: /127.0.0.1:50010
2019-06-04 16:09:28,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55872, dest: /127.0.0.1:50010, bytes: 180, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0006_r_000000_0_2044032400_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741903_1079, duration(ns): 15236635
2019-06-04 16:09:28,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741903_1079, type=LAST_IN_PIPELINE terminating
2019-06-04 16:09:28,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55860, dest: /127.0.0.1:50010, bytes: 35406, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1459226614_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741902_1078, duration(ns): 9504619928
2019-06-04 16:09:28,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741902_1078, type=LAST_IN_PIPELINE terminating
2019-06-04 16:09:28,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741904_1080 src: /127.0.0.1:55874 dest: /127.0.0.1:50010
2019-06-04 16:09:28,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55874, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1459226614_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741904_1080, duration(ns): 4276856
2019-06-04 16:09:28,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741904_1080, type=LAST_IN_PIPELINE terminating
2019-06-04 16:09:29,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741905_1081 src: /127.0.0.1:55878 dest: /127.0.0.1:50010
2019-06-04 16:09:29,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55878, dest: /127.0.0.1:50010, bytes: 35406, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1459226614_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741905_1081, duration(ns): 1847865
2019-06-04 16:09:29,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741905_1081, type=LAST_IN_PIPELINE terminating
2019-06-04 16:09:29,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741906_1082 src: /127.0.0.1:55880 dest: /127.0.0.1:50010
2019-06-04 16:09:29,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55880, dest: /127.0.0.1:50010, bytes: 390481, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1459226614_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741906_1082, duration(ns): 15561855
2019-06-04 16:09:29,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741906_1082, type=LAST_IN_PIPELINE terminating
2019-06-04 16:09:33,042 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741895_1071 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741895 for deletion
2019-06-04 16:09:33,042 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741896_1072 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741896 for deletion
2019-06-04 16:09:33,042 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741897_1073 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741897 for deletion
2019-06-04 16:09:33,042 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741898_1074 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741898 for deletion
2019-06-04 16:09:33,042 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741899_1075 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741899 for deletion
2019-06-04 16:09:33,042 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741900_1076 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741900 for deletion
2019-06-04 16:09:33,042 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741901_1077 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741901 for deletion
2019-06-04 16:09:33,044 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741902_1078 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741902 for deletion
2019-06-04 16:09:33,044 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741903_1079 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741903 for deletion
2019-06-04 16:09:33,045 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741895_1071 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741895
2019-06-04 16:09:33,045 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741896_1072 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741896
2019-06-04 16:09:33,049 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741897_1073 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741897
2019-06-04 16:09:33,049 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741898_1074 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741898
2019-06-04 16:09:33,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741899_1075 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741899
2019-06-04 16:09:33,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741900_1076 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741900
2019-06-04 16:09:33,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741901_1077 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741901
2019-06-04 16:09:33,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741902_1078 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741902
2019-06-04 16:09:33,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741903_1079 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741903
2019-06-04 16:11:56,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741907_1083 src: /127.0.0.1:55896 dest: /127.0.0.1:50010
2019-06-04 16:11:56,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55896, dest: /127.0.0.1:50010, bytes: 5233, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741907_1083, duration(ns): 868027
2019-06-04 16:11:56,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741907_1083, type=LAST_IN_PIPELINE terminating
2019-06-04 16:11:56,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741908_1084 src: /127.0.0.1:55898 dest: /127.0.0.1:50010
2019-06-04 16:11:56,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55898, dest: /127.0.0.1:50010, bytes: 5546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741908_1084, duration(ns): 3922557
2019-06-04 16:11:56,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741908_1084, type=LAST_IN_PIPELINE terminating
2019-06-04 16:11:56,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741909_1085 src: /127.0.0.1:55902 dest: /127.0.0.1:50010
2019-06-04 16:11:56,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55902, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741909_1085, duration(ns): 176793471
2019-06-04 16:11:56,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741909_1085, type=LAST_IN_PIPELINE terminating
2019-06-04 16:11:56,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741910_1086 src: /127.0.0.1:55904 dest: /127.0.0.1:50010
2019-06-04 16:11:56,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55904, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741910_1086, duration(ns): 1008055
2019-06-04 16:11:56,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741910_1086, type=LAST_IN_PIPELINE terminating
2019-06-04 16:11:56,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741911_1087 src: /127.0.0.1:55906 dest: /127.0.0.1:50010
2019-06-04 16:11:56,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55906, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741911_1087, duration(ns): 1101403
2019-06-04 16:11:56,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741911_1087, type=LAST_IN_PIPELINE terminating
2019-06-04 16:11:56,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741912_1088 src: /127.0.0.1:55908 dest: /127.0.0.1:50010
2019-06-04 16:11:56,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55908, dest: /127.0.0.1:50010, bytes: 344940, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741912_1088, duration(ns): 7877578
2019-06-04 16:11:56,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741912_1088, type=LAST_IN_PIPELINE terminating
2019-06-04 16:12:09,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741913_1089 src: /127.0.0.1:55934 dest: /127.0.0.1:50010
2019-06-04 16:12:09,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55934, dest: /127.0.0.1:50010, bytes: 390512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-961545212_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741913_1089, duration(ns): 47134295
2019-06-04 16:12:09,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741913_1089, type=LAST_IN_PIPELINE terminating
2019-06-04 16:12:20,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741914_1090 src: /127.0.0.1:55944 dest: /127.0.0.1:50010
2019-06-04 16:12:29,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741915_1091 src: /127.0.0.1:55956 dest: /127.0.0.1:50010
2019-06-04 16:12:29,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55956, dest: /127.0.0.1:50010, bytes: 180, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0007_r_000000_0_-1010780940_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741915_1091, duration(ns): 16089656
2019-06-04 16:12:29,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741915_1091, type=LAST_IN_PIPELINE terminating
2019-06-04 16:12:30,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55944, dest: /127.0.0.1:50010, bytes: 35420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-961545212_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741914_1090, duration(ns): 9985618107
2019-06-04 16:12:30,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741914_1090, type=LAST_IN_PIPELINE terminating
2019-06-04 16:12:30,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741916_1092 src: /127.0.0.1:55958 dest: /127.0.0.1:50010
2019-06-04 16:12:30,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55958, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-961545212_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741916_1092, duration(ns): 1202917
2019-06-04 16:12:30,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741916_1092, type=LAST_IN_PIPELINE terminating
2019-06-04 16:12:30,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741917_1093 src: /127.0.0.1:55962 dest: /127.0.0.1:50010
2019-06-04 16:12:30,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55962, dest: /127.0.0.1:50010, bytes: 35420, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-961545212_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741917_1093, duration(ns): 1256004
2019-06-04 16:12:30,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741917_1093, type=LAST_IN_PIPELINE terminating
2019-06-04 16:12:30,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741918_1094 src: /127.0.0.1:55964 dest: /127.0.0.1:50010
2019-06-04 16:12:30,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55964, dest: /127.0.0.1:50010, bytes: 390512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-961545212_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741918_1094, duration(ns): 20679095
2019-06-04 16:12:30,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741918_1094, type=LAST_IN_PIPELINE terminating
2019-06-04 16:12:36,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741907_1083 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741907 for deletion
2019-06-04 16:12:36,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741908_1084 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741908 for deletion
2019-06-04 16:12:36,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741909_1085 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741909 for deletion
2019-06-04 16:12:36,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741910_1086 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741910 for deletion
2019-06-04 16:12:36,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741911_1087 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741911 for deletion
2019-06-04 16:12:36,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741912_1088 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741912 for deletion
2019-06-04 16:12:36,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741913_1089 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741913 for deletion
2019-06-04 16:12:36,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741914_1090 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741914 for deletion
2019-06-04 16:12:36,066 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741915_1091 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741915 for deletion
2019-06-04 16:12:36,067 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741907_1083 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741907
2019-06-04 16:12:36,067 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741908_1084 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741908
2019-06-04 16:12:36,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741909_1085 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741909
2019-06-04 16:12:36,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741910_1086 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741910
2019-06-04 16:12:36,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741911_1087 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741911
2019-06-04 16:12:36,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741912_1088 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741912
2019-06-04 16:12:36,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741913_1089 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741913
2019-06-04 16:12:36,071 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741914_1090 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741914
2019-06-04 16:12:36,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741915_1091 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741915
2019-06-04 16:13:39,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741919_1095 src: /127.0.0.1:55978 dest: /127.0.0.1:50010
2019-06-04 16:13:39,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55978, dest: /127.0.0.1:50010, bytes: 5233, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741919_1095, duration(ns): 1329617
2019-06-04 16:13:39,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741919_1095, type=LAST_IN_PIPELINE terminating
2019-06-04 16:13:39,097 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741920_1096 src: /127.0.0.1:55980 dest: /127.0.0.1:50010
2019-06-04 16:13:39,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55980, dest: /127.0.0.1:50010, bytes: 6012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741920_1096, duration(ns): 1180590
2019-06-04 16:13:39,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741920_1096, type=LAST_IN_PIPELINE terminating
2019-06-04 16:13:39,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741921_1097 src: /127.0.0.1:55984 dest: /127.0.0.1:50010
2019-06-04 16:13:39,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55984, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741921_1097, duration(ns): 268046377
2019-06-04 16:13:39,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741921_1097, type=LAST_IN_PIPELINE terminating
2019-06-04 16:13:39,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741922_1098 src: /127.0.0.1:55986 dest: /127.0.0.1:50010
2019-06-04 16:13:39,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55986, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741922_1098, duration(ns): 987275
2019-06-04 16:13:39,932 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741922_1098, type=LAST_IN_PIPELINE terminating
2019-06-04 16:13:39,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741923_1099 src: /127.0.0.1:55988 dest: /127.0.0.1:50010
2019-06-04 16:13:39,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55988, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741923_1099, duration(ns): 985791
2019-06-04 16:13:39,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741923_1099, type=LAST_IN_PIPELINE terminating
2019-06-04 16:13:40,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741924_1100 src: /127.0.0.1:55990 dest: /127.0.0.1:50010
2019-06-04 16:13:40,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:55990, dest: /127.0.0.1:50010, bytes: 344958, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741924_1100, duration(ns): 217841631
2019-06-04 16:13:40,302 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741924_1100, type=LAST_IN_PIPELINE terminating
2019-06-04 16:13:51,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741925_1101 src: /127.0.0.1:56010 dest: /127.0.0.1:50010
2019-06-04 16:13:51,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56010, dest: /127.0.0.1:50010, bytes: 390530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_350375621_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741925_1101, duration(ns): 34303432
2019-06-04 16:13:51,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741925_1101, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:03,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741926_1102 src: /127.0.0.1:56026 dest: /127.0.0.1:50010
2019-06-04 16:14:14,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741927_1103 src: /127.0.0.1:56038 dest: /127.0.0.1:50010
2019-06-04 16:14:14,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56038, dest: /127.0.0.1:50010, bytes: 151, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0008_r_000000_0_-1568646746_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741927_1103, duration(ns): 17278135
2019-06-04 16:14:14,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741927_1103, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:14,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56026, dest: /127.0.0.1:50010, bytes: 35431, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_350375621_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741926_1102, duration(ns): 10955713122
2019-06-04 16:14:14,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741926_1102, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:14,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741928_1104 src: /127.0.0.1:56042 dest: /127.0.0.1:50010
2019-06-04 16:14:14,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56042, dest: /127.0.0.1:50010, bytes: 393, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_350375621_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741928_1104, duration(ns): 11740891
2019-06-04 16:14:14,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741928_1104, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:14,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741929_1105 src: /127.0.0.1:56046 dest: /127.0.0.1:50010
2019-06-04 16:14:14,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56046, dest: /127.0.0.1:50010, bytes: 35431, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_350375621_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741929_1105, duration(ns): 1653562
2019-06-04 16:14:14,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741929_1105, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:14,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741930_1106 src: /127.0.0.1:56048 dest: /127.0.0.1:50010
2019-06-04 16:14:14,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56048, dest: /127.0.0.1:50010, bytes: 390530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_350375621_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741930_1106, duration(ns): 19058811
2019-06-04 16:14:14,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741930_1106, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:18,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741921_1097 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741921 for deletion
2019-06-04 16:14:18,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741922_1098 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741922 for deletion
2019-06-04 16:14:18,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741923_1099 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741923 for deletion
2019-06-04 16:14:18,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741924_1100 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741924 for deletion
2019-06-04 16:14:18,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741925_1101 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741925 for deletion
2019-06-04 16:14:18,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741926_1102 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741926 for deletion
2019-06-04 16:14:18,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741921_1097 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741921
2019-06-04 16:14:18,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741922_1098 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741922
2019-06-04 16:14:18,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741923_1099 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741923
2019-06-04 16:14:18,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741924_1100 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741924
2019-06-04 16:14:18,092 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741925_1101 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741925
2019-06-04 16:14:18,092 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741926_1102 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741926
2019-06-04 16:14:21,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741920_1096 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741920 for deletion
2019-06-04 16:14:21,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741927_1103 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741927 for deletion
2019-06-04 16:14:21,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741919_1095 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741919 for deletion
2019-06-04 16:14:21,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741920_1096 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741920
2019-06-04 16:14:21,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741927_1103 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741927
2019-06-04 16:14:21,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741919_1095 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741919
2019-06-04 16:14:24,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741931_1107 src: /127.0.0.1:56056 dest: /127.0.0.1:50010
2019-06-04 16:14:24,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56056, dest: /127.0.0.1:50010, bytes: 5233, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741931_1107, duration(ns): 1615436
2019-06-04 16:14:24,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741931_1107, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:24,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741932_1108 src: /127.0.0.1:56058 dest: /127.0.0.1:50010
2019-06-04 16:14:24,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56058, dest: /127.0.0.1:50010, bytes: 6012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741932_1108, duration(ns): 980802
2019-06-04 16:14:24,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741932_1108, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:24,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741933_1109 src: /127.0.0.1:56062 dest: /127.0.0.1:50010
2019-06-04 16:14:24,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56062, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741933_1109, duration(ns): 273939377
2019-06-04 16:14:24,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741933_1109, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:25,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741934_1110 src: /127.0.0.1:56064 dest: /127.0.0.1:50010
2019-06-04 16:14:25,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56064, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741934_1110, duration(ns): 934153
2019-06-04 16:14:25,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741934_1110, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:25,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741935_1111 src: /127.0.0.1:56066 dest: /127.0.0.1:50010
2019-06-04 16:14:25,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56066, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741935_1111, duration(ns): 861876
2019-06-04 16:14:25,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741935_1111, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:25,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741936_1112 src: /127.0.0.1:56068 dest: /127.0.0.1:50010
2019-06-04 16:14:25,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56068, dest: /127.0.0.1:50010, bytes: 344958, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741936_1112, duration(ns): 9848885
2019-06-04 16:14:25,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741936_1112, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:37,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741937_1113 src: /127.0.0.1:56088 dest: /127.0.0.1:50010
2019-06-04 16:14:37,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56088, dest: /127.0.0.1:50010, bytes: 390530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1556479315_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741937_1113, duration(ns): 67470212
2019-06-04 16:14:37,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741937_1113, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:46,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741938_1114 src: /127.0.0.1:56098 dest: /127.0.0.1:50010
2019-06-04 16:14:57,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741939_1115 src: /127.0.0.1:56110 dest: /127.0.0.1:50010
2019-06-04 16:14:57,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56110, dest: /127.0.0.1:50010, bytes: 151, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0009_r_000000_0_99510769_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741939_1115, duration(ns): 11159567
2019-06-04 16:14:57,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741939_1115, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:58,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56098, dest: /127.0.0.1:50010, bytes: 35426, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1556479315_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741938_1114, duration(ns): 11138504515
2019-06-04 16:14:58,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741938_1114, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:58,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741940_1116 src: /127.0.0.1:56114 dest: /127.0.0.1:50010
2019-06-04 16:14:58,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56114, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1556479315_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741940_1116, duration(ns): 2882859
2019-06-04 16:14:58,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741940_1116, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:58,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741941_1117 src: /127.0.0.1:56118 dest: /127.0.0.1:50010
2019-06-04 16:14:58,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56118, dest: /127.0.0.1:50010, bytes: 35426, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1556479315_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741941_1117, duration(ns): 885880
2019-06-04 16:14:58,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741941_1117, type=LAST_IN_PIPELINE terminating
2019-06-04 16:14:58,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741942_1118 src: /127.0.0.1:56120 dest: /127.0.0.1:50010
2019-06-04 16:14:58,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56120, dest: /127.0.0.1:50010, bytes: 390530, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1556479315_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741942_1118, duration(ns): 17982577
2019-06-04 16:14:58,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741942_1118, type=LAST_IN_PIPELINE terminating
2019-06-04 16:15:03,092 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741936_1112 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741936 for deletion
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741937_1113 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741937 for deletion
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741938_1114 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741938 for deletion
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741939_1115 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741939 for deletion
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741931_1107 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741931 for deletion
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741932_1108 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741932 for deletion
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741933_1109 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741933 for deletion
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741934_1110 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741934 for deletion
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741935_1111 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741935 for deletion
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741936_1112 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741936
2019-06-04 16:15:03,093 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741937_1113 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741937
2019-06-04 16:15:03,094 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741938_1114 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741938
2019-06-04 16:15:03,094 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741939_1115 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741939
2019-06-04 16:15:03,094 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741931_1107 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741931
2019-06-04 16:15:03,094 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741932_1108 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741932
2019-06-04 16:15:03,098 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741933_1109 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741933
2019-06-04 16:15:03,098 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741934_1110 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741934
2019-06-04 16:15:03,098 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741935_1111 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741935
2019-06-04 16:15:49,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741943_1119 src: /127.0.0.1:56134 dest: /127.0.0.1:50010
2019-06-04 16:15:49,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56134, dest: /127.0.0.1:50010, bytes: 5284, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741943_1119, duration(ns): 1114849
2019-06-04 16:15:49,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741943_1119, type=LAST_IN_PIPELINE terminating
2019-06-04 16:15:49,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741944_1120 src: /127.0.0.1:56136 dest: /127.0.0.1:50010
2019-06-04 16:15:49,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56136, dest: /127.0.0.1:50010, bytes: 6063, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741944_1120, duration(ns): 788745
2019-06-04 16:15:49,508 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741944_1120, type=LAST_IN_PIPELINE terminating
2019-06-04 16:15:49,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741945_1121 src: /127.0.0.1:56140 dest: /127.0.0.1:50010
2019-06-04 16:15:49,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56140, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741945_1121, duration(ns): 293902799
2019-06-04 16:15:49,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741945_1121, type=LAST_IN_PIPELINE terminating
2019-06-04 16:15:50,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741946_1122 src: /127.0.0.1:56142 dest: /127.0.0.1:50010
2019-06-04 16:15:50,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56142, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741946_1122, duration(ns): 1383431
2019-06-04 16:15:50,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741946_1122, type=LAST_IN_PIPELINE terminating
2019-06-04 16:15:50,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741947_1123 src: /127.0.0.1:56144 dest: /127.0.0.1:50010
2019-06-04 16:15:50,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56144, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741947_1123, duration(ns): 4348604
2019-06-04 16:15:50,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741947_1123, type=LAST_IN_PIPELINE terminating
2019-06-04 16:15:50,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741948_1124 src: /127.0.0.1:56146 dest: /127.0.0.1:50010
2019-06-04 16:15:50,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56146, dest: /127.0.0.1:50010, bytes: 344989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741948_1124, duration(ns): 24445887
2019-06-04 16:15:50,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741948_1124, type=LAST_IN_PIPELINE terminating
2019-06-04 16:16:01,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741949_1125 src: /127.0.0.1:56166 dest: /127.0.0.1:50010
2019-06-04 16:16:01,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56166, dest: /127.0.0.1:50010, bytes: 390561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1746500084_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741949_1125, duration(ns): 71311058
2019-06-04 16:16:01,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741949_1125, type=LAST_IN_PIPELINE terminating
2019-06-04 16:16:11,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741950_1126 src: /127.0.0.1:56180 dest: /127.0.0.1:50010
2019-06-04 16:16:22,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741951_1127 src: /127.0.0.1:56192 dest: /127.0.0.1:50010
2019-06-04 16:16:22,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56192, dest: /127.0.0.1:50010, bytes: 151, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0010_r_000000_0_-1086543112_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741951_1127, duration(ns): 10194937
2019-06-04 16:16:22,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741951_1127, type=LAST_IN_PIPELINE terminating
2019-06-04 16:16:22,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56180, dest: /127.0.0.1:50010, bytes: 35440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1746500084_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741950_1126, duration(ns): 11130639019
2019-06-04 16:16:22,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741950_1126, type=LAST_IN_PIPELINE terminating
2019-06-04 16:16:22,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741952_1128 src: /127.0.0.1:56196 dest: /127.0.0.1:50010
2019-06-04 16:16:22,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56196, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1746500084_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741952_1128, duration(ns): 1243864
2019-06-04 16:16:22,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741952_1128, type=LAST_IN_PIPELINE terminating
2019-06-04 16:16:22,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741953_1129 src: /127.0.0.1:56200 dest: /127.0.0.1:50010
2019-06-04 16:16:22,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56200, dest: /127.0.0.1:50010, bytes: 35440, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1746500084_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741953_1129, duration(ns): 857074
2019-06-04 16:16:22,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741953_1129, type=LAST_IN_PIPELINE terminating
2019-06-04 16:16:22,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741954_1130 src: /127.0.0.1:56202 dest: /127.0.0.1:50010
2019-06-04 16:16:22,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56202, dest: /127.0.0.1:50010, bytes: 390561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1746500084_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741954_1130, duration(ns): 18024207
2019-06-04 16:16:22,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741954_1130, type=LAST_IN_PIPELINE terminating
2019-06-04 16:16:27,109 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741943_1119 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741943 for deletion
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741944_1120 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741944 for deletion
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741945_1121 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741945 for deletion
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741946_1122 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741946 for deletion
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741947_1123 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741947 for deletion
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741948_1124 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741948 for deletion
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741949_1125 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741949 for deletion
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741950_1126 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741950 for deletion
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741951_1127 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741951 for deletion
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741943_1119 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741943
2019-06-04 16:16:27,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741944_1120 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741944
2019-06-04 16:16:27,115 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741945_1121 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741945
2019-06-04 16:16:27,115 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741946_1122 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741946
2019-06-04 16:16:27,115 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741947_1123 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741947
2019-06-04 16:16:27,116 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741948_1124 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741948
2019-06-04 16:16:27,116 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741949_1125 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741949
2019-06-04 16:16:27,116 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741950_1126 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741950
2019-06-04 16:16:27,116 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741951_1127 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741951
2019-06-04 16:17:43,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741955_1131 src: /127.0.0.1:56216 dest: /127.0.0.1:50010
2019-06-04 16:17:43,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56216, dest: /127.0.0.1:50010, bytes: 5290, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741955_1131, duration(ns): 668802
2019-06-04 16:17:43,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741955_1131, type=LAST_IN_PIPELINE terminating
2019-06-04 16:17:43,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741956_1132 src: /127.0.0.1:56218 dest: /127.0.0.1:50010
2019-06-04 16:17:43,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56218, dest: /127.0.0.1:50010, bytes: 6069, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741956_1132, duration(ns): 2394209
2019-06-04 16:17:43,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741956_1132, type=LAST_IN_PIPELINE terminating
2019-06-04 16:17:43,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741957_1133 src: /127.0.0.1:56222 dest: /127.0.0.1:50010
2019-06-04 16:17:43,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56222, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741957_1133, duration(ns): 218558550
2019-06-04 16:17:43,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741957_1133, type=LAST_IN_PIPELINE terminating
2019-06-04 16:17:44,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741958_1134 src: /127.0.0.1:56224 dest: /127.0.0.1:50010
2019-06-04 16:17:44,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56224, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741958_1134, duration(ns): 985362
2019-06-04 16:17:44,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741958_1134, type=LAST_IN_PIPELINE terminating
2019-06-04 16:17:44,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741959_1135 src: /127.0.0.1:56226 dest: /127.0.0.1:50010
2019-06-04 16:17:44,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56226, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741959_1135, duration(ns): 642148
2019-06-04 16:17:44,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741959_1135, type=LAST_IN_PIPELINE terminating
2019-06-04 16:17:44,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741960_1136 src: /127.0.0.1:56228 dest: /127.0.0.1:50010
2019-06-04 16:17:44,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56228, dest: /127.0.0.1:50010, bytes: 344989, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741960_1136, duration(ns): 24734437
2019-06-04 16:17:44,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741960_1136, type=LAST_IN_PIPELINE terminating
2019-06-04 16:17:55,393 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741961_1137 src: /127.0.0.1:56250 dest: /127.0.0.1:50010
2019-06-04 16:17:55,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56250, dest: /127.0.0.1:50010, bytes: 390561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1953911580_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741961_1137, duration(ns): 59074566
2019-06-04 16:17:55,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741961_1137, type=LAST_IN_PIPELINE terminating
2019-06-04 16:18:06,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741962_1138 src: /127.0.0.1:56262 dest: /127.0.0.1:50010
2019-06-04 16:18:17,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741963_1139 src: /127.0.0.1:56274 dest: /127.0.0.1:50010
2019-06-04 16:18:17,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56274, dest: /127.0.0.1:50010, bytes: 311, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0011_r_000000_0_1982287636_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741963_1139, duration(ns): 13845913
2019-06-04 16:18:17,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741963_1139, type=LAST_IN_PIPELINE terminating
2019-06-04 16:18:17,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56262, dest: /127.0.0.1:50010, bytes: 35444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1953911580_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741962_1138, duration(ns): 11493166384
2019-06-04 16:18:17,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741962_1138, type=LAST_IN_PIPELINE terminating
2019-06-04 16:18:17,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741964_1140 src: /127.0.0.1:56278 dest: /127.0.0.1:50010
2019-06-04 16:18:17,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56278, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1953911580_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741964_1140, duration(ns): 6816072
2019-06-04 16:18:17,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741964_1140, type=LAST_IN_PIPELINE terminating
2019-06-04 16:18:17,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741965_1141 src: /127.0.0.1:56282 dest: /127.0.0.1:50010
2019-06-04 16:18:17,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56282, dest: /127.0.0.1:50010, bytes: 35444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1953911580_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741965_1141, duration(ns): 1321343
2019-06-04 16:18:17,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741965_1141, type=LAST_IN_PIPELINE terminating
2019-06-04 16:18:17,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741966_1142 src: /127.0.0.1:56284 dest: /127.0.0.1:50010
2019-06-04 16:18:17,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56284, dest: /127.0.0.1:50010, bytes: 390561, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1953911580_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741966_1142, duration(ns): 20753857
2019-06-04 16:18:17,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741966_1142, type=LAST_IN_PIPELINE terminating
2019-06-04 16:18:21,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741957_1133 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741957 for deletion
2019-06-04 16:18:21,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741958_1134 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741958 for deletion
2019-06-04 16:18:21,132 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741959_1135 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741959 for deletion
2019-06-04 16:18:21,132 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741960_1136 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741960 for deletion
2019-06-04 16:18:21,132 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741961_1137 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741961 for deletion
2019-06-04 16:18:21,132 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741962_1138 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741962 for deletion
2019-06-04 16:18:21,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741957_1133 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741957
2019-06-04 16:18:21,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741958_1134 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741958
2019-06-04 16:18:21,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741959_1135 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741959
2019-06-04 16:18:21,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741960_1136 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741960
2019-06-04 16:18:21,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741961_1137 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741961
2019-06-04 16:18:21,139 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741962_1138 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741962
2019-06-04 16:18:24,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741955_1131 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741955 for deletion
2019-06-04 16:18:24,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741956_1132 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741956 for deletion
2019-06-04 16:18:24,131 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741963_1139 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741963 for deletion
2019-06-04 16:18:24,132 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741955_1131 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741955
2019-06-04 16:18:24,132 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741956_1132 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741956
2019-06-04 16:18:24,132 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741963_1139 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741963
2019-06-04 16:19:29,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741967_1143 src: /127.0.0.1:56298 dest: /127.0.0.1:50010
2019-06-04 16:19:29,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56298, dest: /127.0.0.1:50010, bytes: 5116, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741967_1143, duration(ns): 645391
2019-06-04 16:19:29,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741967_1143, type=LAST_IN_PIPELINE terminating
2019-06-04 16:19:30,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741968_1144 src: /127.0.0.1:56300 dest: /127.0.0.1:50010
2019-06-04 16:19:30,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56300, dest: /127.0.0.1:50010, bytes: 5895, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741968_1144, duration(ns): 771373
2019-06-04 16:19:30,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741968_1144, type=LAST_IN_PIPELINE terminating
2019-06-04 16:19:30,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741969_1145 src: /127.0.0.1:56304 dest: /127.0.0.1:50010
2019-06-04 16:19:30,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56304, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741969_1145, duration(ns): 224392486
2019-06-04 16:19:30,346 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741969_1145, type=LAST_IN_PIPELINE terminating
2019-06-04 16:19:30,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741970_1146 src: /127.0.0.1:56306 dest: /127.0.0.1:50010
2019-06-04 16:19:30,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56306, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741970_1146, duration(ns): 711362
2019-06-04 16:19:30,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741970_1146, type=LAST_IN_PIPELINE terminating
2019-06-04 16:19:30,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741971_1147 src: /127.0.0.1:56308 dest: /127.0.0.1:50010
2019-06-04 16:19:30,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56308, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741971_1147, duration(ns): 726892
2019-06-04 16:19:30,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741971_1147, type=LAST_IN_PIPELINE terminating
2019-06-04 16:19:30,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741972_1148 src: /127.0.0.1:56310 dest: /127.0.0.1:50010
2019-06-04 16:19:30,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56310, dest: /127.0.0.1:50010, bytes: 344925, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741972_1148, duration(ns): 1670979
2019-06-04 16:19:30,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741972_1148, type=LAST_IN_PIPELINE terminating
2019-06-04 16:19:42,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741973_1149 src: /127.0.0.1:56330 dest: /127.0.0.1:50010
2019-06-04 16:19:42,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56330, dest: /127.0.0.1:50010, bytes: 390497, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_142714024_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741973_1149, duration(ns): 67954050
2019-06-04 16:19:42,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741973_1149, type=LAST_IN_PIPELINE terminating
2019-06-04 16:19:53,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741974_1150 src: /127.0.0.1:56342 dest: /127.0.0.1:50010
2019-06-04 16:20:05,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741975_1151 src: /127.0.0.1:56356 dest: /127.0.0.1:50010
2019-06-04 16:20:05,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56356, dest: /127.0.0.1:50010, bytes: 503, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0012_r_000000_0_1321253985_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741975_1151, duration(ns): 13127418
2019-06-04 16:20:05,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741975_1151, type=LAST_IN_PIPELINE terminating
2019-06-04 16:20:05,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56342, dest: /127.0.0.1:50010, bytes: 35443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_142714024_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741974_1150, duration(ns): 11580768086
2019-06-04 16:20:05,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741974_1150, type=LAST_IN_PIPELINE terminating
2019-06-04 16:20:05,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741976_1152 src: /127.0.0.1:56360 dest: /127.0.0.1:50010
2019-06-04 16:20:05,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56360, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_142714024_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741976_1152, duration(ns): 1363846
2019-06-04 16:20:05,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741976_1152, type=LAST_IN_PIPELINE terminating
2019-06-04 16:20:05,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741977_1153 src: /127.0.0.1:56364 dest: /127.0.0.1:50010
2019-06-04 16:20:05,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56364, dest: /127.0.0.1:50010, bytes: 35443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_142714024_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741977_1153, duration(ns): 940951
2019-06-04 16:20:05,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741977_1153, type=LAST_IN_PIPELINE terminating
2019-06-04 16:20:05,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741978_1154 src: /127.0.0.1:56366 dest: /127.0.0.1:50010
2019-06-04 16:20:05,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56366, dest: /127.0.0.1:50010, bytes: 390497, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_142714024_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741978_1154, duration(ns): 20715940
2019-06-04 16:20:05,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741978_1154, type=LAST_IN_PIPELINE terminating
2019-06-04 16:20:09,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741969_1145 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741969 for deletion
2019-06-04 16:20:09,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741970_1146 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741970 for deletion
2019-06-04 16:20:09,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741971_1147 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741971 for deletion
2019-06-04 16:20:09,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741972_1148 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741972 for deletion
2019-06-04 16:20:09,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741973_1149 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741973 for deletion
2019-06-04 16:20:09,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741974_1150 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741974 for deletion
2019-06-04 16:20:09,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741969_1145 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741969
2019-06-04 16:20:09,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741970_1146 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741970
2019-06-04 16:20:09,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741971_1147 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741971
2019-06-04 16:20:09,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741972_1148 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741972
2019-06-04 16:20:09,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741973_1149 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741973
2019-06-04 16:20:09,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741974_1150 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741974
2019-06-04 16:20:12,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741968_1144 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741968 for deletion
2019-06-04 16:20:12,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741975_1151 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741975 for deletion
2019-06-04 16:20:12,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741967_1143 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741967 for deletion
2019-06-04 16:20:12,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741968_1144 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741968
2019-06-04 16:20:12,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741975_1151 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741975
2019-06-04 16:20:12,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741967_1143 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741967
2019-06-04 16:21:34,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741979_1155 src: /127.0.0.1:56380 dest: /127.0.0.1:50010
2019-06-04 16:21:34,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56380, dest: /127.0.0.1:50010, bytes: 5116, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741979_1155, duration(ns): 788972
2019-06-04 16:21:34,576 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741979_1155, type=LAST_IN_PIPELINE terminating
2019-06-04 16:21:34,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741980_1156 src: /127.0.0.1:56382 dest: /127.0.0.1:50010
2019-06-04 16:21:34,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56382, dest: /127.0.0.1:50010, bytes: 5803, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741980_1156, duration(ns): 746566
2019-06-04 16:21:34,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741980_1156, type=LAST_IN_PIPELINE terminating
2019-06-04 16:21:34,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741981_1157 src: /127.0.0.1:56386 dest: /127.0.0.1:50010
2019-06-04 16:21:34,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56386, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741981_1157, duration(ns): 261181311
2019-06-04 16:21:34,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741981_1157, type=LAST_IN_PIPELINE terminating
2019-06-04 16:21:35,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741982_1158 src: /127.0.0.1:56388 dest: /127.0.0.1:50010
2019-06-04 16:21:35,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56388, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741982_1158, duration(ns): 671445
2019-06-04 16:21:35,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741982_1158, type=LAST_IN_PIPELINE terminating
2019-06-04 16:21:35,411 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741983_1159 src: /127.0.0.1:56390 dest: /127.0.0.1:50010
2019-06-04 16:21:35,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56390, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741983_1159, duration(ns): 2278760
2019-06-04 16:21:35,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741983_1159, type=LAST_IN_PIPELINE terminating
2019-06-04 16:21:35,447 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741984_1160 src: /127.0.0.1:56392 dest: /127.0.0.1:50010
2019-06-04 16:21:35,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56392, dest: /127.0.0.1:50010, bytes: 344922, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1321829247_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741984_1160, duration(ns): 8159405
2019-06-04 16:21:35,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741984_1160, type=LAST_IN_PIPELINE terminating
2019-06-04 16:21:46,511 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741985_1161 src: /127.0.0.1:56412 dest: /127.0.0.1:50010
2019-06-04 16:21:46,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56412, dest: /127.0.0.1:50010, bytes: 390494, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2059282922_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741985_1161, duration(ns): 85742379
2019-06-04 16:21:46,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741985_1161, type=LAST_IN_PIPELINE terminating
2019-06-04 16:21:55,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741986_1162 src: /127.0.0.1:56424 dest: /127.0.0.1:50010
2019-06-04 16:22:06,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741987_1163 src: /127.0.0.1:56438 dest: /127.0.0.1:50010
2019-06-04 16:22:06,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56438, dest: /127.0.0.1:50010, bytes: 503, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0013_r_000000_0_1843361759_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741987_1163, duration(ns): 7872140
2019-06-04 16:22:06,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741987_1163, type=LAST_IN_PIPELINE terminating
2019-06-04 16:22:07,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56424, dest: /127.0.0.1:50010, bytes: 35443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2059282922_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741986_1162, duration(ns): 11057763960
2019-06-04 16:22:07,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741986_1162, type=LAST_IN_PIPELINE terminating
2019-06-04 16:22:07,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741988_1164 src: /127.0.0.1:56442 dest: /127.0.0.1:50010
2019-06-04 16:22:07,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56442, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2059282922_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741988_1164, duration(ns): 885572
2019-06-04 16:22:07,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741988_1164, type=LAST_IN_PIPELINE terminating
2019-06-04 16:22:07,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741989_1165 src: /127.0.0.1:56446 dest: /127.0.0.1:50010
2019-06-04 16:22:07,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56446, dest: /127.0.0.1:50010, bytes: 35443, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2059282922_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741989_1165, duration(ns): 827684
2019-06-04 16:22:07,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741989_1165, type=LAST_IN_PIPELINE terminating
2019-06-04 16:22:07,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741990_1166 src: /127.0.0.1:56448 dest: /127.0.0.1:50010
2019-06-04 16:22:07,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56448, dest: /127.0.0.1:50010, bytes: 390494, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2059282922_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741990_1166, duration(ns): 17046771
2019-06-04 16:22:07,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741990_1166, type=LAST_IN_PIPELINE terminating
2019-06-04 16:22:12,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741984_1160 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741984 for deletion
2019-06-04 16:22:12,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741985_1161 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741985 for deletion
2019-06-04 16:22:12,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741986_1162 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741986 for deletion
2019-06-04 16:22:12,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741987_1163 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741987 for deletion
2019-06-04 16:22:12,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741979_1155 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741979 for deletion
2019-06-04 16:22:12,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741980_1156 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741980 for deletion
2019-06-04 16:22:12,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741981_1157 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741981 for deletion
2019-06-04 16:22:12,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741982_1158 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741982 for deletion
2019-06-04 16:22:12,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741983_1159 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741983 for deletion
2019-06-04 16:22:12,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741984_1160 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741984
2019-06-04 16:22:12,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741985_1161 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741985
2019-06-04 16:22:12,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741986_1162 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741986
2019-06-04 16:22:12,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741987_1163 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741987
2019-06-04 16:22:12,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741979_1155 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741979
2019-06-04 16:22:12,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741980_1156 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741980
2019-06-04 16:22:12,184 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741981_1157 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741981
2019-06-04 16:22:12,184 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741982_1158 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741982
2019-06-04 16:22:12,184 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741983_1159 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741983
2019-06-04 16:27:54,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741991_1167 src: /127.0.0.1:56490 dest: /127.0.0.1:50010
2019-06-04 16:27:55,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56490, dest: /127.0.0.1:50010, bytes: 5111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1461049279_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741991_1167, duration(ns): 12954467
2019-06-04 16:27:55,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741991_1167, type=LAST_IN_PIPELINE terminating
2019-06-04 16:27:55,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741992_1168 src: /127.0.0.1:56492 dest: /127.0.0.1:50010
2019-06-04 16:27:55,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56492, dest: /127.0.0.1:50010, bytes: 5810, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1461049279_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741992_1168, duration(ns): 980629
2019-06-04 16:27:55,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741992_1168, type=LAST_IN_PIPELINE terminating
2019-06-04 16:27:56,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741993_1169 src: /127.0.0.1:56496 dest: /127.0.0.1:50010
2019-06-04 16:27:56,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56496, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1461049279_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741993_1169, duration(ns): 674194012
2019-06-04 16:27:56,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741993_1169, type=LAST_IN_PIPELINE terminating
2019-06-04 16:27:56,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741994_1170 src: /127.0.0.1:56498 dest: /127.0.0.1:50010
2019-06-04 16:27:56,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56498, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1461049279_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741994_1170, duration(ns): 842441
2019-06-04 16:27:57,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741994_1170, type=LAST_IN_PIPELINE terminating
2019-06-04 16:27:57,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741995_1171 src: /127.0.0.1:56500 dest: /127.0.0.1:50010
2019-06-04 16:27:57,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56500, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1461049279_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741995_1171, duration(ns): 704630
2019-06-04 16:27:57,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741995_1171, type=LAST_IN_PIPELINE terminating
2019-06-04 16:27:57,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741996_1172 src: /127.0.0.1:56502 dest: /127.0.0.1:50010
2019-06-04 16:27:57,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56502, dest: /127.0.0.1:50010, bytes: 344755, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1461049279_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741996_1172, duration(ns): 110162548
2019-06-04 16:27:57,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741996_1172, type=LAST_IN_PIPELINE terminating
2019-06-04 16:28:08,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741997_1173 src: /127.0.0.1:56524 dest: /127.0.0.1:50010
2019-06-04 16:28:08,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56524, dest: /127.0.0.1:50010, bytes: 390303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1669043564_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741997_1173, duration(ns): 41217801
2019-06-04 16:28:08,952 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741997_1173, type=LAST_IN_PIPELINE terminating
2019-06-04 16:28:20,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741998_1174 src: /127.0.0.1:56538 dest: /127.0.0.1:50010
2019-06-04 16:28:31,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073741999_1175 src: /127.0.0.1:56550 dest: /127.0.0.1:50010
2019-06-04 16:28:31,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56550, dest: /127.0.0.1:50010, bytes: 503, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0014_r_000000_0_-106277389_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741999_1175, duration(ns): 14563835
2019-06-04 16:28:31,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741999_1175, type=LAST_IN_PIPELINE terminating
2019-06-04 16:28:32,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56538, dest: /127.0.0.1:50010, bytes: 35447, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1669043564_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073741998_1174, duration(ns): 11478568237
2019-06-04 16:28:32,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073741998_1174, type=LAST_IN_PIPELINE terminating
2019-06-04 16:28:32,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742000_1176 src: /127.0.0.1:56554 dest: /127.0.0.1:50010
2019-06-04 16:28:32,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56554, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1669043564_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742000_1176, duration(ns): 2460869
2019-06-04 16:28:32,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742000_1176, type=LAST_IN_PIPELINE terminating
2019-06-04 16:28:32,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742001_1177 src: /127.0.0.1:56558 dest: /127.0.0.1:50010
2019-06-04 16:28:32,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56558, dest: /127.0.0.1:50010, bytes: 35447, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1669043564_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742001_1177, duration(ns): 13375444
2019-06-04 16:28:32,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742001_1177, type=LAST_IN_PIPELINE terminating
2019-06-04 16:28:32,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742002_1178 src: /127.0.0.1:56560 dest: /127.0.0.1:50010
2019-06-04 16:28:32,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56560, dest: /127.0.0.1:50010, bytes: 390303, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1669043564_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742002_1178, duration(ns): 12761586
2019-06-04 16:28:32,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742002_1178, type=LAST_IN_PIPELINE terminating
2019-06-04 16:28:36,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741993_1169 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741993 for deletion
2019-06-04 16:28:36,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741994_1170 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741994 for deletion
2019-06-04 16:28:36,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741995_1171 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741995 for deletion
2019-06-04 16:28:36,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741996_1172 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741996 for deletion
2019-06-04 16:28:36,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741997_1173 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741997 for deletion
2019-06-04 16:28:36,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741998_1174 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741998 for deletion
2019-06-04 16:28:36,247 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741993_1169 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741993
2019-06-04 16:28:36,247 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741994_1170 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741994
2019-06-04 16:28:36,247 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741995_1171 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741995
2019-06-04 16:28:36,248 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741996_1172 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741996
2019-06-04 16:28:36,248 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741997_1173 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741997
2019-06-04 16:28:36,248 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741998_1174 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741998
2019-06-04 16:28:39,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741991_1167 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741991 for deletion
2019-06-04 16:28:39,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741992_1168 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741992 for deletion
2019-06-04 16:28:39,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741999_1175 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741999 for deletion
2019-06-04 16:28:39,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741991_1167 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741991
2019-06-04 16:28:39,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741992_1168 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741992
2019-06-04 16:28:39,243 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073741999_1175 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073741999
2019-06-04 16:31:39,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a05,  containing 1 storage report(s), of which we sent 1. The reports had 51 total blocks and used 1 RPC(s). This took 2 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-04 16:31:39,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-04 16:32:31,320 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742003_1179 src: /127.0.0.1:56614 dest: /127.0.0.1:50010
2019-06-04 16:32:31,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56614, dest: /127.0.0.1:50010, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1774089907_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742003_1179, duration(ns): 12241743
2019-06-04 16:32:31,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742003_1179, type=LAST_IN_PIPELINE terminating
2019-06-04 16:32:36,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742003_1179 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742003 for deletion
2019-06-04 16:32:36,287 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742003_1179 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742003
2019-06-04 16:35:00,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742004_1180 src: /127.0.0.1:56640 dest: /127.0.0.1:50010
2019-06-04 16:35:00,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56640, dest: /127.0.0.1:50010, bytes: 5111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1274451273_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742004_1180, duration(ns): 27446666
2019-06-04 16:35:00,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742004_1180, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:00,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742005_1181 src: /127.0.0.1:56642 dest: /127.0.0.1:50010
2019-06-04 16:35:00,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56642, dest: /127.0.0.1:50010, bytes: 5810, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1274451273_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742005_1181, duration(ns): 882464
2019-06-04 16:35:00,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742005_1181, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:01,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742006_1182 src: /127.0.0.1:56648 dest: /127.0.0.1:50010
2019-06-04 16:35:02,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56648, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1274451273_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742006_1182, duration(ns): 744075248
2019-06-04 16:35:02,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742006_1182, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:02,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742007_1183 src: /127.0.0.1:56650 dest: /127.0.0.1:50010
2019-06-04 16:35:02,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56650, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1274451273_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742007_1183, duration(ns): 1880986
2019-06-04 16:35:02,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742007_1183, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:02,759 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742008_1184 src: /127.0.0.1:56652 dest: /127.0.0.1:50010
2019-06-04 16:35:02,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56652, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1274451273_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742008_1184, duration(ns): 2156006
2019-06-04 16:35:02,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742008_1184, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:02,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742009_1185 src: /127.0.0.1:56654 dest: /127.0.0.1:50010
2019-06-04 16:35:02,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56654, dest: /127.0.0.1:50010, bytes: 344757, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1274451273_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742009_1185, duration(ns): 31945482
2019-06-04 16:35:02,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742009_1185, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:13,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742010_1186 src: /127.0.0.1:56672 dest: /127.0.0.1:50010
2019-06-04 16:35:13,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56672, dest: /127.0.0.1:50010, bytes: 390305, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1352132562_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742010_1186, duration(ns): 34147347
2019-06-04 16:35:13,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742010_1186, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:23,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742011_1187 src: /127.0.0.1:56684 dest: /127.0.0.1:50010
2019-06-04 16:35:33,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742012_1188 src: /127.0.0.1:56696 dest: /127.0.0.1:50010
2019-06-04 16:35:33,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56696, dest: /127.0.0.1:50010, bytes: 503, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0015_r_000000_0_1072398101_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742012_1188, duration(ns): 12205287
2019-06-04 16:35:33,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742012_1188, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:34,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56684, dest: /127.0.0.1:50010, bytes: 35448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1352132562_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742011_1187, duration(ns): 10232217486
2019-06-04 16:35:34,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742011_1187, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:34,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742013_1189 src: /127.0.0.1:56700 dest: /127.0.0.1:50010
2019-06-04 16:35:34,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56700, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1352132562_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742013_1189, duration(ns): 1175822
2019-06-04 16:35:34,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742013_1189, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:34,225 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742014_1190 src: /127.0.0.1:56704 dest: /127.0.0.1:50010
2019-06-04 16:35:34,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56704, dest: /127.0.0.1:50010, bytes: 35448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1352132562_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742014_1190, duration(ns): 4769662
2019-06-04 16:35:34,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742014_1190, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:34,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742015_1191 src: /127.0.0.1:56706 dest: /127.0.0.1:50010
2019-06-04 16:35:34,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:56706, dest: /127.0.0.1:50010, bytes: 390305, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1352132562_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742015_1191, duration(ns): 20988531
2019-06-04 16:35:34,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742015_1191, type=LAST_IN_PIPELINE terminating
2019-06-04 16:35:39,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742004_1180 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742004 for deletion
2019-06-04 16:35:39,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742005_1181 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742005 for deletion
2019-06-04 16:35:39,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742006_1182 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742006 for deletion
2019-06-04 16:35:39,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742007_1183 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742007 for deletion
2019-06-04 16:35:39,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742008_1184 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742008 for deletion
2019-06-04 16:35:39,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742009_1185 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742009 for deletion
2019-06-04 16:35:39,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742010_1186 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742010 for deletion
2019-06-04 16:35:39,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742011_1187 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742011 for deletion
2019-06-04 16:35:39,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742012_1188 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742012 for deletion
2019-06-04 16:35:39,321 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742004_1180 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742004
2019-06-04 16:35:39,321 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742005_1181 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742005
2019-06-04 16:35:39,325 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742006_1182 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742006
2019-06-04 16:35:39,326 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742007_1183 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742007
2019-06-04 16:35:39,326 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742008_1184 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742008
2019-06-04 16:35:39,326 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742009_1185 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742009
2019-06-04 16:35:39,326 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742010_1186 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742010
2019-06-04 16:35:39,326 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742011_1187 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742011
2019-06-04 16:35:39,326 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742012_1188 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742012
2019-06-04 18:35:58,309 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 54, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-04 22:31:39,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a06,  containing 1 storage report(s), of which we sent 1. The reports had 54 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-04 22:31:39,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-05 00:35:58,292 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 54, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-05 04:31:40,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a07,  containing 1 storage report(s), of which we sent 1. The reports had 54 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-05 04:31:40,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-05 06:35:58,295 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 54, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-05 09:42:25,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742016_1192 src: /127.0.0.1:59014 dest: /127.0.0.1:50010
2019-06-05 09:42:25,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59014, dest: /127.0.0.1:50010, bytes: 5111, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1485641640_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742016_1192, duration(ns): 11819735
2019-06-05 09:42:25,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742016_1192, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:25,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742017_1193 src: /127.0.0.1:59016 dest: /127.0.0.1:50010
2019-06-05 09:42:25,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59016, dest: /127.0.0.1:50010, bytes: 5810, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1485641640_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742017_1193, duration(ns): 752654
2019-06-05 09:42:25,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742017_1193, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:26,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742018_1194 src: /127.0.0.1:59020 dest: /127.0.0.1:50010
2019-06-05 09:42:26,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59020, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1485641640_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742018_1194, duration(ns): 502002550
2019-06-05 09:42:26,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742018_1194, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:26,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742019_1195 src: /127.0.0.1:59022 dest: /127.0.0.1:50010
2019-06-05 09:42:26,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59022, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1485641640_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742019_1195, duration(ns): 795720
2019-06-05 09:42:26,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742019_1195, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:26,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742020_1196 src: /127.0.0.1:59024 dest: /127.0.0.1:50010
2019-06-05 09:42:26,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59024, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1485641640_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742020_1196, duration(ns): 707066
2019-06-05 09:42:26,935 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742020_1196, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:27,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742021_1197 src: /127.0.0.1:59026 dest: /127.0.0.1:50010
2019-06-05 09:42:27,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59026, dest: /127.0.0.1:50010, bytes: 344757, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1485641640_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742021_1197, duration(ns): 27573891
2019-06-05 09:42:27,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742021_1197, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:37,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742022_1198 src: /127.0.0.1:59044 dest: /127.0.0.1:50010
2019-06-05 09:42:37,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59044, dest: /127.0.0.1:50010, bytes: 390305, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1264158108_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742022_1198, duration(ns): 32553809
2019-06-05 09:42:37,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742022_1198, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:46,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742023_1199 src: /127.0.0.1:59056 dest: /127.0.0.1:50010
2019-06-05 09:42:55,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742024_1200 src: /127.0.0.1:59068 dest: /127.0.0.1:50010
2019-06-05 09:42:55,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59068, dest: /127.0.0.1:50010, bytes: 503, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0016_r_000000_0_-1743492684_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742024_1200, duration(ns): 14488254
2019-06-05 09:42:55,812 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742024_1200, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:56,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59056, dest: /127.0.0.1:50010, bytes: 35448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1264158108_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742023_1199, duration(ns): 9154611348
2019-06-05 09:42:56,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742023_1199, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:56,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742025_1201 src: /127.0.0.1:59070 dest: /127.0.0.1:50010
2019-06-05 09:42:56,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59070, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1264158108_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742025_1201, duration(ns): 922186
2019-06-05 09:42:56,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742025_1201, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:56,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742026_1202 src: /127.0.0.1:59074 dest: /127.0.0.1:50010
2019-06-05 09:42:56,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59074, dest: /127.0.0.1:50010, bytes: 35448, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1264158108_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742026_1202, duration(ns): 1846398
2019-06-05 09:42:56,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742026_1202, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:56,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742027_1203 src: /127.0.0.1:59076 dest: /127.0.0.1:50010
2019-06-05 09:42:56,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59076, dest: /127.0.0.1:50010, bytes: 390305, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1264158108_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742027_1203, duration(ns): 17039934
2019-06-05 09:42:56,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742027_1203, type=LAST_IN_PIPELINE terminating
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742016_1192 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742016 for deletion
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742017_1193 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742017 for deletion
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742018_1194 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742018 for deletion
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742019_1195 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742019 for deletion
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742020_1196 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742020 for deletion
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742021_1197 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742021 for deletion
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742022_1198 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742022 for deletion
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742023_1199 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742023 for deletion
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742016_1192 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742016
2019-06-05 09:42:58,406 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742017_1193 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742017
2019-06-05 09:42:58,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742018_1194 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742018
2019-06-05 09:42:58,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742019_1195 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742019
2019-06-05 09:42:58,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742020_1196 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742020
2019-06-05 09:42:58,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742021_1197 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742021
2019-06-05 09:42:58,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742022_1198 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742022
2019-06-05 09:42:58,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742023_1199 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742023
2019-06-05 09:43:01,407 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742024_1200 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742024 for deletion
2019-06-05 09:43:01,408 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742024_1200 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742024
2019-06-05 10:31:40,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a08,  containing 1 storage report(s), of which we sent 1. The reports had 57 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-05 10:31:40,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-05 11:18:37,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742028_1204 src: /127.0.0.1:59330 dest: /127.0.0.1:50010
2019-06-05 11:18:37,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59330, dest: /127.0.0.1:50010, bytes: 5030, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1774223326_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742028_1204, duration(ns): 16125195
2019-06-05 11:18:37,059 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742028_1204, type=LAST_IN_PIPELINE terminating
2019-06-05 11:18:37,107 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742029_1205 src: /127.0.0.1:59332 dest: /127.0.0.1:50010
2019-06-05 11:18:37,115 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59332, dest: /127.0.0.1:50010, bytes: 5705, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1774223326_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742029_1205, duration(ns): 2748112
2019-06-05 11:18:37,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742029_1205, type=LAST_IN_PIPELINE terminating
2019-06-05 11:18:38,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742030_1206 src: /127.0.0.1:59336 dest: /127.0.0.1:50010
2019-06-05 11:18:38,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59336, dest: /127.0.0.1:50010, bytes: 34271938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1774223326_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742030_1206, duration(ns): 496773869
2019-06-05 11:18:38,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742030_1206, type=LAST_IN_PIPELINE terminating
2019-06-05 11:18:38,699 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742031_1207 src: /127.0.0.1:59338 dest: /127.0.0.1:50010
2019-06-05 11:18:38,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59338, dest: /127.0.0.1:50010, bytes: 221, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1774223326_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742031_1207, duration(ns): 1395680
2019-06-05 11:18:38,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742031_1207, type=LAST_IN_PIPELINE terminating
2019-06-05 11:18:38,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742032_1208 src: /127.0.0.1:59340 dest: /127.0.0.1:50010
2019-06-05 11:18:38,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59340, dest: /127.0.0.1:50010, bytes: 23, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1774223326_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742032_1208, duration(ns): 737505
2019-06-05 11:18:38,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742032_1208, type=LAST_IN_PIPELINE terminating
2019-06-05 11:18:38,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742033_1209 src: /127.0.0.1:59342 dest: /127.0.0.1:50010
2019-06-05 11:18:38,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59342, dest: /127.0.0.1:50010, bytes: 344722, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1774223326_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742033_1209, duration(ns): 102528086
2019-06-05 11:18:38,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742033_1209, type=LAST_IN_PIPELINE terminating
2019-06-05 11:18:49,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742034_1210 src: /127.0.0.1:59360 dest: /127.0.0.1:50010
2019-06-05 11:18:49,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59360, dest: /127.0.0.1:50010, bytes: 390270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_436014639_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742034_1210, duration(ns): 41173512
2019-06-05 11:18:49,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742034_1210, type=LAST_IN_PIPELINE terminating
2019-06-05 11:18:59,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742035_1211 src: /127.0.0.1:59372 dest: /127.0.0.1:50010
2019-06-05 11:19:08,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742036_1212 src: /127.0.0.1:59384 dest: /127.0.0.1:50010
2019-06-05 11:19:08,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59384, dest: /127.0.0.1:50010, bytes: 528, op: HDFS_WRITE, cliID: DFSClient_attempt_1559628913836_0017_r_000000_0_480427220_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742036_1212, duration(ns): 13143181
2019-06-05 11:19:08,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742036_1212, type=LAST_IN_PIPELINE terminating
2019-06-05 11:19:09,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59372, dest: /127.0.0.1:50010, bytes: 35432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_436014639_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742035_1211, duration(ns): 9928458575
2019-06-05 11:19:09,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742035_1211, type=LAST_IN_PIPELINE terminating
2019-06-05 11:19:09,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742037_1213 src: /127.0.0.1:59386 dest: /127.0.0.1:50010
2019-06-05 11:19:09,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59386, dest: /127.0.0.1:50010, bytes: 392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_436014639_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742037_1213, duration(ns): 6355107
2019-06-05 11:19:09,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742037_1213, type=LAST_IN_PIPELINE terminating
2019-06-05 11:19:09,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742038_1214 src: /127.0.0.1:59390 dest: /127.0.0.1:50010
2019-06-05 11:19:09,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59390, dest: /127.0.0.1:50010, bytes: 35432, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_436014639_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742038_1214, duration(ns): 915438
2019-06-05 11:19:09,272 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742038_1214, type=LAST_IN_PIPELINE terminating
2019-06-05 11:19:09,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742039_1215 src: /127.0.0.1:59392 dest: /127.0.0.1:50010
2019-06-05 11:19:09,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59392, dest: /127.0.0.1:50010, bytes: 390270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_436014639_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742039_1215, duration(ns): 18423149
2019-06-05 11:19:09,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742039_1215, type=LAST_IN_PIPELINE terminating
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742032_1208 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742032 for deletion
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742033_1209 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742033 for deletion
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742034_1210 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742034 for deletion
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742035_1211 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742035 for deletion
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742028_1204 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742028 for deletion
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742029_1205 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742029 for deletion
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742030_1206 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742030 for deletion
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742031_1207 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742031 for deletion
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742032_1208 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742032
2019-06-05 11:19:11,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742033_1209 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742033
2019-06-05 11:19:11,349 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742034_1210 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742034
2019-06-05 11:19:11,349 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742035_1211 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742035
2019-06-05 11:19:11,349 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742028_1204 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742028
2019-06-05 11:19:11,349 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742029_1205 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742029
2019-06-05 11:19:11,354 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742030_1206 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742030
2019-06-05 11:19:11,354 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742031_1207 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742031
2019-06-05 11:19:14,348 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742036_1212 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742036 for deletion
2019-06-05 11:19:14,349 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742036_1212 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742036
2019-06-05 12:35:58,299 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 60, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-05 16:31:41,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a09,  containing 1 storage report(s), of which we sent 1. The reports had 60 total blocks and used 1 RPC(s). This took 2 msec to generate and 20 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-05 16:31:41,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-05 18:35:58,295 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 60, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-05 22:31:41,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a0a,  containing 1 storage report(s), of which we sent 1. The reports had 60 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-05 22:31:41,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-06 00:35:58,286 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 60, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-06 04:31:40,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a0b,  containing 1 storage report(s), of which we sent 1. The reports had 60 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-06 04:31:40,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-06 06:35:58,293 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 60, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-06 10:31:39,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a0c,  containing 1 storage report(s), of which we sent 1. The reports had 60 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-06 10:31:39,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-06 12:35:58,288 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 60, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-06 16:31:38,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a0d,  containing 1 storage report(s), of which we sent 1. The reports had 60 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-06 16:31:38,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-06 18:35:58,282 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 60, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-06 22:31:40,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a0e,  containing 1 storage report(s), of which we sent 1. The reports had 60 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-06 22:31:40,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-07 00:35:58,281 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 60, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-07 04:31:40,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xae971b9ed1239a0f,  containing 1 storage report(s), of which we sent 1. The reports had 60 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-07 04:31:40,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-07 06:35:58,282 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 60, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-07 09:21:47,335 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-06-07 09:21:51,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-07 09:21:51,482 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-07 09:21:51,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-07 09:24:29,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-07 09:24:29,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-07 09:24:30,310 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-07 09:24:30,953 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-07 09:24:31,081 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-07 09:24:31,261 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-07 09:24:31,261 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-07 09:24:31,274 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-07 09:24:31,277 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-07 09:24:31,281 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-07 09:24:31,281 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-07 09:24:31,281 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-07 09:24:31,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-07 09:24:31,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-07 09:24:31,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-07 09:24:31,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-07 09:24:31,498 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-07 09:24:31,517 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-07 09:24:31,557 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-07 09:24:31,570 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-07 09:24:31,576 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-07 09:24:31,577 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-07 09:24:31,577 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-07 09:24:31,615 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34355
2019-06-07 09:24:31,615 INFO org.mortbay.log: jetty-6.1.26
2019-06-07 09:24:32,545 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:34355
2019-06-07 09:24:32,832 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-07 09:24:32,853 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-07 09:24:34,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-07 09:24:34,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-07 09:24:34,272 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-07 09:24:34,350 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-07 09:24:34,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-07 09:24:34,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-07 09:24:34,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-07 09:24:34,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-07 09:24:34,831 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-07 09:24:34,837 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-07 09:24:35,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-07 09:24:35,784 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-07 09:24:35,796 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 25710@master
2019-06-07 09:24:35,916 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-07 09:24:35,916 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-07 09:24:35,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-07 09:24:36,039 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-07 09:24:36,039 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-07 09:24:36,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-07 09:24:36,064 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-07 09:24:36,090 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-07 09:24:36,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-07 09:24:36,096 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-07 09:24:36,128 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current: 10260480
2019-06-07 09:24:36,171 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 74ms
2019-06-07 09:24:36,173 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 81ms
2019-06-07 09:24:36,177 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-07 09:24:36,178 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-07 09:24:36,231 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 54ms
2019-06-07 09:24:36,233 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 59ms
2019-06-07 09:24:36,418 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 1576152732 ms.
2019-06-07 09:24:36,438 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 7 오후 1:18 with interval of 21600000ms
2019-06-07 09:24:36,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-06-07 09:24:36,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-06-07 09:24:36,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-07 09:24:36,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x820ce55d2d659248,  containing 1 storage report(s), of which we sent 1. The reports had 60 total blocks and used 1 RPC(s). This took 12 msec to generate and 171 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-07 09:24:36,917 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-07 10:15:03,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742040_1216 src: /127.0.0.1:37964 dest: /127.0.0.1:50010
2019-06-07 10:15:03,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37964, dest: /127.0.0.1:50010, bytes: 1033299, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742040_1216, duration(ns): 156792240
2019-06-07 10:15:03,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742040_1216, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:03,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742041_1217 src: /127.0.0.1:37966 dest: /127.0.0.1:50010
2019-06-07 10:15:03,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37966, dest: /127.0.0.1:50010, bytes: 375618, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742041_1217, duration(ns): 4943799
2019-06-07 10:15:03,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742041_1217, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:03,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742042_1218 src: /127.0.0.1:37968 dest: /127.0.0.1:50010
2019-06-07 10:15:03,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37968, dest: /127.0.0.1:50010, bytes: 914311, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742042_1218, duration(ns): 26631411
2019-06-07 10:15:03,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742042_1218, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:04,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742043_1219 src: /127.0.0.1:37970 dest: /127.0.0.1:50010
2019-06-07 10:15:04,344 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37970, dest: /127.0.0.1:50010, bytes: 267634, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742043_1219, duration(ns): 3502810
2019-06-07 10:15:04,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742043_1219, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:04,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742044_1220 src: /127.0.0.1:37972 dest: /127.0.0.1:50010
2019-06-07 10:15:04,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37972, dest: /127.0.0.1:50010, bytes: 25496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742044_1220, duration(ns): 2275837
2019-06-07 10:15:04,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742044_1220, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:04,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742045_1221 src: /127.0.0.1:37974 dest: /127.0.0.1:50010
2019-06-07 10:15:04,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37974, dest: /127.0.0.1:50010, bytes: 232248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742045_1221, duration(ns): 3054018
2019-06-07 10:15:04,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742045_1221, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:04,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742046_1222 src: /127.0.0.1:37976 dest: /127.0.0.1:50010
2019-06-07 10:15:04,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37976, dest: /127.0.0.1:50010, bytes: 20998, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742046_1222, duration(ns): 2503807
2019-06-07 10:15:04,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742046_1222, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:04,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742047_1223 src: /127.0.0.1:37978 dest: /127.0.0.1:50010
2019-06-07 10:15:04,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37978, dest: /127.0.0.1:50010, bytes: 1007502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742047_1223, duration(ns): 13078445
2019-06-07 10:15:04,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742047_1223, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:04,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742048_1224 src: /127.0.0.1:37980 dest: /127.0.0.1:50010
2019-06-07 10:15:04,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37980, dest: /127.0.0.1:50010, bytes: 60686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742048_1224, duration(ns): 1322797
2019-06-07 10:15:04,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742048_1224, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:04,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742049_1225 src: /127.0.0.1:37982 dest: /127.0.0.1:50010
2019-06-07 10:15:04,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37982, dest: /127.0.0.1:50010, bytes: 197986, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742049_1225, duration(ns): 2888731
2019-06-07 10:15:04,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742049_1225, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:04,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742050_1226 src: /127.0.0.1:37984 dest: /127.0.0.1:50010
2019-06-07 10:15:04,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37984, dest: /127.0.0.1:50010, bytes: 1108073, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742050_1226, duration(ns): 17603457
2019-06-07 10:15:04,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742050_1226, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742051_1227 src: /127.0.0.1:37986 dest: /127.0.0.1:50010
2019-06-07 10:15:05,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37986, dest: /127.0.0.1:50010, bytes: 224277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742051_1227, duration(ns): 6387355
2019-06-07 10:15:05,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742051_1227, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742052_1228 src: /127.0.0.1:37988 dest: /127.0.0.1:50010
2019-06-07 10:15:05,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37988, dest: /127.0.0.1:50010, bytes: 434678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742052_1228, duration(ns): 9515491
2019-06-07 10:15:05,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742052_1228, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742053_1229 src: /127.0.0.1:37990 dest: /127.0.0.1:50010
2019-06-07 10:15:05,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37990, dest: /127.0.0.1:50010, bytes: 109043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742053_1229, duration(ns): 1840452
2019-06-07 10:15:05,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742053_1229, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742054_1230 src: /127.0.0.1:37992 dest: /127.0.0.1:50010
2019-06-07 10:15:05,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37992, dest: /127.0.0.1:50010, bytes: 780664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742054_1230, duration(ns): 11195366
2019-06-07 10:15:05,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742054_1230, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742055_1231 src: /127.0.0.1:37994 dest: /127.0.0.1:50010
2019-06-07 10:15:05,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37994, dest: /127.0.0.1:50010, bytes: 706710, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742055_1231, duration(ns): 7156471
2019-06-07 10:15:05,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742055_1231, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742056_1232 src: /127.0.0.1:37996 dest: /127.0.0.1:50010
2019-06-07 10:15:05,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37996, dest: /127.0.0.1:50010, bytes: 1007502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742056_1232, duration(ns): 4071861
2019-06-07 10:15:05,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742056_1232, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742057_1233 src: /127.0.0.1:37998 dest: /127.0.0.1:50010
2019-06-07 10:15:05,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:37998, dest: /127.0.0.1:50010, bytes: 1765905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742057_1233, duration(ns): 44635041
2019-06-07 10:15:05,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742057_1233, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742058_1234 src: /127.0.0.1:38000 dest: /127.0.0.1:50010
2019-06-07 10:15:05,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38000, dest: /127.0.0.1:50010, bytes: 20744, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742058_1234, duration(ns): 829109
2019-06-07 10:15:05,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742058_1234, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742059_1235 src: /127.0.0.1:38002 dest: /127.0.0.1:50010
2019-06-07 10:15:05,876 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38002, dest: /127.0.0.1:50010, bytes: 279012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742059_1235, duration(ns): 3697139
2019-06-07 10:15:05,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742059_1235, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742060_1236 src: /127.0.0.1:38004 dest: /127.0.0.1:50010
2019-06-07 10:15:05,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38004, dest: /127.0.0.1:50010, bytes: 58160, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742060_1236, duration(ns): 1638907
2019-06-07 10:15:05,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742060_1236, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742061_1237 src: /127.0.0.1:38006 dest: /127.0.0.1:50010
2019-06-07 10:15:05,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38006, dest: /127.0.0.1:50010, bytes: 1801469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742061_1237, duration(ns): 15474935
2019-06-07 10:15:05,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742061_1237, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:05,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742062_1238 src: /127.0.0.1:38008 dest: /127.0.0.1:50010
2019-06-07 10:15:06,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38008, dest: /127.0.0.1:50010, bytes: 205389, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742062_1238, duration(ns): 942835
2019-06-07 10:15:06,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742062_1238, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:06,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742063_1239 src: /127.0.0.1:38010 dest: /127.0.0.1:50010
2019-06-07 10:15:06,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38010, dest: /127.0.0.1:50010, bytes: 53464, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742063_1239, duration(ns): 2887299
2019-06-07 10:15:06,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742063_1239, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:06,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742064_1240 src: /127.0.0.1:38012 dest: /127.0.0.1:50010
2019-06-07 10:15:06,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38012, dest: /127.0.0.1:50010, bytes: 592319, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742064_1240, duration(ns): 1787520
2019-06-07 10:15:06,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742064_1240, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:06,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742065_1241 src: /127.0.0.1:38014 dest: /127.0.0.1:50010
2019-06-07 10:15:06,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38014, dest: /127.0.0.1:50010, bytes: 892808, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742065_1241, duration(ns): 9237283
2019-06-07 10:15:06,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742065_1241, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:06,544 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742066_1242 src: /127.0.0.1:38016 dest: /127.0.0.1:50010
2019-06-07 10:15:06,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38016, dest: /127.0.0.1:50010, bytes: 36455, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742066_1242, duration(ns): 612283
2019-06-07 10:15:06,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742066_1242, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:06,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742067_1243 src: /127.0.0.1:38018 dest: /127.0.0.1:50010
2019-06-07 10:15:06,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38018, dest: /127.0.0.1:50010, bytes: 99555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742067_1243, duration(ns): 7318223
2019-06-07 10:15:06,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742067_1243, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:06,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742068_1244 src: /127.0.0.1:38020 dest: /127.0.0.1:50010
2019-06-07 10:15:06,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38020, dest: /127.0.0.1:50010, bytes: 2178774, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742068_1244, duration(ns): 26639328
2019-06-07 10:15:06,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742068_1244, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742069_1245 src: /127.0.0.1:38022 dest: /127.0.0.1:50010
2019-06-07 10:15:07,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38022, dest: /127.0.0.1:50010, bytes: 36519, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742069_1245, duration(ns): 824428
2019-06-07 10:15:07,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742069_1245, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742070_1246 src: /127.0.0.1:38024 dest: /127.0.0.1:50010
2019-06-07 10:15:07,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38024, dest: /127.0.0.1:50010, bytes: 186260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742070_1246, duration(ns): 1617227
2019-06-07 10:15:07,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742070_1246, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742071_1247 src: /127.0.0.1:38026 dest: /127.0.0.1:50010
2019-06-07 10:15:07,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38026, dest: /127.0.0.1:50010, bytes: 19827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742071_1247, duration(ns): 5035573
2019-06-07 10:15:07,167 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742071_1247, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742072_1248 src: /127.0.0.1:38028 dest: /127.0.0.1:50010
2019-06-07 10:15:07,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38028, dest: /127.0.0.1:50010, bytes: 34604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742072_1248, duration(ns): 630804
2019-06-07 10:15:07,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742072_1248, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742073_1249 src: /127.0.0.1:38030 dest: /127.0.0.1:50010
2019-06-07 10:15:07,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38030, dest: /127.0.0.1:50010, bytes: 1344870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742073_1249, duration(ns): 2034442
2019-06-07 10:15:07,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742073_1249, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742074_1250 src: /127.0.0.1:38032 dest: /127.0.0.1:50010
2019-06-07 10:15:07,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38032, dest: /127.0.0.1:50010, bytes: 1768012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742074_1250, duration(ns): 15983783
2019-06-07 10:15:07,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742074_1250, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,313 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742047_1223 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742047 for deletion
2019-06-07 10:15:07,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742075_1251 src: /127.0.0.1:38034 dest: /127.0.0.1:50010
2019-06-07 10:15:07,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38034, dest: /127.0.0.1:50010, bytes: 365552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742075_1251, duration(ns): 3370488
2019-06-07 10:15:07,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742075_1251, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,327 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742047_1223 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742047
2019-06-07 10:15:07,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742076_1252 src: /127.0.0.1:38036 dest: /127.0.0.1:50010
2019-06-07 10:15:07,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38036, dest: /127.0.0.1:50010, bytes: 9442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742076_1252, duration(ns): 679824
2019-06-07 10:15:07,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742076_1252, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742077_1253 src: /127.0.0.1:38040 dest: /127.0.0.1:50010
2019-06-07 10:15:07,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38040, dest: /127.0.0.1:50010, bytes: 94, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742077_1253, duration(ns): 707823
2019-06-07 10:15:07,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742077_1253, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:07,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742078_1254 src: /127.0.0.1:38042 dest: /127.0.0.1:50010
2019-06-07 10:15:07,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38042, dest: /127.0.0.1:50010, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742078_1254, duration(ns): 683560
2019-06-07 10:15:07,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742078_1254, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:08,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742079_1255 src: /127.0.0.1:38044 dest: /127.0.0.1:50010
2019-06-07 10:15:08,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38044, dest: /127.0.0.1:50010, bytes: 176907, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_668113300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742079_1255, duration(ns): 17637219
2019-06-07 10:15:08,298 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742079_1255, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:24,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742080_1256 src: /127.0.0.1:38062 dest: /127.0.0.1:50010
2019-06-07 10:15:24,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38062, dest: /127.0.0.1:50010, bytes: 204045, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1267265607_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742080_1256, duration(ns): 16517952
2019-06-07 10:15:24,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742080_1256, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:32,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742081_1257 src: /127.0.0.1:38074 dest: /127.0.0.1:50010
2019-06-07 10:15:32,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38074, dest: /127.0.0.1:50010, bytes: 110, op: HDFS_WRITE, cliID: DFSClient_attempt_1559867131140_0001_m_000000_0_2945017_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742081_1257, duration(ns): 7827743
2019-06-07 10:15:32,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742081_1257, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:32,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742082_1258 src: /127.0.0.1:38076 dest: /127.0.0.1:50010
2019-06-07 10:15:32,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38076, dest: /127.0.0.1:50010, bytes: 21068, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1267265607_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742082_1258, duration(ns): 198689271
2019-06-07 10:15:32,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742082_1258, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:32,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742083_1259 src: /127.0.0.1:38078 dest: /127.0.0.1:50010
2019-06-07 10:15:32,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38078, dest: /127.0.0.1:50010, bytes: 338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1267265607_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742083_1259, duration(ns): 8599580
2019-06-07 10:15:32,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742083_1259, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:32,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742084_1260 src: /127.0.0.1:38082 dest: /127.0.0.1:50010
2019-06-07 10:15:32,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38082, dest: /127.0.0.1:50010, bytes: 21068, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1267265607_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742084_1260, duration(ns): 804489
2019-06-07 10:15:32,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742084_1260, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:32,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742085_1261 src: /127.0.0.1:38084 dest: /127.0.0.1:50010
2019-06-07 10:15:32,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38084, dest: /127.0.0.1:50010, bytes: 204045, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1267265607_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742085_1261, duration(ns): 1230798
2019-06-07 10:15:32,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742085_1261, type=LAST_IN_PIPELINE terminating
2019-06-07 10:15:37,297 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742080_1256 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742080 for deletion
2019-06-07 10:15:37,297 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742082_1258 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742082 for deletion
2019-06-07 10:15:37,297 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742040_1216 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742040 for deletion
2019-06-07 10:15:37,297 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742041_1217 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742041 for deletion
2019-06-07 10:15:37,297 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742042_1218 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742042 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742043_1219 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742043 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742044_1220 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742044 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742045_1221 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742045 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742046_1222 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742046 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742048_1224 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742048 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742049_1225 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742049 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742050_1226 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742050 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742051_1227 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742051 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742052_1228 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742052 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742053_1229 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742053 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742054_1230 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742054 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742055_1231 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742055 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742056_1232 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742056 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742057_1233 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742057 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742058_1234 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742058 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742059_1235 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742059 for deletion
2019-06-07 10:15:37,298 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742060_1236 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742060 for deletion
2019-06-07 10:15:37,300 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742080_1256 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742080
2019-06-07 10:15:37,301 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742082_1258 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742082
2019-06-07 10:15:37,301 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742040_1216 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742040
2019-06-07 10:15:37,301 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742041_1217 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742041
2019-06-07 10:15:37,301 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742042_1218 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742042
2019-06-07 10:15:37,301 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742043_1219 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742043
2019-06-07 10:15:37,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742044_1220 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742044
2019-06-07 10:15:37,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742045_1221 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742045
2019-06-07 10:15:37,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742046_1222 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742046
2019-06-07 10:15:37,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742048_1224 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742048
2019-06-07 10:15:37,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742049_1225 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742049
2019-06-07 10:15:37,302 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742050_1226 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742050
2019-06-07 10:15:37,306 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742061_1237 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742061 for deletion
2019-06-07 10:15:37,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742062_1238 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742062 for deletion
2019-06-07 10:15:37,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742063_1239 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742063 for deletion
2019-06-07 10:15:37,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742064_1240 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742064 for deletion
2019-06-07 10:15:37,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742065_1241 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742065 for deletion
2019-06-07 10:15:37,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742066_1242 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742066 for deletion
2019-06-07 10:15:37,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742067_1243 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742067 for deletion
2019-06-07 10:15:37,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742068_1244 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742068 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742069_1245 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742069 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742070_1246 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742070 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742071_1247 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742071 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742072_1248 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742072 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742073_1249 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742073 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742074_1250 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742074 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742075_1251 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742075 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742076_1252 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742076 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742077_1253 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742077 for deletion
2019-06-07 10:15:37,308 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742078_1254 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742078 for deletion
2019-06-07 10:15:37,309 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742051_1227 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742051
2019-06-07 10:15:37,309 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742052_1228 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742052
2019-06-07 10:15:37,309 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742053_1229 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742053
2019-06-07 10:15:37,310 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742054_1230 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742054
2019-06-07 10:15:37,310 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742055_1231 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742055
2019-06-07 10:15:37,310 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742056_1232 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742056
2019-06-07 10:15:37,310 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742057_1233 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742057
2019-06-07 10:15:37,311 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742058_1234 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742058
2019-06-07 10:15:37,311 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742059_1235 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742059
2019-06-07 10:15:37,311 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742060_1236 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742060
2019-06-07 10:15:37,311 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742061_1237 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742061
2019-06-07 10:15:37,311 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742062_1238 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742062
2019-06-07 10:15:37,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742063_1239 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742063
2019-06-07 10:15:37,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742064_1240 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742064
2019-06-07 10:15:37,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742065_1241 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742065
2019-06-07 10:15:37,313 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742066_1242 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742066
2019-06-07 10:15:37,313 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742067_1243 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742067
2019-06-07 10:15:37,314 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742068_1244 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742068
2019-06-07 10:15:37,314 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742069_1245 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742069
2019-06-07 10:15:37,312 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742079_1255 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742079 for deletion
2019-06-07 10:15:37,316 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742070_1246 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742070
2019-06-07 10:15:37,316 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742071_1247 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742071
2019-06-07 10:15:37,316 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742072_1248 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742072
2019-06-07 10:15:37,317 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742073_1249 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742073
2019-06-07 10:15:37,317 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742074_1250 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742074
2019-06-07 10:15:37,317 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742075_1251 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742075
2019-06-07 10:15:37,317 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742076_1252 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742076
2019-06-07 10:15:37,317 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742077_1253 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742077
2019-06-07 10:15:37,317 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742078_1254 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742078
2019-06-07 10:15:37,317 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742079_1255 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir0/blk_1073742079
2019-06-07 12:59:42,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x820ce55d2d659249,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 1 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-07 12:59:42,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-07 13:18:22,482 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-07 16:40:06,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-07 16:40:06,930 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-07 16:40:07,769 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-07 16:40:08,702 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-07 16:40:08,921 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-07 16:40:09,240 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-07 16:40:09,240 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-07 16:40:09,295 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-07 16:40:09,302 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-07 16:40:09,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-07 16:40:09,309 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-07 16:40:09,317 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-07 16:40:09,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-07 16:40:09,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-07 16:40:09,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-07 16:40:09,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-07 16:40:09,772 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-07 16:40:09,834 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-07 16:40:09,926 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-07 16:40:09,953 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-07 16:40:09,968 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-07 16:40:09,975 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-07 16:40:09,975 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-07 16:40:10,035 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38895
2019-06-07 16:40:10,035 INFO org.mortbay.log: jetty-6.1.26
2019-06-07 16:40:11,176 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38895
2019-06-07 16:40:11,504 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-07 16:40:11,539 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-07 16:40:12,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-07 16:40:12,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-07 16:40:12,750 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-07 16:40:12,809 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-07 16:40:12,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-07 16:40:13,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-07 16:40:13,040 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-07 16:40:13,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-07 16:40:13,080 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-07 16:40:13,082 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-07 16:40:13,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-07 16:40:13,791 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-07 16:40:13,810 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 2079@master
2019-06-07 16:40:13,975 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-07 16:40:13,975 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-07 16:40:13,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-07 16:40:14,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-07 16:40:14,179 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-07 16:40:14,197 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-07 16:40:14,226 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-07 16:40:14,259 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-07 16:40:14,260 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-07 16:40:14,269 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-07 16:40:14,410 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 140ms
2019-06-07 16:40:14,411 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 145ms
2019-06-07 16:40:14,416 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-07 16:40:14,416 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-07 16:40:14,500 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 83ms
2019-06-07 16:40:14,506 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 93ms
2019-06-07 16:40:14,756 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 1550014394 ms.
2019-06-07 16:40:14,796 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 7 오후 10:17 with interval of 21600000ms
2019-06-07 16:40:14,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-06-07 16:40:15,039 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-06-07 16:40:15,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-07 16:40:15,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad921,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 23 msec to generate and 222 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-07 16:40:15,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-07 21:39:07,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad922,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-07 21:39:07,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-07 22:17:38,836 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-08 03:39:09,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad923,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-08 03:39:09,960 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-08 04:17:38,816 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-08 09:39:09,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad924,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-08 09:39:09,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-08 10:17:38,822 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-08 15:39:08,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad925,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-08 15:39:08,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-08 16:17:38,814 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-08 21:39:08,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad926,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-08 21:39:08,560 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-08 22:17:38,808 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-09 03:39:08,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad927,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-09 03:39:08,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-09 04:17:38,808 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-09 09:39:07,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad928,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-09 09:39:07,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-09 10:17:38,803 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-09 15:39:07,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad929,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-09 15:39:07,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-09 16:17:38,804 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-09 21:39:10,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad92a,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-09 21:39:10,055 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-09 22:17:38,800 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-10 03:39:09,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad92b,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-10 03:39:09,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-10 04:17:38,801 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-10 09:39:09,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad92c,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 1 msec to generate and 0 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-10 09:39:09,621 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-10 10:17:38,801 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-10 15:39:09,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad92d,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-10 15:39:09,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-10 16:17:38,802 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-10 21:39:08,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad92e,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-10 21:39:08,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-10 22:17:38,806 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-11 03:39:08,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad92f,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-11 03:39:08,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-11 04:17:38,801 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-11 09:39:07,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad930,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-11 09:39:07,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-11 10:17:38,804 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-11 15:39:09,752 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1cbbd5916b5ad931,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 2 msec to generate and 27 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-11 15:39:09,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-11 16:17:38,814 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 64, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-14 09:23:13,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-14 09:23:13,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-14 09:23:14,025 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-14 09:23:14,611 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-14 09:23:14,729 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-14 09:23:14,918 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-14 09:23:14,918 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-14 09:23:14,925 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 09:23:14,927 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-14 09:23:14,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-14 09:23:14,932 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 09:23:14,932 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-14 09:23:14,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-14 09:23:14,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-14 09:23:15,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-14 09:23:15,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-14 09:23:15,146 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-14 09:23:15,164 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:23:15,204 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-14 09:23:15,217 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:23:15,219 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-14 09:23:15,220 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:23:15,220 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:23:15,243 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46290
2019-06-14 09:23:15,243 INFO org.mortbay.log: jetty-6.1.26
2019-06-14 09:23:15,801 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46290
2019-06-14 09:23:15,941 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-14 09:23:15,951 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-14 09:23:16,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-14 09:23:16,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-14 09:23:16,702 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-14 09:23:16,752 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-14 09:23:16,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-14 09:23:16,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-14 09:23:17,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-14 09:23:17,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-14 09:23:17,140 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-14 09:23:17,142 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-14 09:23:18,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:19,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:20,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:21,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:22,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:23,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:24,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:25,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:26,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:27,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:27,484 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-06-14 09:23:33,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:34,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:35,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:36,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:37,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:38,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:39,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:40,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:41,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:42,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:42,506 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-06-14 09:23:48,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:49,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:50,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:51,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:52,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:53,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:54,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:55,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:56,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:57,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:23:57,528 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-06-14 09:24:03,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:04,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:05,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:06,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:07,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:08,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:09,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:10,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:11,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:12,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:12,543 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-06-14 09:24:18,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:19,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:20,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:21,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:22,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:23,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:24,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:25,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:26,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:27,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:24:27,559 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2019-06-14 09:24:32,043 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-14 09:24:32,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-14 09:25:29,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-14 09:25:29,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-14 09:25:29,946 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-14 09:25:30,633 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-14 09:25:30,748 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-14 09:25:30,926 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-14 09:25:30,927 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-14 09:25:30,939 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 09:25:30,941 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-14 09:25:30,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-14 09:25:30,945 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 09:25:30,945 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-14 09:25:30,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-14 09:25:30,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-14 09:25:31,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-14 09:25:31,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-14 09:25:31,175 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-14 09:25:31,207 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:25:31,266 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-14 09:25:31,277 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:25:31,285 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-14 09:25:31,288 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:25:31,288 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:25:31,327 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43281
2019-06-14 09:25:31,327 INFO org.mortbay.log: jetty-6.1.26
2019-06-14 09:25:32,376 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43281
2019-06-14 09:25:32,765 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-14 09:25:32,798 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-14 09:25:34,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-14 09:25:34,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-14 09:25:34,265 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-14 09:25:34,325 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-14 09:25:34,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-14 09:25:34,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-14 09:25:34,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-14 09:25:34,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-14 09:25:34,745 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-14 09:25:34,753 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-14 09:25:35,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-14 09:25:35,401 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-14 09:25:35,422 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 4141@master
2019-06-14 09:25:35,548 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-14 09:25:35,548 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-14 09:25:35,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-14 09:25:35,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-14 09:25:35,695 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-14 09:25:35,707 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-14 09:25:35,727 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 09:25:35,750 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-14 09:25:35,756 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 09:25:35,761 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 09:25:35,861 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 100ms
2019-06-14 09:25:35,862 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 106ms
2019-06-14 09:25:35,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 09:25:35,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-14 09:25:35,945 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 72ms
2019-06-14 09:25:35,945 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 81ms
2019-06-14 09:25:36,162 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 971292988 ms.
2019-06-14 09:25:36,184 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 14 오후 2:18 with interval of 21600000ms
2019-06-14 09:25:36,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-06-14 09:25:36,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-06-14 09:25:36,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-14 09:25:36,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xb043276b775f5c11,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 16 msec to generate and 185 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-14 09:25:36,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 09:34:27,143 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-14 09:34:27,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-14 09:36:18,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-14 09:36:18,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-14 09:36:19,235 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-14 09:36:19,921 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-14 09:36:20,020 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-14 09:36:20,190 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-14 09:36:20,190 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-14 09:36:20,202 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 09:36:20,204 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-14 09:36:20,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-14 09:36:20,208 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 09:36:20,208 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-14 09:36:20,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-14 09:36:20,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-14 09:36:20,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-14 09:36:20,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-14 09:36:20,442 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-14 09:36:20,462 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:36:20,501 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-14 09:36:20,512 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:36:20,521 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-14 09:36:20,522 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:36:20,522 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:36:20,557 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45393
2019-06-14 09:36:20,560 INFO org.mortbay.log: jetty-6.1.26
2019-06-14 09:36:21,582 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45393
2019-06-14 09:36:21,918 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-14 09:36:21,935 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-14 09:36:23,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-14 09:36:23,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-14 09:36:23,338 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-14 09:36:23,399 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-14 09:36:23,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-14 09:36:23,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-14 09:36:23,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-14 09:36:23,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-06-14 09:36:23,840 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-14 09:36:23,846 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-14 09:36:24,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-06-14 09:36:24,794 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-14 09:36:24,806 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 3134@master
2019-06-14 09:36:24,923 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-14 09:36:24,923 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-14 09:36:24,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-14 09:36:25,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-14 09:36:25,076 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-14 09:36:25,092 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-14 09:36:25,110 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 09:36:25,148 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-14 09:36:25,149 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 09:36:25,151 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 09:36:25,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current: 10526720
2019-06-14 09:36:25,235 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 84ms
2019-06-14 09:36:25,235 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 86ms
2019-06-14 09:36:25,241 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 09:36:25,241 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-14 09:36:25,299 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 58ms
2019-06-14 09:36:25,299 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 63ms
2019-06-14 09:36:25,482 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 970643668 ms.
2019-06-14 09:36:25,501 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 14 오후 12:21 with interval of 21600000ms
2019-06-14 09:36:25,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-06-14 09:36:25,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-06-14 09:36:25,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-14 09:36:26,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x9e5c5c3084d0ad19,  containing 1 storage report(s), of which we sent 1. The reports had 64 total blocks and used 1 RPC(s). This took 19 msec to generate and 220 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-14 09:36:26,139 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 09:45:55,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742086_1262 src: /127.0.0.1:44660 dest: /127.0.0.1:50010
2019-06-14 09:45:55,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44660, dest: /127.0.0.1:50010, bytes: 1033299, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742086_1262, duration(ns): 157201586
2019-06-14 09:45:55,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742086_1262, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742087_1263 src: /127.0.0.1:44662 dest: /127.0.0.1:50010
2019-06-14 09:45:56,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44662, dest: /127.0.0.1:50010, bytes: 375618, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742087_1263, duration(ns): 2410306
2019-06-14 09:45:56,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742087_1263, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742088_1264 src: /127.0.0.1:44664 dest: /127.0.0.1:50010
2019-06-14 09:45:56,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44664, dest: /127.0.0.1:50010, bytes: 914311, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742088_1264, duration(ns): 22755959
2019-06-14 09:45:56,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742088_1264, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742089_1265 src: /127.0.0.1:44666 dest: /127.0.0.1:50010
2019-06-14 09:45:56,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44666, dest: /127.0.0.1:50010, bytes: 267634, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742089_1265, duration(ns): 2963430
2019-06-14 09:45:56,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742089_1265, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,742 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742090_1266 src: /127.0.0.1:44668 dest: /127.0.0.1:50010
2019-06-14 09:45:56,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44668, dest: /127.0.0.1:50010, bytes: 25496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742090_1266, duration(ns): 1359799
2019-06-14 09:45:56,767 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742090_1266, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742091_1267 src: /127.0.0.1:44670 dest: /127.0.0.1:50010
2019-06-14 09:45:56,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44670, dest: /127.0.0.1:50010, bytes: 232248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742091_1267, duration(ns): 3039249
2019-06-14 09:45:56,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742091_1267, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742092_1268 src: /127.0.0.1:44672 dest: /127.0.0.1:50010
2019-06-14 09:45:56,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44672, dest: /127.0.0.1:50010, bytes: 20998, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742092_1268, duration(ns): 1090082
2019-06-14 09:45:56,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742092_1268, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742093_1269 src: /127.0.0.1:44674 dest: /127.0.0.1:50010
2019-06-14 09:45:56,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44674, dest: /127.0.0.1:50010, bytes: 1007502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742093_1269, duration(ns): 9740957
2019-06-14 09:45:56,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742093_1269, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742094_1270 src: /127.0.0.1:44676 dest: /127.0.0.1:50010
2019-06-14 09:45:56,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44676, dest: /127.0.0.1:50010, bytes: 60686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742094_1270, duration(ns): 1234650
2019-06-14 09:45:56,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742094_1270, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,947 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742095_1271 src: /127.0.0.1:44678 dest: /127.0.0.1:50010
2019-06-14 09:45:56,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44678, dest: /127.0.0.1:50010, bytes: 197986, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742095_1271, duration(ns): 2416629
2019-06-14 09:45:56,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742095_1271, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:56,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742096_1272 src: /127.0.0.1:44680 dest: /127.0.0.1:50010
2019-06-14 09:45:57,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44680, dest: /127.0.0.1:50010, bytes: 1108073, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742096_1272, duration(ns): 21012013
2019-06-14 09:45:57,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742096_1272, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742097_1273 src: /127.0.0.1:44682 dest: /127.0.0.1:50010
2019-06-14 09:45:57,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44682, dest: /127.0.0.1:50010, bytes: 224277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742097_1273, duration(ns): 1899072
2019-06-14 09:45:57,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742097_1273, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742098_1274 src: /127.0.0.1:44684 dest: /127.0.0.1:50010
2019-06-14 09:45:57,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44684, dest: /127.0.0.1:50010, bytes: 434678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742098_1274, duration(ns): 2047876
2019-06-14 09:45:57,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742098_1274, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742099_1275 src: /127.0.0.1:44686 dest: /127.0.0.1:50010
2019-06-14 09:45:57,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44686, dest: /127.0.0.1:50010, bytes: 109043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742099_1275, duration(ns): 2649369
2019-06-14 09:45:57,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742099_1275, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742100_1276 src: /127.0.0.1:44688 dest: /127.0.0.1:50010
2019-06-14 09:45:57,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44688, dest: /127.0.0.1:50010, bytes: 780664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742100_1276, duration(ns): 11783991
2019-06-14 09:45:57,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742100_1276, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742101_1277 src: /127.0.0.1:44690 dest: /127.0.0.1:50010
2019-06-14 09:45:57,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44690, dest: /127.0.0.1:50010, bytes: 706710, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742101_1277, duration(ns): 1858985
2019-06-14 09:45:57,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742101_1277, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742102_1278 src: /127.0.0.1:44692 dest: /127.0.0.1:50010
2019-06-14 09:45:57,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44692, dest: /127.0.0.1:50010, bytes: 1007502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742102_1278, duration(ns): 6530847
2019-06-14 09:45:57,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742102_1278, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742103_1279 src: /127.0.0.1:44694 dest: /127.0.0.1:50010
2019-06-14 09:45:57,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44694, dest: /127.0.0.1:50010, bytes: 1765905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742103_1279, duration(ns): 19378772
2019-06-14 09:45:57,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742103_1279, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742104_1280 src: /127.0.0.1:44696 dest: /127.0.0.1:50010
2019-06-14 09:45:57,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44696, dest: /127.0.0.1:50010, bytes: 20744, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742104_1280, duration(ns): 3871086
2019-06-14 09:45:57,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742104_1280, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742105_1281 src: /127.0.0.1:44698 dest: /127.0.0.1:50010
2019-06-14 09:45:57,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44698, dest: /127.0.0.1:50010, bytes: 279012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742105_1281, duration(ns): 8603110
2019-06-14 09:45:57,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742105_1281, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742106_1282 src: /127.0.0.1:44700 dest: /127.0.0.1:50010
2019-06-14 09:45:57,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44700, dest: /127.0.0.1:50010, bytes: 58160, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742106_1282, duration(ns): 893907
2019-06-14 09:45:57,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742106_1282, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742107_1283 src: /127.0.0.1:44702 dest: /127.0.0.1:50010
2019-06-14 09:45:57,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44702, dest: /127.0.0.1:50010, bytes: 1801469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742107_1283, duration(ns): 16216029
2019-06-14 09:45:57,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742107_1283, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742108_1284 src: /127.0.0.1:44704 dest: /127.0.0.1:50010
2019-06-14 09:45:57,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44704, dest: /127.0.0.1:50010, bytes: 205389, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742108_1284, duration(ns): 692709
2019-06-14 09:45:57,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742108_1284, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:57,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742109_1285 src: /127.0.0.1:44706 dest: /127.0.0.1:50010
2019-06-14 09:45:57,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44706, dest: /127.0.0.1:50010, bytes: 53464, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742109_1285, duration(ns): 934865
2019-06-14 09:45:58,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742109_1285, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742110_1286 src: /127.0.0.1:44708 dest: /127.0.0.1:50010
2019-06-14 09:45:58,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44708, dest: /127.0.0.1:50010, bytes: 592319, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742110_1286, duration(ns): 2200788
2019-06-14 09:45:58,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742110_1286, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742111_1287 src: /127.0.0.1:44710 dest: /127.0.0.1:50010
2019-06-14 09:45:58,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44710, dest: /127.0.0.1:50010, bytes: 892808, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742111_1287, duration(ns): 6518433
2019-06-14 09:45:58,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742111_1287, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742112_1288 src: /127.0.0.1:44712 dest: /127.0.0.1:50010
2019-06-14 09:45:58,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44712, dest: /127.0.0.1:50010, bytes: 36455, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742112_1288, duration(ns): 2858630
2019-06-14 09:45:58,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742112_1288, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742113_1289 src: /127.0.0.1:44714 dest: /127.0.0.1:50010
2019-06-14 09:45:58,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44714, dest: /127.0.0.1:50010, bytes: 99555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742113_1289, duration(ns): 735598
2019-06-14 09:45:58,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742113_1289, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,221 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742114_1290 src: /127.0.0.1:44716 dest: /127.0.0.1:50010
2019-06-14 09:45:58,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44716, dest: /127.0.0.1:50010, bytes: 2178774, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742114_1290, duration(ns): 18134438
2019-06-14 09:45:58,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742114_1290, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742115_1291 src: /127.0.0.1:44718 dest: /127.0.0.1:50010
2019-06-14 09:45:58,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44718, dest: /127.0.0.1:50010, bytes: 36519, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742115_1291, duration(ns): 822866
2019-06-14 09:45:58,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742115_1291, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742116_1292 src: /127.0.0.1:44720 dest: /127.0.0.1:50010
2019-06-14 09:45:58,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44720, dest: /127.0.0.1:50010, bytes: 186260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742116_1292, duration(ns): 1084627
2019-06-14 09:45:58,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742116_1292, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742117_1293 src: /127.0.0.1:44722 dest: /127.0.0.1:50010
2019-06-14 09:45:58,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44722, dest: /127.0.0.1:50010, bytes: 19827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742117_1293, duration(ns): 682154
2019-06-14 09:45:58,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742117_1293, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742118_1294 src: /127.0.0.1:44724 dest: /127.0.0.1:50010
2019-06-14 09:45:58,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44724, dest: /127.0.0.1:50010, bytes: 34604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742118_1294, duration(ns): 730272
2019-06-14 09:45:58,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742118_1294, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742119_1295 src: /127.0.0.1:44726 dest: /127.0.0.1:50010
2019-06-14 09:45:58,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44726, dest: /127.0.0.1:50010, bytes: 1344870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742119_1295, duration(ns): 5177924
2019-06-14 09:45:58,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742119_1295, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742120_1296 src: /127.0.0.1:44728 dest: /127.0.0.1:50010
2019-06-14 09:45:58,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44728, dest: /127.0.0.1:50010, bytes: 1768012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742120_1296, duration(ns): 13397641
2019-06-14 09:45:58,460 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742120_1296, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742121_1297 src: /127.0.0.1:44730 dest: /127.0.0.1:50010
2019-06-14 09:45:58,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44730, dest: /127.0.0.1:50010, bytes: 365552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742121_1297, duration(ns): 1039526
2019-06-14 09:45:58,505 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742121_1297, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742122_1298 src: /127.0.0.1:44732 dest: /127.0.0.1:50010
2019-06-14 09:45:58,528 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44732, dest: /127.0.0.1:50010, bytes: 9442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742122_1298, duration(ns): 685298
2019-06-14 09:45:58,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742122_1298, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,608 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742123_1299 src: /127.0.0.1:44736 dest: /127.0.0.1:50010
2019-06-14 09:45:58,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44736, dest: /127.0.0.1:50010, bytes: 94, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742123_1299, duration(ns): 571694
2019-06-14 09:45:58,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742123_1299, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742124_1300 src: /127.0.0.1:44738 dest: /127.0.0.1:50010
2019-06-14 09:45:58,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44738, dest: /127.0.0.1:50010, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742124_1300, duration(ns): 670624
2019-06-14 09:45:58,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742124_1300, type=LAST_IN_PIPELINE terminating
2019-06-14 09:45:58,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742093_1269 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742093 for deletion
2019-06-14 09:45:58,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742093_1269 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742093
2019-06-14 09:45:59,099 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742125_1301 src: /127.0.0.1:44740 dest: /127.0.0.1:50010
2019-06-14 09:45:59,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44740, dest: /127.0.0.1:50010, bytes: 176908, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1620096232_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742125_1301, duration(ns): 17943585
2019-06-14 09:45:59,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742125_1301, type=LAST_IN_PIPELINE terminating
2019-06-14 09:46:14,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742126_1302 src: /127.0.0.1:44758 dest: /127.0.0.1:50010
2019-06-14 09:46:14,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44758, dest: /127.0.0.1:50010, bytes: 204046, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1576145226_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742126_1302, duration(ns): 11092661
2019-06-14 09:46:14,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742126_1302, type=LAST_IN_PIPELINE terminating
2019-06-14 09:46:22,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742127_1303 src: /127.0.0.1:44770 dest: /127.0.0.1:50010
2019-06-14 09:46:23,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44770, dest: /127.0.0.1:50010, bytes: 638330, op: HDFS_WRITE, cliID: DFSClient_attempt_1560472599224_0001_m_000000_0_-1626626470_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742127_1303, duration(ns): 468541514
2019-06-14 09:46:23,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742127_1303, type=LAST_IN_PIPELINE terminating
2019-06-14 09:46:23,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742128_1304 src: /127.0.0.1:44772 dest: /127.0.0.1:50010
2019-06-14 09:46:23,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44772, dest: /127.0.0.1:50010, bytes: 21139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1576145226_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742128_1304, duration(ns): 209713645
2019-06-14 09:46:23,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742128_1304, type=LAST_IN_PIPELINE terminating
2019-06-14 09:46:23,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742129_1305 src: /127.0.0.1:44774 dest: /127.0.0.1:50010
2019-06-14 09:46:23,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44774, dest: /127.0.0.1:50010, bytes: 338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1576145226_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742129_1305, duration(ns): 16439850
2019-06-14 09:46:23,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742129_1305, type=LAST_IN_PIPELINE terminating
2019-06-14 09:46:24,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742130_1306 src: /127.0.0.1:44778 dest: /127.0.0.1:50010
2019-06-14 09:46:24,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44778, dest: /127.0.0.1:50010, bytes: 21139, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1576145226_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742130_1306, duration(ns): 3509828
2019-06-14 09:46:24,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742130_1306, type=LAST_IN_PIPELINE terminating
2019-06-14 09:46:24,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742131_1307 src: /127.0.0.1:44780 dest: /127.0.0.1:50010
2019-06-14 09:46:24,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44780, dest: /127.0.0.1:50010, bytes: 204046, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1576145226_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742131_1307, duration(ns): 983018
2019-06-14 09:46:24,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742131_1307, type=LAST_IN_PIPELINE terminating
2019-06-14 09:46:28,830 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742086_1262 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742086 for deletion
2019-06-14 09:46:28,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742086_1262 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742086
2019-06-14 09:46:28,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742087_1263 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742087 for deletion
2019-06-14 09:46:28,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742088_1264 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742088 for deletion
2019-06-14 09:46:28,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742089_1265 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742089 for deletion
2019-06-14 09:46:28,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742090_1266 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742090 for deletion
2019-06-14 09:46:28,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742091_1267 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742091 for deletion
2019-06-14 09:46:28,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742092_1268 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742092 for deletion
2019-06-14 09:46:28,832 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742094_1270 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742094 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742095_1271 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742095 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742096_1272 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742096 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742097_1273 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742097 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742098_1274 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742098 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742099_1275 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742099 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742100_1276 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742100 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742101_1277 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742101 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742102_1278 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742102 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742103_1279 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742103 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742104_1280 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742104 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742105_1281 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742105 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742106_1282 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742106 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742107_1283 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742107 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742108_1284 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742108 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742109_1285 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742109 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742110_1286 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742110 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742111_1287 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742111 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742112_1288 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742112 for deletion
2019-06-14 09:46:28,833 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742113_1289 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742113 for deletion
2019-06-14 09:46:28,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742087_1263 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742087
2019-06-14 09:46:28,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742088_1264 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742088
2019-06-14 09:46:28,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742089_1265 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742089
2019-06-14 09:46:28,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742090_1266 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742090
2019-06-14 09:46:28,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742091_1267 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742091
2019-06-14 09:46:28,835 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742092_1268 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742092
2019-06-14 09:46:28,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742094_1270 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742094
2019-06-14 09:46:28,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742095_1271 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742095
2019-06-14 09:46:28,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742096_1272 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742096
2019-06-14 09:46:28,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742097_1273 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742097
2019-06-14 09:46:28,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742098_1274 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742098
2019-06-14 09:46:28,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742099_1275 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742099
2019-06-14 09:46:28,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742100_1276 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742100
2019-06-14 09:46:28,836 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742101_1277 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742101
2019-06-14 09:46:28,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742102_1278 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742102
2019-06-14 09:46:28,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742103_1279 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742103
2019-06-14 09:46:28,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742104_1280 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742104
2019-06-14 09:46:28,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742105_1281 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742105
2019-06-14 09:46:28,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742106_1282 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742106
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742114_1290 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742114 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742115_1291 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742115 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742116_1292 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742116 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742117_1293 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742117 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742118_1294 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742118 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742119_1295 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742119 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742120_1296 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742120 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742121_1297 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742121 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742122_1298 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742122 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742123_1299 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742123 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742124_1300 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742124 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742125_1301 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742125 for deletion
2019-06-14 09:46:28,840 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742126_1302 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742126 for deletion
2019-06-14 09:46:28,841 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742128_1304 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742128 for deletion
2019-06-14 09:46:28,844 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742107_1283 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742107
2019-06-14 09:46:28,844 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742108_1284 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742108
2019-06-14 09:46:28,844 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742109_1285 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742109
2019-06-14 09:46:28,844 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742110_1286 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742110
2019-06-14 09:46:28,844 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742111_1287 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742111
2019-06-14 09:46:28,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742112_1288 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742112
2019-06-14 09:46:28,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742113_1289 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742113
2019-06-14 09:46:28,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742114_1290 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742114
2019-06-14 09:46:28,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742115_1291 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742115
2019-06-14 09:46:28,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742116_1292 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742116
2019-06-14 09:46:28,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742117_1293 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742117
2019-06-14 09:46:28,845 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742118_1294 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742118
2019-06-14 09:46:28,846 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742119_1295 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742119
2019-06-14 09:46:28,846 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742120_1296 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742120
2019-06-14 09:46:28,846 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742121_1297 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742121
2019-06-14 09:46:28,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742122_1298 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742122
2019-06-14 09:46:28,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742123_1299 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742123
2019-06-14 09:46:28,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742124_1300 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742124
2019-06-14 09:46:28,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742125_1301 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742125
2019-06-14 09:46:28,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742126_1302 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742126
2019-06-14 09:46:28,847 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742128_1304 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742128
2019-06-14 10:04:40,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742132_1308 src: /127.0.0.1:44828 dest: /127.0.0.1:50010
2019-06-14 10:04:40,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44828, dest: /127.0.0.1:50010, bytes: 2310165, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1273831300_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742132_1308, duration(ns): 44108324
2019-06-14 10:04:40,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742132_1308, type=LAST_IN_PIPELINE terminating
2019-06-14 10:05:14,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742133_1309 src: /127.0.0.1:44836 dest: /127.0.0.1:50010
2019-06-14 10:05:14,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:44836, dest: /127.0.0.1:50010, bytes: 2310165, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_871175687_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742133_1309, duration(ns): 41077793
2019-06-14 10:05:14,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742133_1309, type=LAST_IN_PIPELINE terminating
2019-06-14 10:47:11,702 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-06-14 10:47:14,761 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-14 10:47:14,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-14 10:47:53,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-14 10:47:53,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-14 10:47:53,677 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-14 10:47:54,354 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-14 10:47:54,446 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-14 10:47:54,594 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-14 10:47:54,594 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-14 10:47:54,612 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 10:47:54,617 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-14 10:47:54,620 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-14 10:47:54,621 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 10:47:54,621 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-14 10:47:54,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-14 10:47:54,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-14 10:47:54,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-14 10:47:54,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-14 10:47:54,816 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-14 10:47:54,835 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 10:47:54,871 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-14 10:47:54,889 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 10:47:54,893 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-14 10:47:54,900 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 10:47:54,900 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 10:47:54,932 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45654
2019-06-14 10:47:54,932 INFO org.mortbay.log: jetty-6.1.26
2019-06-14 10:47:55,551 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45654
2019-06-14 10:47:55,800 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-14 10:47:55,818 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-14 10:47:56,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-14 10:47:56,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-14 10:47:57,167 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-14 10:47:57,222 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-14 10:47:57,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-14 10:47:57,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-14 10:47:57,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-14 10:47:57,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000 starting to offer service
2019-06-14 10:47:57,667 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-14 10:47:57,672 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-14 10:47:58,746 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000
2019-06-14 10:47:58,762 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-14 10:47:58,794 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 9851@master
2019-06-14 10:47:58,980 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-14 10:47:58,980 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-14 10:47:58,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-14 10:47:59,196 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-14 10:47:59,196 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-14 10:47:59,226 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-14 10:47:59,255 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 10:47:59,289 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-14 10:47:59,290 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 10:47:59,299 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 10:47:59,345 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current: 16089088
2019-06-14 10:47:59,407 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 107ms
2019-06-14 10:47:59,407 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 111ms
2019-06-14 10:47:59,411 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 10:47:59,411 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-14 10:47:59,491 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 80ms
2019-06-14 10:47:59,494 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 85ms
2019-06-14 10:47:59,743 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 966349407 ms.
2019-06-14 10:47:59,781 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 14 오후 1:49 with interval of 21600000ms
2019-06-14 10:47:59,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 beginning handshake with NN
2019-06-14 10:47:59,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 successfully registered with NN
2019-06-14 10:47:59,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/192.168.56.180:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-14 10:48:00,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xbcd758aa542fd62f,  containing 1 storage report(s), of which we sent 1. The reports had 70 total blocks and used 1 RPC(s). This took 24 msec to generate and 228 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-14 10:48:00,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 10:50:30,550 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 10:50:30,551 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 10:50:32,572 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 966196578 ms.
2019-06-14 10:52:20,279 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 10:52:20,279 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 파이프가 깨어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:03:10,529 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:03:10,534 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:03:12,054 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 965437096 ms.
2019-06-14 11:12:28,142 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:12:28,142 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:17:03,650 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:17:03,650 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 파이프가 깨어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:17:25,098 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:17:25,098 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 파이프가 깨어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:30:25,922 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:30:25,933 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 파이프가 깨어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:30:27,937 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 963801213 ms.
2019-06-14 11:33:06,800 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:33:06,800 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:33:21,571 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:33:21,571 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:34:53,480 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:34:53,480 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 파이프가 깨어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:35:19,517 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:35:19,518 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:40:43,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742134_1310 src: /192.168.56.180:45918 dest: /192.168.56.180:50010
2019-06-14 11:40:43,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:45918, dest: /192.168.56.180:50010, bytes: 428996, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1539386033_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742134_1310, duration(ns): 15534960
2019-06-14 11:40:43,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742134_1310, type=LAST_IN_PIPELINE terminating
2019-06-14 11:56:58,949 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 11:56:58,953 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 11:57:00,458 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 962208692 ms.
2019-06-14 12:01:09,191 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 12:01:09,191 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 파이프가 깨어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 12:02:11,322 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 12:02:11,322 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 12:17:49,479 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 12:17:49,492 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 12:17:51,495 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 960957655 ms.
2019-06-14 12:30:59,701 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-14 12:30:59,748 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-14 12:42:23,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-14 12:42:24,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-14 12:42:24,939 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-14 12:42:25,509 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-14 12:42:25,636 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-14 12:42:25,787 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-14 12:42:25,787 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-14 12:42:25,797 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 12:42:25,799 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-14 12:42:25,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-14 12:42:25,804 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 12:42:25,804 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-14 12:42:25,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-14 12:42:25,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-14 12:42:25,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-14 12:42:25,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-14 12:42:25,986 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-14 12:42:26,005 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 12:42:26,041 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-14 12:42:26,054 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 12:42:26,056 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-14 12:42:26,059 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 12:42:26,059 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 12:42:26,082 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46772
2019-06-14 12:42:26,082 INFO org.mortbay.log: jetty-6.1.26
2019-06-14 12:42:26,666 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46772
2019-06-14 12:42:26,823 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-14 12:42:26,835 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-14 12:42:27,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-14 12:42:27,449 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-14 12:42:27,530 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-14 12:42:27,561 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-14 12:42:27,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-14 12:42:27,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-14 12:42:27,764 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-14 12:42:27,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000 starting to offer service
2019-06-14 12:42:27,816 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-14 12:42:27,820 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-14 12:42:28,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000
2019-06-14 12:42:28,315 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-14 12:42:28,323 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 3936@master
2019-06-14 12:42:28,418 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-14 12:42:28,418 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-14 12:42:28,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-14 12:42:28,505 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-14 12:42:28,505 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-14 12:42:28,511 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-14 12:42:28,520 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 12:42:28,533 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-14 12:42:28,538 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 12:42:28,539 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 12:42:28,615 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 76ms
2019-06-14 12:42:28,615 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 77ms
2019-06-14 12:42:28,617 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 12:42:28,617 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-14 12:42:28,672 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 55ms
2019-06-14 12:42:28,672 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 56ms
2019-06-14 12:42:28,839 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 959480311 ms.
2019-06-14 12:42:28,864 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 14 오후 1:15 with interval of 21600000ms
2019-06-14 12:42:28,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 beginning handshake with NN
2019-06-14 12:42:28,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 successfully registered with NN
2019-06-14 12:42:28,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/192.168.56.180:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-14 12:42:29,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcf6fa4af6ee2904d,  containing 1 storage report(s), of which we sent 1. The reports had 71 total blocks and used 1 RPC(s). This took 13 msec to generate and 193 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-14 12:42:29,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 12:42:32,003 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "master":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-06-14 12:42:36,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/192.168.56.180:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 12:42:36,610 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-14 12:42:36,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-14 12:43:01,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-14 12:43:01,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-14 12:43:02,322 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-14 12:43:02,872 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-14 12:43:02,990 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-14 12:43:03,175 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-14 12:43:03,175 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-14 12:43:03,191 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 12:43:03,194 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-14 12:43:03,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-14 12:43:03,199 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-14 12:43:03,199 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-14 12:43:03,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-14 12:43:03,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-14 12:43:03,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-14 12:43:03,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-14 12:43:03,419 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-14 12:43:03,441 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 12:43:03,489 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-14 12:43:03,510 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 12:43:03,517 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-14 12:43:03,517 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 12:43:03,517 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 12:43:03,541 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44949
2019-06-14 12:43:03,541 INFO org.mortbay.log: jetty-6.1.26
2019-06-14 12:43:04,316 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:44949
2019-06-14 12:43:04,587 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-14 12:43:04,605 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-14 12:43:05,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-14 12:43:05,714 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-14 12:43:05,886 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-14 12:43:05,965 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-14 12:43:06,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-14 12:43:06,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-14 12:43:06,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-14 12:43:06,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000 starting to offer service
2019-06-14 12:43:06,484 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-14 12:43:06,489 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-14 12:43:07,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000
2019-06-14 12:43:07,429 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-14 12:43:07,449 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 4635@master
2019-06-14 12:43:07,565 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-14 12:43:07,565 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-14 12:43:07,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-14 12:43:07,682 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-14 12:43:07,682 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-14 12:43:07,688 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-14 12:43:07,702 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 12:43:07,718 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-14 12:43:07,719 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 12:43:07,722 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 12:43:07,746 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current: 16523264
2019-06-14 12:43:07,785 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 63ms
2019-06-14 12:43:07,786 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 65ms
2019-06-14 12:43:07,788 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-14 12:43:07,788 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-14 12:43:07,849 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 61ms
2019-06-14 12:43:07,851 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 64ms
2019-06-14 12:43:08,034 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 959441116 ms.
2019-06-14 12:43:08,057 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 14 오후 1:05 with interval of 21600000ms
2019-06-14 12:43:08,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 beginning handshake with NN
2019-06-14 12:43:08,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 successfully registered with NN
2019-06-14 12:43:08,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/192.168.56.180:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-14 12:43:08,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d0,  containing 1 storage report(s), of which we sent 1. The reports had 71 total blocks and used 1 RPC(s). This took 16 msec to generate and 237 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-14 12:43:08,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 12:44:38,961 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 12:44:38,962 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 12:44:40,977 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 959348173 ms.
2019-06-14 13:05:11,104 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 71, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-14 14:17:07,367 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 14:17:07,377 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 14:17:08,890 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 953800260 ms.
2019-06-14 14:26:36,597 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 14:26:36,597 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 파이프가 깨어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 14:26:36,598 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 953232552 ms.
2019-06-14 14:34:55,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742135_1311 src: /192.168.56.180:34772 dest: /192.168.56.180:50010
2019-06-14 14:34:55,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34772, dest: /192.168.56.180:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_656989701_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742135_1311, duration(ns): 21734379
2019-06-14 14:34:55,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742135_1311, type=LAST_IN_PIPELINE terminating
2019-06-14 15:10:50,793 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 15:10:50,808 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 15:10:52,810 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 950576340 ms.
2019-06-14 15:41:21,456 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-14 15:41:21,460 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: BlockSender.sendChunks() exception: 
java.io.IOException: 연결이 상대편에 의해 끊어짐
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectlyInternal(FileChannelImpl.java:428)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:493)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:605)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:223)
	at org.apache.hadoop.hdfs.server.datanode.FileIoProvider.transferToSocketFully(FileIoProvider.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendPacket(BlockSender.java:620)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.doSendBlock(BlockSender.java:804)
	at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:751)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:607)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opReadBlock(Receiver.java:145)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:100)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:288)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 15:41:22,964 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 948746186 ms.
2019-06-14 16:43:20,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d1,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 1 msec to generate and 25 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-14 16:43:20,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-14 19:05:11,091 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-14 22:43:21,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d2,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 1 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-14 22:43:21,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-15 01:05:11,083 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-15 04:43:21,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d3,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 1 msec to generate and 15 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-15 04:43:21,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-15 07:05:11,076 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-15 10:43:20,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d4,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 1 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-15 10:43:20,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-15 13:05:11,068 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-15 16:43:19,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d5,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 1 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-15 16:43:19,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-15 19:05:11,070 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-15 22:43:22,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d6,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-15 22:43:22,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-16 01:05:11,065 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-16 04:43:21,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d7,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-16 04:43:21,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-16 07:05:11,064 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-16 10:43:20,963 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d8,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-16 10:43:20,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-16 13:05:11,065 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-16 16:43:20,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5d9,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-16 16:43:20,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-16 19:05:11,068 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-16 22:43:19,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5da,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-16 22:43:19,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-17 01:05:11,065 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-17 04:43:21,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x14f689b8cbdaa5db,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-17 04:43:21,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-17 07:05:11,065 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 72, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-17 10:39:00,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-17 10:39:00,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-17 10:39:01,839 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-17 10:39:03,420 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-17 10:39:03,834 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-17 10:39:04,319 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-17 10:39:04,319 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-17 10:39:04,352 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-17 10:39:04,361 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-17 10:39:04,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-17 10:39:04,383 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-17 10:39:04,383 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-17 10:39:04,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-17 10:39:04,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-17 10:39:04,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-17 10:39:04,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-17 10:39:05,021 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-17 10:39:05,060 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-17 10:39:05,147 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-17 10:39:05,188 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-17 10:39:05,190 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-17 10:39:05,196 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-17 10:39:05,200 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-17 10:39:05,280 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35349
2019-06-17 10:39:05,280 INFO org.mortbay.log: jetty-6.1.26
2019-06-17 10:39:06,666 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:35349
2019-06-17 10:39:06,958 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-17 10:39:06,986 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-17 10:39:08,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-17 10:39:08,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-17 10:39:08,285 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-17 10:39:08,357 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-17 10:39:08,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-17 10:39:08,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-17 10:39:08,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-17 10:39:08,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000 starting to offer service
2019-06-17 10:39:08,908 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-17 10:39:08,913 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-17 10:39:10,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000
2019-06-17 10:39:10,270 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-17 10:39:10,296 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 7743@master
2019-06-17 10:39:10,544 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-17 10:39:10,544 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-17 10:39:10,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-17 10:39:10,794 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-17 10:39:10,794 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-17 10:39:10,821 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-17 10:39:10,849 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-17 10:39:10,904 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-17 10:39:10,905 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-17 10:39:10,919 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-17 10:39:11,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 137ms
2019-06-17 10:39:11,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 151ms
2019-06-17 10:39:11,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-17 10:39:11,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-17 10:39:11,177 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 107ms
2019-06-17 10:39:11,186 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 124ms
2019-06-17 10:39:11,503 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 707677647 ms.
2019-06-17 10:39:11,546 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 17 오후 3:37 with interval of 21600000ms
2019-06-17 10:39:11,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 beginning handshake with NN
2019-06-17 10:39:11,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 successfully registered with NN
2019-06-17 10:39:11,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/192.168.56.180:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-17 10:39:12,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x73555c50ebe594b2,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 21 msec to generate and 231 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-17 10:39:12,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-17 11:09:00,222 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "master":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-06-17 11:09:04,024 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-17 11:09:04,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-17 11:09:49,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-17 11:09:49,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-17 11:09:49,837 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-17 11:09:50,509 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-17 11:09:50,611 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-17 11:09:50,775 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-17 11:09:50,775 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-17 11:09:50,785 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-17 11:09:50,787 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-17 11:09:50,790 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-17 11:09:50,790 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-17 11:09:50,790 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-17 11:09:50,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-17 11:09:50,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-17 11:09:50,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-17 11:09:50,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-17 11:09:50,981 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-17 11:09:51,000 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-17 11:09:51,041 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-17 11:09:51,051 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-17 11:09:51,056 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-17 11:09:51,057 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-17 11:09:51,057 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-17 11:09:51,077 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37319
2019-06-17 11:09:51,077 INFO org.mortbay.log: jetty-6.1.26
2019-06-17 11:09:51,647 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:37319
2019-06-17 11:09:51,835 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-17 11:09:51,854 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-17 11:09:52,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-17 11:09:52,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-17 11:09:53,088 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-17 11:09:53,166 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-17 11:09:53,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-17 11:09:53,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-17 11:09:53,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-17 11:09:53,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000 starting to offer service
2019-06-17 11:09:53,661 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-17 11:09:53,664 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-17 11:09:54,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000
2019-06-17 11:09:54,564 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-17 11:09:54,578 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 12088@master
2019-06-17 11:09:54,721 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-17 11:09:54,721 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-17 11:09:54,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-17 11:09:54,907 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-17 11:09:54,907 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-17 11:09:54,920 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-17 11:09:54,943 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-17 11:09:54,969 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-17 11:09:54,975 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-17 11:09:54,982 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-17 11:09:55,019 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current: 16531456
2019-06-17 11:09:55,080 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 94ms
2019-06-17 11:09:55,080 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 104ms
2019-06-17 11:09:55,087 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-17 11:09:55,087 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-17 11:09:55,177 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 90ms
2019-06-17 11:09:55,185 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 103ms
2019-06-17 11:09:55,385 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 705833766 ms.
2019-06-17 11:09:55,405 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 17 오후 4:46 with interval of 21600000ms
2019-06-17 11:09:55,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 beginning handshake with NN
2019-06-17 11:09:55,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 successfully registered with NN
2019-06-17 11:09:55,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/192.168.56.180:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-17 11:09:55,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c74,  containing 1 storage report(s), of which we sent 1. The reports had 72 total blocks and used 1 RPC(s). This took 16 msec to generate and 137 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-17 11:09:55,828 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-17 11:14:54,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742136_1312 src: /192.168.56.180:34306 dest: /192.168.56.180:50010
2019-06-17 11:17:30,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34306, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1322016724_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742136_1312, duration(ns): 156566640031
2019-06-17 11:17:30,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742136_1312, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:15,923 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742137_1313 src: /192.168.56.180:34412 dest: /192.168.56.180:50010
2019-06-17 11:46:16,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34412, dest: /192.168.56.180:50010, bytes: 1033299, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742137_1313, duration(ns): 79125076
2019-06-17 11:46:16,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742137_1313, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:16,731 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742138_1314 src: /192.168.56.180:34414 dest: /192.168.56.180:50010
2019-06-17 11:46:16,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34414, dest: /192.168.56.180:50010, bytes: 375618, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742138_1314, duration(ns): 11834839
2019-06-17 11:46:16,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742138_1314, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:16,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742139_1315 src: /192.168.56.180:34416 dest: /192.168.56.180:50010
2019-06-17 11:46:16,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34416, dest: /192.168.56.180:50010, bytes: 914311, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742139_1315, duration(ns): 19486838
2019-06-17 11:46:16,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742139_1315, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742140_1316 src: /192.168.56.180:34418 dest: /192.168.56.180:50010
2019-06-17 11:46:17,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34418, dest: /192.168.56.180:50010, bytes: 267634, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742140_1316, duration(ns): 1869254
2019-06-17 11:46:17,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742140_1316, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742141_1317 src: /192.168.56.180:34420 dest: /192.168.56.180:50010
2019-06-17 11:46:17,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34420, dest: /192.168.56.180:50010, bytes: 25496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742141_1317, duration(ns): 3935580
2019-06-17 11:46:17,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742141_1317, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742142_1318 src: /192.168.56.180:34422 dest: /192.168.56.180:50010
2019-06-17 11:46:17,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34422, dest: /192.168.56.180:50010, bytes: 232248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742142_1318, duration(ns): 3319861
2019-06-17 11:46:17,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742142_1318, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742143_1319 src: /192.168.56.180:34424 dest: /192.168.56.180:50010
2019-06-17 11:46:17,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34424, dest: /192.168.56.180:50010, bytes: 20998, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742143_1319, duration(ns): 4467172
2019-06-17 11:46:17,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742143_1319, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742144_1320 src: /192.168.56.180:34426 dest: /192.168.56.180:50010
2019-06-17 11:46:17,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34426, dest: /192.168.56.180:50010, bytes: 1007502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742144_1320, duration(ns): 18022893
2019-06-17 11:46:17,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742144_1320, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742145_1321 src: /192.168.56.180:34428 dest: /192.168.56.180:50010
2019-06-17 11:46:17,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34428, dest: /192.168.56.180:50010, bytes: 60686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742145_1321, duration(ns): 1240391
2019-06-17 11:46:17,501 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742145_1321, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742146_1322 src: /192.168.56.180:34430 dest: /192.168.56.180:50010
2019-06-17 11:46:17,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34430, dest: /192.168.56.180:50010, bytes: 197986, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742146_1322, duration(ns): 5500738
2019-06-17 11:46:17,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742146_1322, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742147_1323 src: /192.168.56.180:34432 dest: /192.168.56.180:50010
2019-06-17 11:46:17,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34432, dest: /192.168.56.180:50010, bytes: 1108073, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742147_1323, duration(ns): 23108107
2019-06-17 11:46:17,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742147_1323, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742148_1324 src: /192.168.56.180:34434 dest: /192.168.56.180:50010
2019-06-17 11:46:17,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34434, dest: /192.168.56.180:50010, bytes: 224277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742148_1324, duration(ns): 2066480
2019-06-17 11:46:17,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742148_1324, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742149_1325 src: /192.168.56.180:34436 dest: /192.168.56.180:50010
2019-06-17 11:46:17,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34436, dest: /192.168.56.180:50010, bytes: 434678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742149_1325, duration(ns): 3711358
2019-06-17 11:46:17,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742149_1325, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742150_1326 src: /192.168.56.180:34438 dest: /192.168.56.180:50010
2019-06-17 11:46:17,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34438, dest: /192.168.56.180:50010, bytes: 109043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742150_1326, duration(ns): 1916474
2019-06-17 11:46:17,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742150_1326, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,756 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742151_1327 src: /192.168.56.180:34440 dest: /192.168.56.180:50010
2019-06-17 11:46:17,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34440, dest: /192.168.56.180:50010, bytes: 780664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742151_1327, duration(ns): 16897288
2019-06-17 11:46:17,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742151_1327, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,826 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742152_1328 src: /192.168.56.180:34442 dest: /192.168.56.180:50010
2019-06-17 11:46:17,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34442, dest: /192.168.56.180:50010, bytes: 706710, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742152_1328, duration(ns): 5105227
2019-06-17 11:46:17,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742152_1328, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742153_1329 src: /192.168.56.180:34444 dest: /192.168.56.180:50010
2019-06-17 11:46:17,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34444, dest: /192.168.56.180:50010, bytes: 1007502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742153_1329, duration(ns): 10065593
2019-06-17 11:46:17,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742153_1329, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:17,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742154_1330 src: /192.168.56.180:34446 dest: /192.168.56.180:50010
2019-06-17 11:46:17,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34446, dest: /192.168.56.180:50010, bytes: 1765905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742154_1330, duration(ns): 20632417
2019-06-17 11:46:17,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742154_1330, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742155_1331 src: /192.168.56.180:34448 dest: /192.168.56.180:50010
2019-06-17 11:46:18,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34448, dest: /192.168.56.180:50010, bytes: 20744, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742155_1331, duration(ns): 1238284
2019-06-17 11:46:18,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742155_1331, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742156_1332 src: /192.168.56.180:34450 dest: /192.168.56.180:50010
2019-06-17 11:46:18,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34450, dest: /192.168.56.180:50010, bytes: 279012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742156_1332, duration(ns): 13396503
2019-06-17 11:46:18,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742156_1332, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742157_1333 src: /192.168.56.180:34452 dest: /192.168.56.180:50010
2019-06-17 11:46:18,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34452, dest: /192.168.56.180:50010, bytes: 58160, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742157_1333, duration(ns): 2160281
2019-06-17 11:46:18,500 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742157_1333, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742158_1334 src: /192.168.56.180:34454 dest: /192.168.56.180:50010
2019-06-17 11:46:18,557 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34454, dest: /192.168.56.180:50010, bytes: 1801469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742158_1334, duration(ns): 19872487
2019-06-17 11:46:18,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742158_1334, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742159_1335 src: /192.168.56.180:34456 dest: /192.168.56.180:50010
2019-06-17 11:46:18,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34456, dest: /192.168.56.180:50010, bytes: 205389, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742159_1335, duration(ns): 947551
2019-06-17 11:46:18,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742159_1335, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742160_1336 src: /192.168.56.180:34458 dest: /192.168.56.180:50010
2019-06-17 11:46:18,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34458, dest: /192.168.56.180:50010, bytes: 53464, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742160_1336, duration(ns): 2367351
2019-06-17 11:46:18,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742160_1336, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,667 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742161_1337 src: /192.168.56.180:34460 dest: /192.168.56.180:50010
2019-06-17 11:46:18,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34460, dest: /192.168.56.180:50010, bytes: 592319, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742161_1337, duration(ns): 1766252
2019-06-17 11:46:18,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742161_1337, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742162_1338 src: /192.168.56.180:34462 dest: /192.168.56.180:50010
2019-06-17 11:46:18,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34462, dest: /192.168.56.180:50010, bytes: 892808, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742162_1338, duration(ns): 11411920
2019-06-17 11:46:18,747 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742162_1338, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,776 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742163_1339 src: /192.168.56.180:34464 dest: /192.168.56.180:50010
2019-06-17 11:46:18,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34464, dest: /192.168.56.180:50010, bytes: 36455, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742163_1339, duration(ns): 587140
2019-06-17 11:46:18,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742163_1339, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742164_1340 src: /192.168.56.180:34466 dest: /192.168.56.180:50010
2019-06-17 11:46:18,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34466, dest: /192.168.56.180:50010, bytes: 99555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742164_1340, duration(ns): 733362
2019-06-17 11:46:18,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742164_1340, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:18,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742165_1341 src: /192.168.56.180:34468 dest: /192.168.56.180:50010
2019-06-17 11:46:18,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34468, dest: /192.168.56.180:50010, bytes: 2178774, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742165_1341, duration(ns): 31042576
2019-06-17 11:46:18,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742165_1341, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,419 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742166_1342 src: /192.168.56.180:34470 dest: /192.168.56.180:50010
2019-06-17 11:46:19,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34470, dest: /192.168.56.180:50010, bytes: 36519, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742166_1342, duration(ns): 958392
2019-06-17 11:46:19,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742166_1342, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742167_1343 src: /192.168.56.180:34472 dest: /192.168.56.180:50010
2019-06-17 11:46:19,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34472, dest: /192.168.56.180:50010, bytes: 186260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742167_1343, duration(ns): 3218363
2019-06-17 11:46:19,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742167_1343, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742168_1344 src: /192.168.56.180:34474 dest: /192.168.56.180:50010
2019-06-17 11:46:19,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34474, dest: /192.168.56.180:50010, bytes: 19827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742168_1344, duration(ns): 532032
2019-06-17 11:46:19,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742168_1344, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742169_1345 src: /192.168.56.180:34476 dest: /192.168.56.180:50010
2019-06-17 11:46:19,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34476, dest: /192.168.56.180:50010, bytes: 34604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742169_1345, duration(ns): 2648902
2019-06-17 11:46:19,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742169_1345, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742170_1346 src: /192.168.56.180:34478 dest: /192.168.56.180:50010
2019-06-17 11:46:19,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34478, dest: /192.168.56.180:50010, bytes: 1344870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742170_1346, duration(ns): 10308577
2019-06-17 11:46:19,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742170_1346, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742171_1347 src: /192.168.56.180:34480 dest: /192.168.56.180:50010
2019-06-17 11:46:19,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34480, dest: /192.168.56.180:50010, bytes: 1768012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742171_1347, duration(ns): 17956144
2019-06-17 11:46:19,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742171_1347, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742172_1348 src: /192.168.56.180:34482 dest: /192.168.56.180:50010
2019-06-17 11:46:19,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34482, dest: /192.168.56.180:50010, bytes: 365552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742172_1348, duration(ns): 1524726
2019-06-17 11:46:19,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742172_1348, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742173_1349 src: /192.168.56.180:34484 dest: /192.168.56.180:50010
2019-06-17 11:46:19,725 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34484, dest: /192.168.56.180:50010, bytes: 9442, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742173_1349, duration(ns): 498328
2019-06-17 11:46:19,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742173_1349, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,838 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742174_1350 src: /192.168.56.180:34488 dest: /192.168.56.180:50010
2019-06-17 11:46:19,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34488, dest: /192.168.56.180:50010, bytes: 94, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742174_1350, duration(ns): 761443
2019-06-17 11:46:19,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742174_1350, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:19,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742175_1351 src: /192.168.56.180:34490 dest: /192.168.56.180:50010
2019-06-17 11:46:19,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34490, dest: /192.168.56.180:50010, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742175_1351, duration(ns): 776698
2019-06-17 11:46:19,873 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742175_1351, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:20,046 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742144_1320 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742144 for deletion
2019-06-17 11:46:20,050 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742144_1320 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742144
2019-06-17 11:46:20,427 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742176_1352 src: /192.168.56.180:34492 dest: /192.168.56.180:50010
2019-06-17 11:46:20,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34492, dest: /192.168.56.180:50010, bytes: 176834, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-424712281_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742176_1352, duration(ns): 37840673
2019-06-17 11:46:20,471 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742176_1352, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:42,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742177_1353 src: /192.168.56.180:34508 dest: /192.168.56.180:50010
2019-06-17 11:46:42,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34508, dest: /192.168.56.180:50010, bytes: 203972, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2064297095_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742177_1353, duration(ns): 54464757
2019-06-17 11:46:42,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742177_1353, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:51,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742178_1354 src: /192.168.56.180:34522 dest: /192.168.56.180:50010
2019-06-17 11:46:51,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34522, dest: /192.168.56.180:50010, bytes: 441369, op: HDFS_WRITE, cliID: DFSClient_attempt_1560737415389_0001_m_000000_0_1319954510_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742178_1354, duration(ns): 257924750
2019-06-17 11:46:51,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742178_1354, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:52,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742179_1355 src: /192.168.56.180:34524 dest: /192.168.56.180:50010
2019-06-17 11:46:52,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34524, dest: /192.168.56.180:50010, bytes: 21137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2064297095_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742179_1355, duration(ns): 169751294
2019-06-17 11:46:52,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742179_1355, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:52,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742180_1356 src: /192.168.56.180:34526 dest: /192.168.56.180:50010
2019-06-17 11:46:52,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34526, dest: /192.168.56.180:50010, bytes: 338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2064297095_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742180_1356, duration(ns): 16054594
2019-06-17 11:46:52,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742180_1356, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:52,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742181_1357 src: /192.168.56.180:34530 dest: /192.168.56.180:50010
2019-06-17 11:46:52,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34530, dest: /192.168.56.180:50010, bytes: 21137, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2064297095_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742181_1357, duration(ns): 500454
2019-06-17 11:46:52,444 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742181_1357, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:52,492 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742182_1358 src: /192.168.56.180:34532 dest: /192.168.56.180:50010
2019-06-17 11:46:52,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:34532, dest: /192.168.56.180:50010, bytes: 203972, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2064297095_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742182_1358, duration(ns): 8636624
2019-06-17 11:46:52,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742182_1358, type=LAST_IN_PIPELINE terminating
2019-06-17 11:46:56,046 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742145_1321 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742145 for deletion
2019-06-17 11:46:56,047 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742145_1321 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742145
2019-06-17 11:46:56,047 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742146_1322 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742146 for deletion
2019-06-17 11:46:56,047 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742146_1322 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742146
2019-06-17 11:46:56,047 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742147_1323 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742147 for deletion
2019-06-17 11:46:56,047 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742147_1323 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742147
2019-06-17 11:46:56,047 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742148_1324 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742148 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742148_1324 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742148
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742149_1325 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742149 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742150_1326 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742150 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742151_1327 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742151 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742152_1328 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742152 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742153_1329 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742153 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742154_1330 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742154 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742155_1331 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742155 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742156_1332 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742156 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742157_1333 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742157 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742158_1334 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742158 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742159_1335 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742159 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742160_1336 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742160 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742161_1337 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742161 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742162_1338 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742162 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742163_1339 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742163 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742164_1340 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742164 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742165_1341 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742165 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742166_1342 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742166 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742167_1343 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742167 for deletion
2019-06-17 11:46:56,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742168_1344 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742168 for deletion
2019-06-17 11:46:56,049 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742169_1345 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742169 for deletion
2019-06-17 11:46:56,049 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742170_1346 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742170 for deletion
2019-06-17 11:46:56,054 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742149_1325 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742149
2019-06-17 11:46:56,054 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742150_1326 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742150
2019-06-17 11:46:56,054 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742151_1327 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742151
2019-06-17 11:46:56,055 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742152_1328 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742152
2019-06-17 11:46:56,055 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742153_1329 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742153
2019-06-17 11:46:56,055 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742154_1330 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742154
2019-06-17 11:46:56,055 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742155_1331 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742155
2019-06-17 11:46:56,055 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742156_1332 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742156
2019-06-17 11:46:56,055 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742157_1333 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742157
2019-06-17 11:46:56,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742158_1334 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742158
2019-06-17 11:46:56,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742159_1335 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742159
2019-06-17 11:46:56,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742160_1336 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742160
2019-06-17 11:46:56,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742161_1337 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742161
2019-06-17 11:46:56,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742162_1338 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742162
2019-06-17 11:46:56,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742163_1339 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742163
2019-06-17 11:46:56,056 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742164_1340 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742164
2019-06-17 11:46:56,057 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742165_1341 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742165
2019-06-17 11:46:56,057 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742166_1342 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742166
2019-06-17 11:46:56,057 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742167_1343 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742167
2019-06-17 11:46:56,057 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742168_1344 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742168
2019-06-17 11:46:56,057 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742169_1345 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742169
2019-06-17 11:46:56,057 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742170_1346 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742170
2019-06-17 11:46:56,057 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742171_1347 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742171 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742172_1348 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742172 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742173_1349 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742173 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742174_1350 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742174 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742175_1351 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742175 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742176_1352 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742176 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742177_1353 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742177 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742179_1355 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742179 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742137_1313 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742137 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742138_1314 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742138 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742139_1315 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742139 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742140_1316 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742140 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742141_1317 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742141 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742142_1318 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742142 for deletion
2019-06-17 11:46:56,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742143_1319 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742143 for deletion
2019-06-17 11:46:56,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742171_1347 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742171
2019-06-17 11:46:56,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742172_1348 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742172
2019-06-17 11:46:56,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742173_1349 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742173
2019-06-17 11:46:56,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742174_1350 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742174
2019-06-17 11:46:56,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742175_1351 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742175
2019-06-17 11:46:56,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742176_1352 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742176
2019-06-17 11:46:56,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742177_1353 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742177
2019-06-17 11:46:56,063 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742179_1355 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742179
2019-06-17 11:46:56,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742137_1313 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742137
2019-06-17 11:46:56,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742138_1314 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742138
2019-06-17 11:46:56,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742139_1315 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742139
2019-06-17 11:46:56,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742140_1316 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742140
2019-06-17 11:46:56,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742141_1317 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742141
2019-06-17 11:46:56,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742142_1318 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742142
2019-06-17 11:46:56,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742143_1319 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742143
2019-06-17 13:58:09,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c75,  containing 1 storage report(s), of which we sent 1. The reports had 77 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-17 13:58:09,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-17 16:46:59,452 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 77, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-17 19:58:09,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c76,  containing 1 storage report(s), of which we sent 1. The reports had 77 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-17 19:58:09,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-17 22:46:59,440 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 77, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-18 01:58:09,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c77,  containing 1 storage report(s), of which we sent 1. The reports had 77 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-18 01:58:09,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-18 04:46:59,427 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 77, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-18 07:58:09,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c78,  containing 1 storage report(s), of which we sent 1. The reports had 77 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-18 07:58:09,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-18 10:46:59,433 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 77, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-18 12:38:01,629 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742183_1359 src: /192.168.56.180:37604 dest: /192.168.56.180:50010
2019-06-18 12:40:39,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:37604, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742183_1359, duration(ns): 158085366852
2019-06-18 12:40:39,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742183_1359, type=LAST_IN_PIPELINE terminating
2019-06-18 12:40:42,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742184_1360 src: /192.168.56.180:37628 dest: /192.168.56.180:50010
2019-06-18 12:43:20,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:37628, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742184_1360, duration(ns): 158034743156
2019-06-18 12:43:20,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742184_1360, type=LAST_IN_PIPELINE terminating
2019-06-18 12:43:23,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742185_1361 src: /192.168.56.180:37652 dest: /192.168.56.180:50010
2019-06-18 12:43:45,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:37652, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742185_1361, duration(ns): 22022373602
2019-06-18 12:43:45,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742185_1361, type=LAST_IN_PIPELINE terminating
2019-06-18 12:43:49,061 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742186_1362 src: /192.168.56.180:37660 dest: /192.168.56.180:50010
2019-06-18 12:43:51,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:37660, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742186_1362, duration(ns): 1969353969
2019-06-18 12:43:51,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742186_1362, type=LAST_IN_PIPELINE terminating
2019-06-18 12:43:54,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742187_1363 src: /192.168.56.180:37666 dest: /192.168.56.180:50010
2019-06-18 12:43:58,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:37666, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742187_1363, duration(ns): 4013092973
2019-06-18 12:43:58,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742187_1363, type=LAST_IN_PIPELINE terminating
2019-06-18 12:44:01,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742188_1364 src: /192.168.56.180:37672 dest: /192.168.56.180:50010
2019-06-18 12:53:58,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:37672, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742188_1364, duration(ns): 596993070720
2019-06-18 12:53:58,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742188_1364, type=LAST_IN_PIPELINE terminating
2019-06-18 13:58:09,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c79,  containing 1 storage report(s), of which we sent 1. The reports had 83 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-18 13:58:09,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-18 14:07:23,204 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742189_1365 src: /192.168.56.180:37890 dest: /192.168.56.180:50010
2019-06-18 14:17:20,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:37890, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742189_1365, duration(ns): 596984008599
2019-06-18 14:17:20,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742189_1365, type=LAST_IN_PIPELINE terminating
2019-06-18 14:23:16,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742190_1366 src: /192.168.56.180:37978 dest: /192.168.56.180:50010
2019-06-18 14:24:18,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:37978, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742190_1366, duration(ns): 62014356091
2019-06-18 14:24:18,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742190_1366, type=LAST_IN_PIPELINE terminating
2019-06-18 14:24:21,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742191_1367 src: /192.168.56.180:37990 dest: /192.168.56.180:50010
2019-06-18 14:25:18,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:37990, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742191_1367, duration(ns): 56556486424
2019-06-18 14:25:18,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742191_1367, type=LAST_IN_PIPELINE terminating
2019-06-18 14:25:21,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742192_1368 src: /192.168.56.180:38002 dest: /192.168.56.180:50010
2019-06-18 14:29:51,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38002, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742192_1368, duration(ns): 270551121058
2019-06-18 14:29:51,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742192_1368, type=LAST_IN_PIPELINE terminating
2019-06-18 14:29:54,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742193_1369 src: /192.168.56.180:38036 dest: /192.168.56.180:50010
2019-06-18 14:32:24,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38036, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742193_1369, duration(ns): 150032617354
2019-06-18 14:32:24,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742193_1369, type=LAST_IN_PIPELINE terminating
2019-06-18 14:32:27,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742194_1370 src: /192.168.56.180:38060 dest: /192.168.56.180:50010
2019-06-18 14:42:24,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38060, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742194_1370, duration(ns): 596981563195
2019-06-18 14:42:24,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742194_1370, type=LAST_IN_PIPELINE terminating
2019-06-18 14:59:57,220 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742195_1371 src: /192.168.56.180:38172 dest: /192.168.56.180:50010
2019-06-18 15:05:55,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38172, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742195_1371, duration(ns): 358069462501
2019-06-18 15:05:55,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742195_1371, type=LAST_IN_PIPELINE terminating
2019-06-18 15:05:58,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742196_1372 src: /192.168.56.180:38214 dest: /192.168.56.180:50010
2019-06-18 15:08:12,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38214, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742196_1372, duration(ns): 134025683107
2019-06-18 15:08:12,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742196_1372, type=LAST_IN_PIPELINE terminating
2019-06-18 15:08:15,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742197_1373 src: /192.168.56.180:38238 dest: /192.168.56.180:50010
2019-06-18 15:09:18,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38238, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742197_1373, duration(ns): 63041844250
2019-06-18 15:09:18,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742197_1373, type=LAST_IN_PIPELINE terminating
2019-06-18 15:09:21,633 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742198_1374 src: /192.168.56.180:38254 dest: /192.168.56.180:50010
2019-06-18 15:12:00,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38254, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742198_1374, duration(ns): 159038452832
2019-06-18 15:12:00,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742198_1374, type=LAST_IN_PIPELINE terminating
2019-06-18 15:12:03,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742199_1375 src: /192.168.56.180:38278 dest: /192.168.56.180:50010
2019-06-18 15:14:34,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38278, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742199_1375, duration(ns): 151025704982
2019-06-18 15:14:34,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742199_1375, type=LAST_IN_PIPELINE terminating
2019-06-18 15:14:37,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742200_1376 src: /192.168.56.180:38304 dest: /192.168.56.180:50010
2019-06-18 15:16:19,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38304, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742200_1376, duration(ns): 102027245110
2019-06-18 15:16:19,914 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742200_1376, type=LAST_IN_PIPELINE terminating
2019-06-18 15:16:22,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742201_1377 src: /192.168.56.180:38322 dest: /192.168.56.180:50010
2019-06-18 15:17:02,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38322, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742201_1377, duration(ns): 39816383986
2019-06-18 15:17:02,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742201_1377, type=LAST_IN_PIPELINE terminating
2019-06-18 15:17:05,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742202_1378 src: /192.168.56.180:38330 dest: /192.168.56.180:50010
2019-06-18 15:23:14,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38330, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742202_1378, duration(ns): 368602421177
2019-06-18 15:23:14,487 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742202_1378, type=LAST_IN_PIPELINE terminating
2019-06-18 15:23:17,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742203_1379 src: /192.168.56.180:38378 dest: /192.168.56.180:50010
2019-06-18 15:26:43,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38378, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742203_1379, duration(ns): 206330592417
2019-06-18 15:26:43,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742203_1379, type=LAST_IN_PIPELINE terminating
2019-06-18 15:26:46,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742204_1380 src: /192.168.56.180:38414 dest: /192.168.56.180:50010
2019-06-18 15:27:01,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38414, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742204_1380, duration(ns): 15008066700
2019-06-18 15:27:01,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742204_1380, type=LAST_IN_PIPELINE terminating
2019-06-18 15:27:05,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742205_1381 src: /192.168.56.180:38420 dest: /192.168.56.180:50010
2019-06-18 15:27:14,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38420, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742205_1381, duration(ns): 9487380873
2019-06-18 15:27:14,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742205_1381, type=LAST_IN_PIPELINE terminating
2019-06-18 15:27:17,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742206_1382 src: /192.168.56.180:38426 dest: /192.168.56.180:50010
2019-06-18 15:27:22,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38426, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742206_1382, duration(ns): 4939793046
2019-06-18 15:27:22,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742206_1382, type=LAST_IN_PIPELINE terminating
2019-06-18 15:27:25,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742207_1383 src: /192.168.56.180:38434 dest: /192.168.56.180:50010
2019-06-18 15:29:31,648 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38434, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742207_1383, duration(ns): 126024158170
2019-06-18 15:29:31,650 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742207_1383, type=LAST_IN_PIPELINE terminating
2019-06-18 15:29:34,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742208_1384 src: /192.168.56.180:38452 dest: /192.168.56.180:50010
2019-06-18 15:29:38,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38452, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742208_1384, duration(ns): 4006737181
2019-06-18 15:29:38,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742208_1384, type=LAST_IN_PIPELINE terminating
2019-06-18 15:29:41,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742209_1385 src: /192.168.56.180:38458 dest: /192.168.56.180:50010
2019-06-18 15:29:51,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38458, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742209_1385, duration(ns): 9358620333
2019-06-18 15:29:51,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742209_1385, type=LAST_IN_PIPELINE terminating
2019-06-18 15:29:54,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742210_1386 src: /192.168.56.180:38464 dest: /192.168.56.180:50010
2019-06-18 15:39:51,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38464, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742210_1386, duration(ns): 596978472338
2019-06-18 15:39:51,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742210_1386, type=LAST_IN_PIPELINE terminating
2019-06-18 15:54:11,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742211_1387 src: /192.168.56.180:38576 dest: /192.168.56.180:50010
2019-06-18 15:54:49,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38576, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742211_1387, duration(ns): 38010025627
2019-06-18 15:54:49,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742211_1387, type=LAST_IN_PIPELINE terminating
2019-06-18 15:54:52,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742212_1388 src: /192.168.56.180:38588 dest: /192.168.56.180:50010
2019-06-18 16:02:42,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38588, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742212_1388, duration(ns): 470114939982
2019-06-18 16:02:42,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742212_1388, type=LAST_IN_PIPELINE terminating
2019-06-18 16:02:45,805 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742213_1389 src: /192.168.56.180:38668 dest: /192.168.56.180:50010
2019-06-18 16:03:31,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38668, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742213_1389, duration(ns): 46015553867
2019-06-18 16:03:31,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742213_1389, type=LAST_IN_PIPELINE terminating
2019-06-18 16:03:34,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742214_1390 src: /192.168.56.180:38682 dest: /192.168.56.180:50010
2019-06-18 16:13:31,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38682, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742214_1390, duration(ns): 596978935062
2019-06-18 16:13:31,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742214_1390, type=LAST_IN_PIPELINE terminating
2019-06-18 16:19:45,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742215_1391 src: /192.168.56.180:38768 dest: /192.168.56.180:50010
2019-06-18 16:29:42,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38768, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742215_1391, duration(ns): 596986653234
2019-06-18 16:29:42,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742215_1391, type=LAST_IN_PIPELINE terminating
2019-06-18 16:46:59,426 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 110, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-18 17:10:53,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742216_1392 src: /192.168.56.180:38924 dest: /192.168.56.180:50010
2019-06-18 17:20:50,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:38924, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742216_1392, duration(ns): 596984197710
2019-06-18 17:20:50,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742216_1392, type=LAST_IN_PIPELINE terminating
2019-06-18 17:40:39,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742217_1393 src: /192.168.56.180:39036 dest: /192.168.56.180:50010
2019-06-18 17:41:49,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:39036, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742217_1393, duration(ns): 70013781264
2019-06-18 17:41:49,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742217_1393, type=LAST_IN_PIPELINE terminating
2019-06-18 17:41:53,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742218_1394 src: /192.168.56.180:39050 dest: /192.168.56.180:50010
2019-06-18 17:51:50,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:39050, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742218_1394, duration(ns): 596991464736
2019-06-18 17:51:50,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742218_1394, type=LAST_IN_PIPELINE terminating
2019-06-18 19:58:08,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c7a,  containing 1 storage report(s), of which we sent 1. The reports had 113 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-18 19:58:08,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-18 22:46:59,415 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 113, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-19 01:58:08,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c7b,  containing 1 storage report(s), of which we sent 1. The reports had 113 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-19 01:58:08,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-19 04:46:59,415 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 113, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-19 07:58:11,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c7c,  containing 1 storage report(s), of which we sent 1. The reports had 113 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-19 07:58:11,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-19 09:10:11,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742219_1395 src: /192.168.56.180:41016 dest: /192.168.56.180:50010
2019-06-19 09:12:33,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41016, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742219_1395, duration(ns): 142028871188
2019-06-19 09:12:33,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742219_1395, type=LAST_IN_PIPELINE terminating
2019-06-19 09:12:36,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742220_1396 src: /192.168.56.180:41040 dest: /192.168.56.180:50010
2019-06-19 09:14:34,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41040, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742220_1396, duration(ns): 118021894329
2019-06-19 09:14:34,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742220_1396, type=LAST_IN_PIPELINE terminating
2019-06-19 09:14:37,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742221_1397 src: /192.168.56.180:41058 dest: /192.168.56.180:50010
2019-06-19 09:16:11,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41058, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742221_1397, duration(ns): 94015490189
2019-06-19 09:16:11,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742221_1397, type=LAST_IN_PIPELINE terminating
2019-06-19 09:16:14,807 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742222_1398 src: /192.168.56.180:41072 dest: /192.168.56.180:50010
2019-06-19 09:17:56,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41072, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742222_1398, duration(ns): 102106381973
2019-06-19 09:17:56,922 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742222_1398, type=LAST_IN_PIPELINE terminating
2019-06-19 09:17:59,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742223_1399 src: /192.168.56.180:41090 dest: /192.168.56.180:50010
2019-06-19 09:19:34,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41090, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742223_1399, duration(ns): 94582013272
2019-06-19 09:19:34,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742223_1399, type=LAST_IN_PIPELINE terminating
2019-06-19 09:19:37,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742224_1400 src: /192.168.56.180:41106 dest: /192.168.56.180:50010
2019-06-19 09:25:03,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41106, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742224_1400, duration(ns): 326053906085
2019-06-19 09:25:03,709 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742224_1400, type=LAST_IN_PIPELINE terminating
2019-06-19 09:25:06,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742225_1401 src: /192.168.56.180:41144 dest: /192.168.56.180:50010
2019-06-19 09:27:05,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41144, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742225_1401, duration(ns): 118901480261
2019-06-19 09:27:05,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742225_1401, type=LAST_IN_PIPELINE terminating
2019-06-19 09:27:08,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742226_1402 src: /192.168.56.180:41162 dest: /192.168.56.180:50010
2019-06-19 09:28:35,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41162, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742226_1402, duration(ns): 86788454319
2019-06-19 09:28:35,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742226_1402, type=LAST_IN_PIPELINE terminating
2019-06-19 09:28:38,635 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742227_1403 src: /192.168.56.180:41178 dest: /192.168.56.180:50010
2019-06-19 09:30:14,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41178, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742227_1403, duration(ns): 96322454018
2019-06-19 09:30:14,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742227_1403, type=LAST_IN_PIPELINE terminating
2019-06-19 09:30:18,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742228_1404 src: /192.168.56.180:41192 dest: /192.168.56.180:50010
2019-06-19 09:40:15,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41192, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742228_1404, duration(ns): 596982694050
2019-06-19 09:40:15,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742228_1404, type=LAST_IN_PIPELINE terminating
2019-06-19 10:29:34,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742229_1405 src: /192.168.56.180:41362 dest: /192.168.56.180:50010
2019-06-19 10:30:46,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41362, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742229_1405, duration(ns): 72122513980
2019-06-19 10:30:46,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742229_1405, type=LAST_IN_PIPELINE terminating
2019-06-19 10:30:49,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742230_1406 src: /192.168.56.180:41376 dest: /192.168.56.180:50010
2019-06-19 10:40:46,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:41376, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742230_1406, duration(ns): 596991891431
2019-06-19 10:40:46,676 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742230_1406, type=LAST_IN_PIPELINE terminating
2019-06-19 10:46:59,419 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 125, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-19 13:58:10,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c7d,  containing 1 storage report(s), of which we sent 1. The reports had 125 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-19 13:58:10,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-19 16:46:59,422 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 125, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-19 17:07:58,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742231_1407 src: /192.168.56.180:42232 dest: /192.168.56.180:50010
2019-06-19 17:08:21,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42232, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742231_1407, duration(ns): 22672133086
2019-06-19 17:08:21,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742231_1407, type=LAST_IN_PIPELINE terminating
2019-06-19 17:08:24,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742232_1408 src: /192.168.56.180:42240 dest: /192.168.56.180:50010
2019-06-19 17:11:35,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42240, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742232_1408, duration(ns): 190456047822
2019-06-19 17:11:35,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742232_1408, type=LAST_IN_PIPELINE terminating
2019-06-19 17:11:38,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742233_1409 src: /192.168.56.180:42268 dest: /192.168.56.180:50010
2019-06-19 17:12:08,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42268, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742233_1409, duration(ns): 30677646842
2019-06-19 17:12:08,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742233_1409, type=LAST_IN_PIPELINE terminating
2019-06-19 17:12:11,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742234_1410 src: /192.168.56.180:42278 dest: /192.168.56.180:50010
2019-06-19 17:13:13,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42278, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742234_1410, duration(ns): 62019187877
2019-06-19 17:13:13,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742234_1410, type=LAST_IN_PIPELINE terminating
2019-06-19 17:13:17,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742235_1411 src: /192.168.56.180:42292 dest: /192.168.56.180:50010
2019-06-19 17:14:27,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42292, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742235_1411, duration(ns): 70016168588
2019-06-19 17:14:27,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742235_1411, type=LAST_IN_PIPELINE terminating
2019-06-19 17:14:30,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742236_1412 src: /192.168.56.180:42304 dest: /192.168.56.180:50010
2019-06-19 17:24:27,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42304, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742236_1412, duration(ns): 596992884125
2019-06-19 17:24:27,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742236_1412, type=LAST_IN_PIPELINE terminating
2019-06-19 17:25:35,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742237_1413 src: /192.168.56.180:42374 dest: /192.168.56.180:50010
2019-06-19 17:27:59,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42374, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742237_1413, duration(ns): 144612461768
2019-06-19 17:27:59,928 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742237_1413, type=LAST_IN_PIPELINE terminating
2019-06-19 17:28:03,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742238_1414 src: /192.168.56.180:42396 dest: /192.168.56.180:50010
2019-06-19 17:28:57,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42396, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742238_1414, duration(ns): 54010845806
2019-06-19 17:28:57,027 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742238_1414, type=LAST_IN_PIPELINE terminating
2019-06-19 17:29:00,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742239_1415 src: /192.168.56.180:42408 dest: /192.168.56.180:50010
2019-06-19 17:34:36,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42408, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742239_1415, duration(ns): 335959058932
2019-06-19 17:34:36,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742239_1415, type=LAST_IN_PIPELINE terminating
2019-06-19 17:34:39,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742240_1416 src: /192.168.56.180:42448 dest: /192.168.56.180:50010
2019-06-19 17:36:40,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42448, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742240_1416, duration(ns): 120924574947
2019-06-19 17:36:40,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742240_1416, type=LAST_IN_PIPELINE terminating
2019-06-19 17:36:43,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742241_1417 src: /192.168.56.180:42466 dest: /192.168.56.180:50010
2019-06-19 17:41:00,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42466, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742241_1417, duration(ns): 256932190049
2019-06-19 17:41:00,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742241_1417, type=LAST_IN_PIPELINE terminating
2019-06-19 17:41:03,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742242_1418 src: /192.168.56.180:42498 dest: /192.168.56.180:50010
2019-06-19 17:44:37,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42498, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742242_1418, duration(ns): 214039188207
2019-06-19 17:44:37,196 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742242_1418, type=LAST_IN_PIPELINE terminating
2019-06-19 17:44:40,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742243_1419 src: /192.168.56.180:42526 dest: /192.168.56.180:50010
2019-06-19 17:46:06,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42526, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742243_1419, duration(ns): 86023138863
2019-06-19 17:46:06,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742243_1419, type=LAST_IN_PIPELINE terminating
2019-06-19 17:46:09,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742244_1420 src: /192.168.56.180:42540 dest: /192.168.56.180:50010
2019-06-19 17:48:55,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42540, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742244_1420, duration(ns): 166041613193
2019-06-19 17:48:55,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742244_1420, type=LAST_IN_PIPELINE terminating
2019-06-19 17:48:58,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742245_1421 src: /192.168.56.180:42564 dest: /192.168.56.180:50010
2019-06-19 17:50:50,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42564, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742245_1421, duration(ns): 112251342335
2019-06-19 17:50:50,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742245_1421, type=LAST_IN_PIPELINE terminating
2019-06-19 17:50:53,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742246_1422 src: /192.168.56.180:42582 dest: /192.168.56.180:50010
2019-06-19 18:00:50,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:42582, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742246_1422, duration(ns): 596982378923
2019-06-19 18:00:50,850 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742246_1422, type=LAST_IN_PIPELINE terminating
2019-06-19 19:58:10,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c7e,  containing 1 storage report(s), of which we sent 1. The reports had 141 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-19 19:58:10,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-19 22:46:59,417 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 141, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-20 01:58:10,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c7f,  containing 1 storage report(s), of which we sent 1. The reports had 141 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-20 01:58:10,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-20 04:46:59,417 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 141, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-20 07:58:10,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaca67ed984381c80,  containing 1 storage report(s), of which we sent 1. The reports had 141 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-20 07:58:10,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-20 09:25:04,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742247_1423 src: /192.168.56.180:44530 dest: /192.168.56.180:50010
2019-06-20 09:35:01,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:44530, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742247_1423, duration(ns): 596992105282
2019-06-20 09:35:01,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742247_1423, type=LAST_IN_PIPELINE terminating
2019-06-20 10:03:14,300 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742248_1424 src: /192.168.56.180:44654 dest: /192.168.56.180:50010
2019-06-20 10:06:08,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:44654, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742248_1424, duration(ns): 174589577329
2019-06-20 10:06:08,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742248_1424, type=LAST_IN_PIPELINE terminating
2019-06-20 10:06:11,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742249_1425 src: /192.168.56.180:44678 dest: /192.168.56.180:50010
2019-06-20 10:07:06,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:44678, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742249_1425, duration(ns): 54014248682
2019-06-20 10:07:06,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742249_1425, type=LAST_IN_PIPELINE terminating
2019-06-20 10:07:09,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742250_1426 src: /192.168.56.180:44690 dest: /192.168.56.180:50010
2019-06-20 10:12:27,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:44690, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742250_1426, duration(ns): 318055839589
2019-06-20 10:12:27,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742250_1426, type=LAST_IN_PIPELINE terminating
2019-06-20 10:12:30,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742251_1427 src: /192.168.56.180:44730 dest: /192.168.56.180:50010
2019-06-20 10:22:27,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:44730, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742251_1427, duration(ns): 596993544051
2019-06-20 10:22:27,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742251_1427, type=LAST_IN_PIPELINE terminating
2019-06-20 10:46:59,419 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 146, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-20 11:39:16,900 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/192.168.56.180"; destination host is: "master":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-06-20 11:39:20,030 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-20 11:39:20,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
2019-06-20 11:39:59,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/192.168.56.180
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /home/FP/hadoop-2.9.2/etc/hadoop:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/FP/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 1.8.0_211
************************************************************/
2019-06-20 11:39:59,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-06-20 11:40:00,244 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-20 11:40:00,951 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/FP/hadoop/datanode/
2019-06-20 11:40:01,047 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-06-20 11:40:01,231 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-06-20 11:40:01,231 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-06-20 11:40:01,238 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-20 11:40:01,240 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-06-20 11:40:01,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-06-20 11:40:01,244 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-06-20 11:40:01,244 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-06-20 11:40:01,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-06-20 11:40:01,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-06-20 11:40:01,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-06-20 11:40:01,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-06-20 11:40:01,628 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-06-20 11:40:01,660 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-20 11:40:01,717 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-06-20 11:40:01,746 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-20 11:40:01,750 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-06-20 11:40:01,750 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-20 11:40:01,751 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-20 11:40:01,810 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 37135
2019-06-20 11:40:01,810 INFO org.mortbay.log: jetty-6.1.26
2019-06-20 11:40:03,022 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:37135
2019-06-20 11:40:03,394 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-06-20 11:40:03,414 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-06-20 11:40:04,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2019-06-20 11:40:04,942 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-06-20 11:40:05,150 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-06-20 11:40:05,225 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-06-20 11:40:05,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-06-20 11:40:05,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-06-20 11:40:05,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-06-20 11:40:05,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000 starting to offer service
2019-06-20 11:40:05,808 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-06-20 11:40:05,818 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-06-20 11:40:06,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/192.168.56.180:9000
2019-06-20 11:40:06,858 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-06-20 11:40:06,877 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/FP/hadoop/datanode/in_use.lock acquired by nodename 29921@master
2019-06-20 11:40:07,016 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-176234095-192.168.56.180-1559628803602
2019-06-20 11:40:07,016 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602
2019-06-20 11:40:07,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1394054448;bpid=BP-176234095-192.168.56.180-1559628803602;lv=-57;nsInfo=lv=-63;cid=CID-58aa3572-da14-4733-8366-2582b85acf36;nsid=1394054448;c=1559628803602;bpid=BP-176234095-192.168.56.180-1559628803602;dnuuid=e73933f1-f299-4a17-994e-22eb0f3ff35c
2019-06-20 11:40:07,192 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9
2019-06-20 11:40:07,193 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /home/FP/hadoop/datanode/current, StorageType: DISK
2019-06-20 11:40:07,207 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-06-20 11:40:07,231 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/FP/hadoop/datanode/current
2019-06-20 11:40:07,264 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/FP/hadoop/datanode/current
2019-06-20 11:40:07,265 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-176234095-192.168.56.180-1559628803602
2019-06-20 11:40:07,270 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-20 11:40:07,303 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current: 17805312
2019-06-20 11:40:07,363 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-176234095-192.168.56.180-1559628803602 on /home/FP/hadoop/datanode/current: 93ms
2019-06-20 11:40:07,377 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-176234095-192.168.56.180-1559628803602: 107ms
2019-06-20 11:40:07,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current...
2019-06-20 11:40:07,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/replicas doesn't exist 
2019-06-20 11:40:07,551 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-176234095-192.168.56.180-1559628803602 on volume /home/FP/hadoop/datanode/current: 165ms
2019-06-20 11:40:07,551 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 173ms
2019-06-20 11:40:07,819 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/FP/hadoop/datanode, DS-97b8dd0e-6fc7-4789-bd8f-586ccd245ae9): no suitable block pools found to scan.  Waiting 444821331 ms.
2019-06-20 11:40:07,849 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 19. 6. 20 오후 3:19 with interval of 21600000ms
2019-06-20 11:40:07,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 beginning handshake with NN
2019-06-20 11:40:08,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-176234095-192.168.56.180-1559628803602 (Datanode Uuid e73933f1-f299-4a17-994e-22eb0f3ff35c) service to master/192.168.56.180:9000 successfully registered with NN
2019-06-20 11:40:08,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/192.168.56.180:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-06-20 11:40:08,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bea,  containing 1 storage report(s), of which we sent 1. The reports had 146 total blocks and used 1 RPC(s). This took 27 msec to generate and 302 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-20 11:40:08,682 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-20 11:40:51,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742252_1428 src: /192.168.56.180:45000 dest: /192.168.56.180:50010
2019-06-20 11:40:51,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:45000, dest: /192.168.56.180:50010, bytes: 828368, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-278533710_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742252_1428, duration(ns): 54030057
2019-06-20 11:40:51,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742252_1428, type=LAST_IN_PIPELINE terminating
2019-06-20 12:47:41,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1beb,  containing 1 storage report(s), of which we sent 1. The reports had 147 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-20 12:47:41,979 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-20 14:11:06,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742253_1429 src: /192.168.56.180:45324 dest: /192.168.56.180:50010
2019-06-20 14:11:21,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:45324, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742253_1429, duration(ns): 15009498600
2019-06-20 14:11:21,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742253_1429, type=LAST_IN_PIPELINE terminating
2019-06-20 14:11:24,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742254_1430 src: /192.168.56.180:45334 dest: /192.168.56.180:50010
2019-06-20 14:11:33,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:45334, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742254_1430, duration(ns): 9008839903
2019-06-20 14:11:33,140 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742254_1430, type=LAST_IN_PIPELINE terminating
2019-06-20 14:11:36,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742255_1431 src: /192.168.56.180:45340 dest: /192.168.56.180:50010
2019-06-20 14:12:07,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:45340, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742255_1431, duration(ns): 30787348098
2019-06-20 14:12:07,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742255_1431, type=LAST_IN_PIPELINE terminating
2019-06-20 14:12:10,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742256_1432 src: /192.168.56.180:45348 dest: /192.168.56.180:50010
2019-06-20 14:12:21,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:45348, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742256_1432, duration(ns): 10887840105
2019-06-20 14:12:21,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742256_1432, type=LAST_IN_PIPELINE terminating
2019-06-20 14:12:24,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742257_1433 src: /192.168.56.180:45358 dest: /192.168.56.180:50010
2019-06-20 14:22:21,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:45358, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742257_1433, duration(ns): 596984026433
2019-06-20 14:22:21,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742257_1433, type=LAST_IN_PIPELINE terminating
2019-06-20 14:38:52,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742258_1434 src: /192.168.56.180:45456 dest: /192.168.56.180:50010
2019-06-20 14:38:52,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:45456, dest: /192.168.56.180:50010, bytes: 503572, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_792786694_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742258_1434, duration(ns): 38982252
2019-06-20 14:38:52,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742258_1434, type=LAST_IN_PIPELINE terminating
2019-06-20 15:19:32,924 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 153, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-20 16:36:19,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742259_1435 src: /192.168.56.180:47366 dest: /192.168.56.180:50010
2019-06-20 16:44:33,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:47366, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742259_1435, duration(ns): 494095197291
2019-06-20 16:44:33,536 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742259_1435, type=LAST_IN_PIPELINE terminating
2019-06-20 16:44:36,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742260_1436 src: /192.168.56.180:47598 dest: /192.168.56.180:50010
2019-06-20 16:54:33,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:47598, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742260_1436, duration(ns): 596996340120
2019-06-20 16:54:33,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742260_1436, type=LAST_IN_PIPELINE terminating
2019-06-20 17:20:46,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742261_1437 src: /192.168.56.180:47892 dest: /192.168.56.180:50010
2019-06-20 17:30:43,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:47892, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742261_1437, duration(ns): 596990777475
2019-06-20 17:30:43,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742261_1437, type=LAST_IN_PIPELINE terminating
2019-06-20 17:35:43,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742262_1438 src: /192.168.56.180:48326 dest: /192.168.56.180:50010
2019-06-20 17:41:02,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:48326, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742262_1438, duration(ns): 319601935664
2019-06-20 17:41:02,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742262_1438, type=LAST_IN_PIPELINE terminating
2019-06-20 17:41:05,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742263_1439 src: /192.168.56.180:48538 dest: /192.168.56.180:50010
2019-06-20 17:44:08,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:48538, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742263_1439, duration(ns): 182038243639
2019-06-20 17:44:08,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742263_1439, type=LAST_IN_PIPELINE terminating
2019-06-20 17:44:11,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742264_1440 src: /192.168.56.180:48746 dest: /192.168.56.180:50010
2019-06-20 17:54:08,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:48746, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742264_1440, duration(ns): 596991759789
2019-06-20 17:54:08,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742264_1440, type=LAST_IN_PIPELINE terminating
2019-06-20 18:47:41,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bec,  containing 1 storage report(s), of which we sent 1. The reports had 159 total blocks and used 1 RPC(s). This took 4 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-20 18:47:41,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-20 21:19:32,900 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 159, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-21 00:47:40,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bed,  containing 1 storage report(s), of which we sent 1. The reports had 159 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-21 00:47:40,693 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-21 03:19:32,877 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 159, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-21 06:47:43,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bee,  containing 1 storage report(s), of which we sent 1. The reports had 159 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-21 06:47:43,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-21 09:19:32,877 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 159, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-21 09:47:28,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742265_1441 src: /192.168.56.180:54590 dest: /192.168.56.180:50010
2019-06-21 09:49:50,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:54590, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742265_1441, duration(ns): 142038503618
2019-06-21 09:49:50,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742265_1441, type=LAST_IN_PIPELINE terminating
2019-06-21 09:49:53,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742266_1442 src: /192.168.56.180:54698 dest: /192.168.56.180:50010
2019-06-21 09:51:44,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:54698, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742266_1442, duration(ns): 110879474282
2019-06-21 09:51:44,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742266_1442, type=LAST_IN_PIPELINE terminating
2019-06-21 09:51:47,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742267_1443 src: /192.168.56.180:54792 dest: /192.168.56.180:50010
2019-06-21 10:01:44,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:54792, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742267_1443, duration(ns): 596993953237
2019-06-21 10:01:44,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742267_1443, type=LAST_IN_PIPELINE terminating
2019-06-21 12:16:54,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742268_1444 src: /192.168.56.180:55160 dest: /192.168.56.180:50010
2019-06-21 12:21:42,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:55160, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742268_1444, duration(ns): 287771097119
2019-06-21 12:21:42,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742268_1444, type=LAST_IN_PIPELINE terminating
2019-06-21 12:21:45,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742269_1445 src: /192.168.56.180:55220 dest: /192.168.56.180:50010
2019-06-21 12:24:56,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:55220, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742269_1445, duration(ns): 191313247098
2019-06-21 12:24:56,596 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742269_1445, type=LAST_IN_PIPELINE terminating
2019-06-21 12:25:00,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742270_1446 src: /192.168.56.180:55268 dest: /192.168.56.180:50010
2019-06-21 12:26:52,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:55268, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742270_1446, duration(ns): 112680550165
2019-06-21 12:26:52,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742270_1446, type=LAST_IN_PIPELINE terminating
2019-06-21 12:26:56,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742271_1447 src: /192.168.56.180:55310 dest: /192.168.56.180:50010
2019-06-21 12:33:03,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:55310, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742271_1447, duration(ns): 367091285963
2019-06-21 12:33:03,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742271_1447, type=LAST_IN_PIPELINE terminating
2019-06-21 12:33:06,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742272_1448 src: /192.168.56.180:55378 dest: /192.168.56.180:50010
2019-06-21 12:36:56,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:55378, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742272_1448, duration(ns): 230039337966
2019-06-21 12:36:56,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742272_1448, type=LAST_IN_PIPELINE terminating
2019-06-21 12:36:59,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742273_1449 src: /192.168.56.180:55432 dest: /192.168.56.180:50010
2019-06-21 12:46:56,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:55432, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742273_1449, duration(ns): 596987208545
2019-06-21 12:46:56,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742273_1449, type=LAST_IN_PIPELINE terminating
2019-06-21 12:47:42,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bef,  containing 1 storage report(s), of which we sent 1. The reports had 168 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-21 12:47:42,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-21 14:23:10,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742274_1450 src: /192.168.56.180:55720 dest: /192.168.56.180:50010
2019-06-21 14:33:07,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:55720, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742274_1450, duration(ns): 596990364828
2019-06-21 14:33:07,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742274_1450, type=LAST_IN_PIPELINE terminating
2019-06-21 15:19:32,887 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 169, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-21 15:48:16,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742275_1451 src: /192.168.56.180:55966 dest: /192.168.56.180:50010
2019-06-21 15:58:13,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:55966, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742275_1451, duration(ns): 596982877053
2019-06-21 15:58:13,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742275_1451, type=LAST_IN_PIPELINE terminating
2019-06-21 18:47:42,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf0,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-21 18:47:42,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-21 21:19:32,874 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-22 00:47:42,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf1,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-22 00:47:42,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-22 03:19:32,865 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-22 06:47:41,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf2,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-22 06:47:41,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-22 09:19:32,863 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-22 12:47:41,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf3,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 0 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-22 12:47:41,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-22 15:19:32,873 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-22 18:47:41,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf4,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-22 18:47:41,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-22 21:19:32,866 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-23 00:47:40,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf5,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-23 00:47:40,867 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-23 03:19:32,882 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-23 06:47:43,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf6,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-23 06:47:43,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-23 09:19:32,879 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-23 12:47:43,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf7,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-23 12:47:43,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-23 15:19:32,862 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-23 18:47:43,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf8,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-23 18:47:43,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-23 21:19:32,883 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-24 00:47:42,815 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bf9,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-24 00:47:42,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-24 03:19:32,863 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-24 06:47:42,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bfa,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-24 06:47:42,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-24 09:19:32,869 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-176234095-192.168.56.180-1559628803602 Total blocks: 170, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-06-24 12:47:42,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2a46db9498bd1bfb,  containing 1 storage report(s), of which we sent 1. The reports had 170 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-06-24 12:47:42,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-176234095-192.168.56.180-1559628803602
2019-06-24 14:19:36,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742276_1452 src: /192.168.56.180:36410 dest: /192.168.56.180:50010
2019-06-24 14:19:36,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36410, dest: /192.168.56.180:50010, bytes: 1033299, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742276_1452, duration(ns): 51581822
2019-06-24 14:19:36,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742276_1452, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:36,750 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742277_1453 src: /192.168.56.180:36412 dest: /192.168.56.180:50010
2019-06-24 14:19:36,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36412, dest: /192.168.56.180:50010, bytes: 375618, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742277_1453, duration(ns): 6875803
2019-06-24 14:19:36,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742277_1453, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:36,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742278_1454 src: /192.168.56.180:36414 dest: /192.168.56.180:50010
2019-06-24 14:19:36,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36414, dest: /192.168.56.180:50010, bytes: 914311, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742278_1454, duration(ns): 20219001
2019-06-24 14:19:36,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742278_1454, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:36,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742279_1455 src: /192.168.56.180:36416 dest: /192.168.56.180:50010
2019-06-24 14:19:36,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36416, dest: /192.168.56.180:50010, bytes: 267634, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742279_1455, duration(ns): 3029428
2019-06-24 14:19:36,899 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742279_1455, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:36,927 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742280_1456 src: /192.168.56.180:36418 dest: /192.168.56.180:50010
2019-06-24 14:19:36,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36418, dest: /192.168.56.180:50010, bytes: 25496, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742280_1456, duration(ns): 1622110
2019-06-24 14:19:36,940 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742280_1456, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:36,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742281_1457 src: /192.168.56.180:36420 dest: /192.168.56.180:50010
2019-06-24 14:19:36,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36420, dest: /192.168.56.180:50010, bytes: 232248, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742281_1457, duration(ns): 2088913
2019-06-24 14:19:36,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742281_1457, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742282_1458 src: /192.168.56.180:36422 dest: /192.168.56.180:50010
2019-06-24 14:19:37,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36422, dest: /192.168.56.180:50010, bytes: 20998, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742282_1458, duration(ns): 1667499
2019-06-24 14:19:37,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742282_1458, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742283_1459 src: /192.168.56.180:36424 dest: /192.168.56.180:50010
2019-06-24 14:19:37,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36424, dest: /192.168.56.180:50010, bytes: 1007502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742283_1459, duration(ns): 32374051
2019-06-24 14:19:37,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742283_1459, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,128 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742284_1460 src: /192.168.56.180:36426 dest: /192.168.56.180:50010
2019-06-24 14:19:37,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36426, dest: /192.168.56.180:50010, bytes: 60686, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742284_1460, duration(ns): 5411424
2019-06-24 14:19:37,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742284_1460, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742285_1461 src: /192.168.56.180:36428 dest: /192.168.56.180:50010
2019-06-24 14:19:37,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36428, dest: /192.168.56.180:50010, bytes: 197986, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742285_1461, duration(ns): 7980970
2019-06-24 14:19:37,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742285_1461, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742286_1462 src: /192.168.56.180:36430 dest: /192.168.56.180:50010
2019-06-24 14:19:37,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36430, dest: /192.168.56.180:50010, bytes: 1108073, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742286_1462, duration(ns): 17349257
2019-06-24 14:19:37,242 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742286_1462, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742287_1463 src: /192.168.56.180:36432 dest: /192.168.56.180:50010
2019-06-24 14:19:37,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36432, dest: /192.168.56.180:50010, bytes: 224277, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742287_1463, duration(ns): 2828539
2019-06-24 14:19:37,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742287_1463, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742288_1464 src: /192.168.56.180:36434 dest: /192.168.56.180:50010
2019-06-24 14:19:37,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36434, dest: /192.168.56.180:50010, bytes: 434678, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742288_1464, duration(ns): 3621740
2019-06-24 14:19:37,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742288_1464, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742289_1465 src: /192.168.56.180:36436 dest: /192.168.56.180:50010
2019-06-24 14:19:37,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36436, dest: /192.168.56.180:50010, bytes: 109043, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742289_1465, duration(ns): 5654462
2019-06-24 14:19:37,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742289_1465, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742290_1466 src: /192.168.56.180:36438 dest: /192.168.56.180:50010
2019-06-24 14:19:37,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36438, dest: /192.168.56.180:50010, bytes: 780664, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742290_1466, duration(ns): 8100167
2019-06-24 14:19:37,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742290_1466, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742291_1467 src: /192.168.56.180:36440 dest: /192.168.56.180:50010
2019-06-24 14:19:37,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36440, dest: /192.168.56.180:50010, bytes: 706710, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742291_1467, duration(ns): 9186809
2019-06-24 14:19:37,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742291_1467, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,522 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742292_1468 src: /192.168.56.180:36442 dest: /192.168.56.180:50010
2019-06-24 14:19:37,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36442, dest: /192.168.56.180:50010, bytes: 1007502, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742292_1468, duration(ns): 9399596
2019-06-24 14:19:37,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742292_1468, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,569 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742293_1469 src: /192.168.56.180:36444 dest: /192.168.56.180:50010
2019-06-24 14:19:37,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36444, dest: /192.168.56.180:50010, bytes: 1765905, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742293_1469, duration(ns): 22407753
2019-06-24 14:19:37,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742293_1469, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,639 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742294_1470 src: /192.168.56.180:36446 dest: /192.168.56.180:50010
2019-06-24 14:19:37,647 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36446, dest: /192.168.56.180:50010, bytes: 20744, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742294_1470, duration(ns): 2199356
2019-06-24 14:19:37,651 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742294_1470, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742295_1471 src: /192.168.56.180:36448 dest: /192.168.56.180:50010
2019-06-24 14:19:37,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36448, dest: /192.168.56.180:50010, bytes: 279012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742295_1471, duration(ns): 10302309
2019-06-24 14:19:37,708 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742295_1471, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742296_1472 src: /192.168.56.180:36450 dest: /192.168.56.180:50010
2019-06-24 14:19:37,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36450, dest: /192.168.56.180:50010, bytes: 58160, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742296_1472, duration(ns): 676844
2019-06-24 14:19:37,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742296_1472, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742297_1473 src: /192.168.56.180:36452 dest: /192.168.56.180:50010
2019-06-24 14:19:37,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36452, dest: /192.168.56.180:50010, bytes: 1801469, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742297_1473, duration(ns): 16870924
2019-06-24 14:19:37,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742297_1473, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742298_1474 src: /192.168.56.180:36454 dest: /192.168.56.180:50010
2019-06-24 14:19:37,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36454, dest: /192.168.56.180:50010, bytes: 205389, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742298_1474, duration(ns): 2421826
2019-06-24 14:19:37,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742298_1474, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742299_1475 src: /192.168.56.180:36456 dest: /192.168.56.180:50010
2019-06-24 14:19:37,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36456, dest: /192.168.56.180:50010, bytes: 53464, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742299_1475, duration(ns): 3218817
2019-06-24 14:19:37,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742299_1475, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:37,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742300_1476 src: /192.168.56.180:36458 dest: /192.168.56.180:50010
2019-06-24 14:19:37,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36458, dest: /192.168.56.180:50010, bytes: 592319, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742300_1476, duration(ns): 4608381
2019-06-24 14:19:37,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742300_1476, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,007 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742301_1477 src: /192.168.56.180:36460 dest: /192.168.56.180:50010
2019-06-24 14:19:38,021 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36460, dest: /192.168.56.180:50010, bytes: 892808, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742301_1477, duration(ns): 9649372
2019-06-24 14:19:38,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742301_1477, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,048 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742302_1478 src: /192.168.56.180:36462 dest: /192.168.56.180:50010
2019-06-24 14:19:38,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36462, dest: /192.168.56.180:50010, bytes: 36455, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742302_1478, duration(ns): 5180373
2019-06-24 14:19:38,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742302_1478, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742303_1479 src: /192.168.56.180:36464 dest: /192.168.56.180:50010
2019-06-24 14:19:38,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36464, dest: /192.168.56.180:50010, bytes: 99555, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742303_1479, duration(ns): 908807
2019-06-24 14:19:38,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742303_1479, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742304_1480 src: /192.168.56.180:36466 dest: /192.168.56.180:50010
2019-06-24 14:19:38,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36466, dest: /192.168.56.180:50010, bytes: 2178774, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742304_1480, duration(ns): 28100652
2019-06-24 14:19:38,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742304_1480, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742305_1481 src: /192.168.56.180:36468 dest: /192.168.56.180:50010
2019-06-24 14:19:38,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36468, dest: /192.168.56.180:50010, bytes: 36519, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742305_1481, duration(ns): 4807463
2019-06-24 14:19:38,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742305_1481, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742306_1482 src: /192.168.56.180:36470 dest: /192.168.56.180:50010
2019-06-24 14:19:38,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36470, dest: /192.168.56.180:50010, bytes: 186260, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742306_1482, duration(ns): 3076170
2019-06-24 14:19:38,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742306_1482, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742307_1483 src: /192.168.56.180:36472 dest: /192.168.56.180:50010
2019-06-24 14:19:38,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36472, dest: /192.168.56.180:50010, bytes: 19827, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742307_1483, duration(ns): 4534246
2019-06-24 14:19:38,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742307_1483, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742308_1484 src: /192.168.56.180:36474 dest: /192.168.56.180:50010
2019-06-24 14:19:38,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36474, dest: /192.168.56.180:50010, bytes: 34604, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742308_1484, duration(ns): 3740081
2019-06-24 14:19:38,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742308_1484, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742309_1485 src: /192.168.56.180:36476 dest: /192.168.56.180:50010
2019-06-24 14:19:38,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36476, dest: /192.168.56.180:50010, bytes: 1344870, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742309_1485, duration(ns): 9474849
2019-06-24 14:19:38,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742309_1485, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,392 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742310_1486 src: /192.168.56.180:36478 dest: /192.168.56.180:50010
2019-06-24 14:19:38,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36478, dest: /192.168.56.180:50010, bytes: 1768012, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742310_1486, duration(ns): 14084203
2019-06-24 14:19:38,417 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742310_1486, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742311_1487 src: /192.168.56.180:36480 dest: /192.168.56.180:50010
2019-06-24 14:19:38,467 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36480, dest: /192.168.56.180:50010, bytes: 365552, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742311_1487, duration(ns): 5206815
2019-06-24 14:19:38,468 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742311_1487, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742312_1488 src: /192.168.56.180:36482 dest: /192.168.56.180:50010
2019-06-24 14:19:38,512 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36482, dest: /192.168.56.180:50010, bytes: 10212, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742312_1488, duration(ns): 5365302
2019-06-24 14:19:38,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742312_1488, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742313_1489 src: /192.168.56.180:36486 dest: /192.168.56.180:50010
2019-06-24 14:19:38,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36486, dest: /192.168.56.180:50010, bytes: 94, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742313_1489, duration(ns): 541975
2019-06-24 14:19:38,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742313_1489, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:38,641 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742314_1490 src: /192.168.56.180:36488 dest: /192.168.56.180:50010
2019-06-24 14:19:38,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36488, dest: /192.168.56.180:50010, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742314_1490, duration(ns): 488463
2019-06-24 14:19:38,652 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742314_1490, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:39,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742315_1491 src: /192.168.56.180:36490 dest: /192.168.56.180:50010
2019-06-24 14:19:39,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36490, dest: /192.168.56.180:50010, bytes: 176853, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2060343323_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742315_1491, duration(ns): 37478673
2019-06-24 14:19:39,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742315_1491, type=LAST_IN_PIPELINE terminating
2019-06-24 14:19:40,635 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742283_1459 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742283 for deletion
2019-06-24 14:19:40,644 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742283_1459 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742283
2019-06-24 14:19:58,345 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742316_1492 src: /192.168.56.180:36508 dest: /192.168.56.180:50010
2019-06-24 14:19:58,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36508, dest: /192.168.56.180:50010, bytes: 203991, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1502732516_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742316_1492, duration(ns): 27093675
2019-06-24 14:19:58,387 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742316_1492, type=LAST_IN_PIPELINE terminating
2019-06-24 14:20:07,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742317_1493 src: /192.168.56.180:36520 dest: /192.168.56.180:50010
2019-06-24 14:20:07,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36520, dest: /192.168.56.180:50010, bytes: 503291, op: HDFS_WRITE, cliID: DFSClient_attempt_1560998425679_0001_m_000000_0_1955543041_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742317_1493, duration(ns): 237861696
2019-06-24 14:20:07,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742317_1493, type=LAST_IN_PIPELINE terminating
2019-06-24 14:20:07,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742318_1494 src: /192.168.56.180:36522 dest: /192.168.56.180:50010
2019-06-24 14:20:07,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36522, dest: /192.168.56.180:50010, bytes: 21136, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1502732516_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742318_1494, duration(ns): 153851684
2019-06-24 14:20:07,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742318_1494, type=LAST_IN_PIPELINE terminating
2019-06-24 14:20:07,724 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742319_1495 src: /192.168.56.180:36524 dest: /192.168.56.180:50010
2019-06-24 14:20:07,733 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36524, dest: /192.168.56.180:50010, bytes: 338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1502732516_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742319_1495, duration(ns): 609468
2019-06-24 14:20:07,734 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742319_1495, type=LAST_IN_PIPELINE terminating
2019-06-24 14:20:07,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742320_1496 src: /192.168.56.180:36528 dest: /192.168.56.180:50010
2019-06-24 14:20:07,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36528, dest: /192.168.56.180:50010, bytes: 21136, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1502732516_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742320_1496, duration(ns): 2044716
2019-06-24 14:20:07,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742320_1496, type=LAST_IN_PIPELINE terminating
2019-06-24 14:20:07,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742321_1497 src: /192.168.56.180:36530 dest: /192.168.56.180:50010
2019-06-24 14:20:07,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36530, dest: /192.168.56.180:50010, bytes: 203991, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1502732516_1, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742321_1497, duration(ns): 1945495
2019-06-24 14:20:07,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742321_1497, type=LAST_IN_PIPELINE terminating
2019-06-24 14:20:10,612 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742276_1452 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742276 for deletion
2019-06-24 14:20:10,612 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742277_1453 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742277 for deletion
2019-06-24 14:20:10,613 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742278_1454 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742278 for deletion
2019-06-24 14:20:10,613 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742279_1455 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742279 for deletion
2019-06-24 14:20:10,613 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742280_1456 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742280 for deletion
2019-06-24 14:20:10,613 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742281_1457 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742281 for deletion
2019-06-24 14:20:10,613 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742282_1458 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742282 for deletion
2019-06-24 14:20:10,613 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742284_1460 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742284 for deletion
2019-06-24 14:20:10,614 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742285_1461 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742285 for deletion
2019-06-24 14:20:10,614 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742286_1462 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742286 for deletion
2019-06-24 14:20:10,614 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742276_1452 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742276
2019-06-24 14:20:10,614 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742287_1463 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742287 for deletion
2019-06-24 14:20:10,614 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742288_1464 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742288 for deletion
2019-06-24 14:20:10,615 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742277_1453 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742277
2019-06-24 14:20:10,615 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742289_1465 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742289 for deletion
2019-06-24 14:20:10,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742290_1466 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742290 for deletion
2019-06-24 14:20:10,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742278_1454 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742278
2019-06-24 14:20:10,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742291_1467 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742291 for deletion
2019-06-24 14:20:10,616 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742279_1455 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742279
2019-06-24 14:20:10,618 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742292_1468 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742292 for deletion
2019-06-24 14:20:10,618 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742293_1469 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742293 for deletion
2019-06-24 14:20:10,618 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742280_1456 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742280
2019-06-24 14:20:10,618 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742294_1470 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742294 for deletion
2019-06-24 14:20:10,618 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742295_1471 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742295 for deletion
2019-06-24 14:20:10,618 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742281_1457 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742281
2019-06-24 14:20:10,621 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742296_1472 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742296 for deletion
2019-06-24 14:20:10,621 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742297_1473 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742297 for deletion
2019-06-24 14:20:10,621 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742282_1458 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742282
2019-06-24 14:20:10,622 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742298_1474 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742298 for deletion
2019-06-24 14:20:10,622 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742299_1475 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742299 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742300_1476 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742300 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742301_1477 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742301 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742302_1478 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742302 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742303_1479 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742303 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742304_1480 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742304 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742305_1481 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742305 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742306_1482 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742306 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742307_1483 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742307 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742308_1484 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742308 for deletion
2019-06-24 14:20:10,623 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742309_1485 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742309 for deletion
2019-06-24 14:20:10,624 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742310_1486 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742310 for deletion
2019-06-24 14:20:10,624 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742311_1487 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742311 for deletion
2019-06-24 14:20:10,624 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742312_1488 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742312 for deletion
2019-06-24 14:20:10,624 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742313_1489 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742313 for deletion
2019-06-24 14:20:10,624 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742314_1490 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742314 for deletion
2019-06-24 14:20:10,624 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742315_1491 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742315 for deletion
2019-06-24 14:20:10,624 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742316_1492 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742316 for deletion
2019-06-24 14:20:10,622 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742284_1460 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742284
2019-06-24 14:20:10,625 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742285_1461 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742285
2019-06-24 14:20:10,626 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742286_1462 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742286
2019-06-24 14:20:10,626 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742287_1463 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742287
2019-06-24 14:20:10,627 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742288_1464 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742288
2019-06-24 14:20:10,628 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742289_1465 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742289
2019-06-24 14:20:10,628 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742290_1466 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742290
2019-06-24 14:20:10,628 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742291_1467 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742291
2019-06-24 14:20:10,629 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742292_1468 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742292
2019-06-24 14:20:10,631 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073742318_1494 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742318 for deletion
2019-06-24 14:20:10,635 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742293_1469 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742293
2019-06-24 14:20:10,636 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742294_1470 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742294
2019-06-24 14:20:10,636 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742295_1471 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742295
2019-06-24 14:20:10,636 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742296_1472 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742296
2019-06-24 14:20:10,637 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742297_1473 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742297
2019-06-24 14:20:10,637 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742298_1474 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742298
2019-06-24 14:20:10,637 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742299_1475 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742299
2019-06-24 14:20:10,641 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742300_1476 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742300
2019-06-24 14:20:10,642 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742301_1477 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742301
2019-06-24 14:20:10,642 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742302_1478 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742302
2019-06-24 14:20:10,642 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742303_1479 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742303
2019-06-24 14:20:10,643 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742304_1480 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742304
2019-06-24 14:20:10,643 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742305_1481 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742305
2019-06-24 14:20:10,645 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742306_1482 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742306
2019-06-24 14:20:10,646 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742307_1483 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742307
2019-06-24 14:20:10,646 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742308_1484 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742308
2019-06-24 14:20:10,646 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742309_1485 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742309
2019-06-24 14:20:10,647 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742310_1486 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742310
2019-06-24 14:20:10,650 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742311_1487 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742311
2019-06-24 14:20:10,651 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742312_1488 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742312
2019-06-24 14:20:10,651 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742313_1489 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742313
2019-06-24 14:20:10,651 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742314_1490 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742314
2019-06-24 14:20:10,651 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742315_1491 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742315
2019-06-24 14:20:10,651 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742316_1492 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742316
2019-06-24 14:20:10,651 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-176234095-192.168.56.180-1559628803602 blk_1073742318_1494 file /home/FP/hadoop/datanode/current/BP-176234095-192.168.56.180-1559628803602/current/finalized/subdir0/subdir1/blk_1073742318
2019-06-24 14:20:32,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-176234095-192.168.56.180-1559628803602:blk_1073742322_1498 src: /192.168.56.180:36542 dest: /192.168.56.180:50010
2019-06-24 14:27:07,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /192.168.56.180:36542, dest: /192.168.56.180:50010, bytes: 8, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-878347945_34, offset: 0, srvID: e73933f1-f299-4a17-994e-22eb0f3ff35c, blockid: BP-176234095-192.168.56.180-1559628803602:blk_1073742322_1498, duration(ns): 395020284430
2019-06-24 14:27:07,504 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-176234095-192.168.56.180-1559628803602:blk_1073742322_1498, type=LAST_IN_PIPELINE terminating
2019-06-24 14:28:41,737 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-06-24 14:28:41,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/192.168.56.180
************************************************************/
