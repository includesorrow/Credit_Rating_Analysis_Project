<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Spark ML - LinearSVC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for ml_linear_svc {sparklyr}"><tr><td>ml_linear_svc {sparklyr}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Spark ML &ndash; LinearSVC</h2>

<h3>Description</h3>

<p>Perform classification using linear support vector machines (SVM). This binary classifier optimizes the Hinge Loss using the OWLQN optimizer. Only supports L2 regularization currently.
</p>


<h3>Usage</h3>

<pre>
ml_linear_svc(x, formula = NULL, fit_intercept = TRUE, reg_param = 0,
  max_iter = 100, standardization = TRUE, weight_col = NULL,
  tol = 1e-06, threshold = 0, aggregation_depth = 2,
  features_col = "features", label_col = "label",
  prediction_col = "prediction", raw_prediction_col = "rawPrediction",
  uid = random_string("linear_svc_"), ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x</code></td>
<td>
<p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p>
</td></tr>
<tr valign="top"><td><code>formula</code></td>
<td>
<p>Used when <code>x</code> is a <code>tbl_spark</code>. R formula as a character string or a formula. This is used to transform the input dataframe before fitting, see <a href="ft_r_formula.html">ft_r_formula</a> for details.</p>
</td></tr>
<tr valign="top"><td><code>fit_intercept</code></td>
<td>
<p>Boolean; should the model be fit with an intercept term?</p>
</td></tr>
<tr valign="top"><td><code>reg_param</code></td>
<td>
<p>Regularization parameter (aka lambda)</p>
</td></tr>
<tr valign="top"><td><code>max_iter</code></td>
<td>
<p>The maximum number of iterations to use.</p>
</td></tr>
<tr valign="top"><td><code>standardization</code></td>
<td>
<p>Whether to standardize the training features before fitting the model.</p>
</td></tr>
<tr valign="top"><td><code>weight_col</code></td>
<td>
<p>The name of the column to use as weights for the model fit.</p>
</td></tr>
<tr valign="top"><td><code>tol</code></td>
<td>
<p>Param for the convergence tolerance for iterative algorithms.</p>
</td></tr>
<tr valign="top"><td><code>threshold</code></td>
<td>
<p>in binary classification prediction, in range [0, 1].</p>
</td></tr>
<tr valign="top"><td><code>aggregation_depth</code></td>
<td>
<p>(Spark 2.1.0+) Suggested depth for treeAggregate (&gt;= 2).</p>
</td></tr>
<tr valign="top"><td><code>features_col</code></td>
<td>
<p>Features column name, as a length-one character vector. The column should be single vector column of numeric values. Usually this column is output by <code><a href="ft_r_formula.html">ft_r_formula</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>label_col</code></td>
<td>
<p>Label column name. The column should be a numeric column. Usually this column is output by <code><a href="ft_r_formula.html">ft_r_formula</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>prediction_col</code></td>
<td>
<p>Prediction column name.</p>
</td></tr>
<tr valign="top"><td><code>raw_prediction_col</code></td>
<td>
<p>Raw prediction (a.k.a. confidence) column name.</p>
</td></tr>
<tr valign="top"><td><code>uid</code></td>
<td>
<p>A character string used to uniquely identify the ML estimator.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Optional arguments; see Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>x</code> is a <code>tbl_spark</code> and <code>formula</code> (alternatively, <code>response</code> and <code>features</code>) is specified, the function returns a <code>ml_model</code> object wrapping a <code>ml_pipeline_model</code> which contains data pre-processing transformers, the ML predictor, and, for classification models, a post-processing transformer that converts predictions into class labels. For classification, an optional argument <code>predicted_label_col</code> (defaults to <code>"predicted_label"</code>) can be used to specify the name of the predicted label column. In addition to the fitted <code>ml_pipeline_model</code>, <code>ml_model</code> objects also contain a <code>ml_pipeline</code> object where the ML predictor stage is an estimator ready to be fit against data. This is utilized by <code><a href="ml-persistence.html">ml_save</a></code> with <code>type = "pipeline"</code> to faciliate model refresh workflows.
</p>


<h3>Value</h3>

<p>The object returned depends on the class of <code>x</code>.
</p>

<ul>
<li> <p><code>spark_connection</code>: When <code>x</code> is a <code>spark_connection</code>, the function returns an instance of a <code>ml_estimator</code> object. The object contains a pointer to
a Spark <code>Predictor</code> object and can be used to compose
<code>Pipeline</code> objects.
</p>
</li>
<li> <p><code>ml_pipeline</code>: When <code>x</code> is a <code>ml_pipeline</code>, the function returns a <code>ml_pipeline</code> with
the predictor appended to the pipeline.
</p>
</li>
<li> <p><code>tbl_spark</code>: When <code>x</code> is a <code>tbl_spark</code>, a predictor is constructed then
immediately fit with the input <code>tbl_spark</code>, returning a prediction model.
</p>
</li>
<li> <p><code>tbl_spark</code>, with <code>formula</code>: specified When <code>formula</code>
is specified, the input <code>tbl_spark</code> is first transformed using a
<code>RFormula</code> transformer before being fit by
the predictor. The object returned in this case is a <code>ml_model</code> which is a
wrapper of a <code>ml_pipeline_model</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p>See <a href="http://spark.apache.org/docs/latest/ml-classification-regression.html">http://spark.apache.org/docs/latest/ml-classification-regression.html</a> for
more information on the set of supervised learning algorithms.
</p>
<p>Other ml algorithms: <code><a href="ml_aft_survival_regression.html">ml_aft_survival_regression</a></code>,
<code><a href="ml_decision_tree.html">ml_decision_tree_classifier</a></code>,
<code><a href="ml_gradient_boosted_trees.html">ml_gbt_classifier</a></code>,
<code><a href="ml_generalized_linear_regression.html">ml_generalized_linear_regression</a></code>,
<code><a href="ml_isotonic_regression.html">ml_isotonic_regression</a></code>,
<code><a href="ml_linear_regression.html">ml_linear_regression</a></code>,
<code><a href="ml_logistic_regression.html">ml_logistic_regression</a></code>,
<code><a href="ml_multilayer_perceptron_classifier.html">ml_multilayer_perceptron_classifier</a></code>,
<code><a href="ml_naive_bayes.html">ml_naive_bayes</a></code>,
<code><a href="ml_one_vs_rest.html">ml_one_vs_rest</a></code>,
<code><a href="ml_random_forest.html">ml_random_forest_classifier</a></code>
</p>


<h3>Examples</h3>

<pre>
## Not run: 
library(dplyr)

sc &lt;- spark_connect(master = "local")
iris_tbl &lt;- sdf_copy_to(sc, iris, name = "iris_tbl", overwrite = TRUE)

partitions &lt;- iris_tbl %&gt;%
  filter(Species != "setosa") %&gt;%
  sdf_random_split(training = 0.7, test = 0.3, seed = 1111)

iris_training &lt;- partitions$training
iris_test &lt;- partitions$test

svc_model &lt;- iris_training %&gt;%
  ml_linear_svc(Species ~ .)

pred &lt;- ml_predict(svc_model, iris_test)

ml_binary_classification_evaluator(pred)

## End(Not run)
</pre>

<hr /><div style="text-align: center;">[Package <em>sparklyr</em> version 1.0.1 <a href="00Index.html">Index</a>]</div>
</body></html>
