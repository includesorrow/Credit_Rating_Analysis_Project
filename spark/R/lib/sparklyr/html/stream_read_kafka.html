<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Read Kafka Stream</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for stream_read_kafka {sparklyr}"><tr><td>stream_read_kafka {sparklyr}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Read Kafka Stream</h2>

<h3>Description</h3>

<p>Reads a Kafka stream as a Spark dataframe stream.
</p>


<h3>Usage</h3>

<pre>
stream_read_kafka(sc, name = NULL, options = list(), ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>sc</code></td>
<td>
<p>A <code>spark_connection</code>.</p>
</td></tr>
<tr valign="top"><td><code>name</code></td>
<td>
<p>The name to assign to the newly generated stream.</p>
</td></tr>
<tr valign="top"><td><code>options</code></td>
<td>
<p>A list of strings with additional options.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please note that Kafka requires installing the appropriate
package by conneting with a config setting where <code>sparklyr.shell.packages</code>
is set to, for Spark 2.3.2, <code>"org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.2"</code>.
</p>


<h3>See Also</h3>

<p>Other Spark stream serialization: <code><a href="stream_read_csv.html">stream_read_csv</a></code>,
<code><a href="stream_read_json.html">stream_read_json</a></code>,
<code><a href="stream_read_orc.html">stream_read_orc</a></code>,
<code><a href="stream_read_parquet.html">stream_read_parquet</a></code>,
<code><a href="stream_read_scoket.html">stream_read_scoket</a></code>,
<code><a href="stream_read_text.html">stream_read_text</a></code>,
<code><a href="stream_write_console.html">stream_write_console</a></code>,
<code><a href="stream_write_csv.html">stream_write_csv</a></code>,
<code><a href="stream_write_json.html">stream_write_json</a></code>,
<code><a href="stream_write_kafka.html">stream_write_kafka</a></code>,
<code><a href="stream_write_memory.html">stream_write_memory</a></code>,
<code><a href="stream_write_orc.html">stream_write_orc</a></code>,
<code><a href="stream_write_parquet.html">stream_write_parquet</a></code>,
<code><a href="stream_write_text.html">stream_write_text</a></code>
</p>


<h3>Examples</h3>

<pre>
## Not run: 

config &lt;- spark_config()

# The following package is dependent to Spark version, for Spark 2.3.2:
config$sparklyr.shell.packages &lt;- "org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.2"

sc &lt;- spark_connect(master = "local", config = config)

read_options &lt;- list(kafka.bootstrap.servers = "localhost:9092", subscribe = "topic1")
write_options &lt;- list(kafka.bootstrap.servers = "localhost:9092", topic = "topic2")

stream &lt;- stream_read_kafka(sc, options = read_options) %&gt;%
  stream_write_kafka(options = write_options)

stream_stop(stream)


## End(Not run)

</pre>

<hr /><div style="text-align: center;">[Package <em>sparklyr</em> version 1.0.1 <a href="00Index.html">Index</a>]</div>
</body></html>
