<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Spark ML - Naive-Bayes</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for ml_naive_bayes {sparklyr}"><tr><td>ml_naive_bayes {sparklyr}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Spark ML &ndash; Naive-Bayes</h2>

<h3>Description</h3>

<p>Naive Bayes Classifiers. It supports Multinomial NB (see <a href="http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html">here</a>) which can handle finitely supported discrete data. For example, by converting documents into TF-IDF vectors, it can be used for document classification. By making every vector a binary (0/1) data, it can also be used as Bernoulli NB (see <a href="http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html">here</a>). The input feature values must be nonnegative.
</p>


<h3>Usage</h3>

<pre>
ml_naive_bayes(x, formula = NULL, model_type = "multinomial",
  smoothing = 1, thresholds = NULL, weight_col = NULL,
  features_col = "features", label_col = "label",
  prediction_col = "prediction", probability_col = "probability",
  raw_prediction_col = "rawPrediction",
  uid = random_string("naive_bayes_"), ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x</code></td>
<td>
<p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p>
</td></tr>
<tr valign="top"><td><code>formula</code></td>
<td>
<p>Used when <code>x</code> is a <code>tbl_spark</code>. R formula as a character string or a formula. This is used to transform the input dataframe before fitting, see <a href="ft_r_formula.html">ft_r_formula</a> for details.</p>
</td></tr>
<tr valign="top"><td><code>model_type</code></td>
<td>
<p>The model type. Supported options: <code>"multinomial"</code>
and <code>"bernoulli"</code>. (default = <code>multinomial</code>)</p>
</td></tr>
<tr valign="top"><td><code>smoothing</code></td>
<td>
<p>The (Laplace) smoothing parameter. Defaults to 1.</p>
</td></tr>
<tr valign="top"><td><code>thresholds</code></td>
<td>
<p>Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values &gt; 0 excepting that at most one value may be 0. The class with largest value <code>p/t</code> is predicted, where <code>p</code> is the original probability of that class and <code>t</code> is the class's threshold.</p>
</td></tr>
<tr valign="top"><td><code>weight_col</code></td>
<td>
<p>(Spark 2.1.0+) Weight column name. If this is not set or empty, we treat all instance weights as 1.0.</p>
</td></tr>
<tr valign="top"><td><code>features_col</code></td>
<td>
<p>Features column name, as a length-one character vector. The column should be single vector column of numeric values. Usually this column is output by <code><a href="ft_r_formula.html">ft_r_formula</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>label_col</code></td>
<td>
<p>Label column name. The column should be a numeric column. Usually this column is output by <code><a href="ft_r_formula.html">ft_r_formula</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>prediction_col</code></td>
<td>
<p>Prediction column name.</p>
</td></tr>
<tr valign="top"><td><code>probability_col</code></td>
<td>
<p>Column name for predicted class conditional probabilities.</p>
</td></tr>
<tr valign="top"><td><code>raw_prediction_col</code></td>
<td>
<p>Raw prediction (a.k.a. confidence) column name.</p>
</td></tr>
<tr valign="top"><td><code>uid</code></td>
<td>
<p>A character string used to uniquely identify the ML estimator.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Optional arguments; see Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>x</code> is a <code>tbl_spark</code> and <code>formula</code> (alternatively, <code>response</code> and <code>features</code>) is specified, the function returns a <code>ml_model</code> object wrapping a <code>ml_pipeline_model</code> which contains data pre-processing transformers, the ML predictor, and, for classification models, a post-processing transformer that converts predictions into class labels. For classification, an optional argument <code>predicted_label_col</code> (defaults to <code>"predicted_label"</code>) can be used to specify the name of the predicted label column. In addition to the fitted <code>ml_pipeline_model</code>, <code>ml_model</code> objects also contain a <code>ml_pipeline</code> object where the ML predictor stage is an estimator ready to be fit against data. This is utilized by <code><a href="ml-persistence.html">ml_save</a></code> with <code>type = "pipeline"</code> to faciliate model refresh workflows.
</p>


<h3>Value</h3>

<p>The object returned depends on the class of <code>x</code>.
</p>

<ul>
<li> <p><code>spark_connection</code>: When <code>x</code> is a <code>spark_connection</code>, the function returns an instance of a <code>ml_estimator</code> object. The object contains a pointer to
a Spark <code>Predictor</code> object and can be used to compose
<code>Pipeline</code> objects.
</p>
</li>
<li> <p><code>ml_pipeline</code>: When <code>x</code> is a <code>ml_pipeline</code>, the function returns a <code>ml_pipeline</code> with
the predictor appended to the pipeline.
</p>
</li>
<li> <p><code>tbl_spark</code>: When <code>x</code> is a <code>tbl_spark</code>, a predictor is constructed then
immediately fit with the input <code>tbl_spark</code>, returning a prediction model.
</p>
</li>
<li> <p><code>tbl_spark</code>, with <code>formula</code>: specified When <code>formula</code>
is specified, the input <code>tbl_spark</code> is first transformed using a
<code>RFormula</code> transformer before being fit by
the predictor. The object returned in this case is a <code>ml_model</code> which is a
wrapper of a <code>ml_pipeline_model</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p>See <a href="http://spark.apache.org/docs/latest/ml-classification-regression.html">http://spark.apache.org/docs/latest/ml-classification-regression.html</a> for
more information on the set of supervised learning algorithms.
</p>
<p>Other ml algorithms: <code><a href="ml_aft_survival_regression.html">ml_aft_survival_regression</a></code>,
<code><a href="ml_decision_tree.html">ml_decision_tree_classifier</a></code>,
<code><a href="ml_gradient_boosted_trees.html">ml_gbt_classifier</a></code>,
<code><a href="ml_generalized_linear_regression.html">ml_generalized_linear_regression</a></code>,
<code><a href="ml_isotonic_regression.html">ml_isotonic_regression</a></code>,
<code><a href="ml_linear_regression.html">ml_linear_regression</a></code>,
<code><a href="ml_linear_svc.html">ml_linear_svc</a></code>,
<code><a href="ml_logistic_regression.html">ml_logistic_regression</a></code>,
<code><a href="ml_multilayer_perceptron_classifier.html">ml_multilayer_perceptron_classifier</a></code>,
<code><a href="ml_one_vs_rest.html">ml_one_vs_rest</a></code>,
<code><a href="ml_random_forest.html">ml_random_forest_classifier</a></code>
</p>


<h3>Examples</h3>

<pre>
## Not run: 
sc &lt;- spark_connect(master = "local")
iris_tbl &lt;- sdf_copy_to(sc, iris, name = "iris_tbl", overwrite = TRUE)

partitions &lt;- iris_tbl %&gt;%
  sdf_random_split(training = 0.7, test = 0.3, seed = 1111)

iris_training &lt;- partitions$training
iris_test &lt;- partitions$test

nb_model &lt;- iris_training %&gt;%
  ml_naive_bayes(Species ~ .)

pred &lt;- ml_predict(nb_model, iris_test)

ml_multiclass_classification_evaluator(pred)

## End(Not run)

</pre>

<hr /><div style="text-align: center;">[Package <em>sparklyr</em> version 1.0.1 <a href="00Index.html">Index</a>]</div>
</body></html>
